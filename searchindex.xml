<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Linux的路由表和策略路由</title><url>https://lizj3624.github.io/post/linux-route-rule/</url><categories><category>linux</category><category>网络路由</category><category>策略路由</category></categories><tags><tag>linux</tag><tag>网络路由</tag><tag>策略路由</tag></tags><content type="html"> 传统的路由是一个指向目标子网的"指路牌"，任何人来"问路"，路由都会明确指向目标。 传统路由这种"不问来人情况"的处理策略越来越不适合现代计算机网络，举例来说"行人与汽车"走的"路"应该是不同的。 这样策略路由就兴起了，策略路由是近些年来兴起的一个比较新的路由概念。 策略路由可以根据多种不同的策略，决定数据包通过的路径。
路由表 路由表标记数据包转发的方向，可以通过ip route show查看路由表信息
[root@my ~]$ip route show table local broadcast 127.0.0.0 dev lo proto kernel scope link src 127.0.0.1 local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1 local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1 broadcast 127.255.255.255 dev lo proto kernel scope link src 127.0.0.1 broadcast 192.168.139.0 dev ens33 proto kernel scope link src 192.168.139.152 local 192.168.139.152 dev ens33 proto kernel scope host src 192.168.139.152 broadcast 192.168.139.255 dev ens33 proto kernel scope link src 192.168.139.152 Linux最多可以支持255张路由表，其中有3张表是内置的：
表255 本地路由表（Local table）本地接口地址，广播地址，已及 NAT 地址都放在这个表。该路由表由系统自动维护，管理员不能直接修改。 表254 主路由表（Main table）如果没有指明路由所属的表，所有的路由都默认都放在这个表里，一般来说，旧的路由工具（如route）所添加的路由都会加到这个表。一般是普通的路由。 表253 默认路由表 （Default table）一般来说默认的路由都放在这张表，但是如果特别指明放的也可以是所有的网关路由。 还有一张表 0 是保留的，在文件 /etc/iproute2/rt_tables 可以查看和配置路由表的 TABLE_ID 及路由表名称。 也可以通过route -n命令查看，但是只能查看main表，比如 ip route show命令强大
策略路由 策略是指对于IP包的路由是以我们根据需要而定下的一些策略为主要依据进行路由的。 例如我们可以有这样的策略：&ldquo;所有来直自网A的包，选择X路径；其他选择Y路径&rdquo;，或者是“所有TOS为A的包选择路径F；其他选者路径K”。
Linux是通过规则(rule)来支持策略路由的
我们可以用自然语言这样描述规则：
规则一：&ldquo;所有来自192.16.152.24的IP包，使用路由表10，本规则的优先级是990&rdquo; 规则三：&ldquo;所有到192.168.127.127的IP包，使用路由表11，本规则的优先级是991&rdquo; 规则二：&ldquo;所有的包，使用路由表253，本规则的优先级是32767&rdquo; 我们可以看到，规则包含3个要素：
什么样的包，将应用本规则（所谓的SELECTOR，可能是filter更能反映其作用）； 符合本规则的包将对其采取什么动作（ACTION），例如：使用哪个路由个表； 本规则的优先级。优先级别越高的规则越先匹配（数值越小优先级别越高）。 可以通过ip rule list查看规则
[root@my ~]# ip rule list 0: from all lookup local 32765: from 192.168.19.0/24 lookup test1 32766: from all lookup main 32767: from all lookup default 引用 Linux的策略路由 Linux的策略路由 Linux IP 路由背后的原理及其工作原理 IP-route管理路由 通俗理解IP路由 Linux系列—策略路由、ip rule、ip route</content></entry><entry><title>Http隧道</title><url>https://lizj3624.github.io/post/http-tunnel/</url><categories><category>http协议</category><category>http隧道</category></categories><tags><tag>http协议</tag><tag>http隧道</tag></tags><content type="html"> HTTP隧道代理模式 在HTTP协议中，CONNECT方法可以开启一个客户端与所请求资源之间的双向沟通的通道。它可以用来创建隧道(tunnel)。
例如，CONNECT可以用来访问采用了SSL (HTTPS)协议的站点。客户端要求代理服务器将TCP连接作为通往目的主机隧道。 之后该服务器会代替客户端与目的主机建立连接。连接建立好之后，代理服务器会面向客户端发送或接收TCP消息流。
只有当浏览器配置为使用代理服务器时才会用到CONNECT方法。
HTTP隧道代理跟HTTP正向代理类似。
下面是一个代理的请求
# -x 执向代理服务 $ curl https://github.com -sv -x localhost:3128 * Connected to localhost (127.0.0.1) port 3128 (#0) * allocate connect buffer! * Establish HTTP proxy tunnel to github.com:443 > CONNECT github.com:443 HTTP/1.1 > Host: github.com:443 > User-Agent: curl/7.64.1 > Proxy-Connection: Keep-Alive > &lt; HTTP/1.1 200 Connection Established --. &lt; Proxy-agent: nginx | custom CONNECT response &lt; X-Proxy-Connected-Addr: 13.229.188.59:443 --' ... 代理请求链路： 引用 HTTP CONNECT
理解HTTP CONNECT通道</content></entry><entry><title>2018.5月红周刊对查理.芒格的深度访谈</title><url>https://lizj3624.github.io/post/charlie-munger-hong-zhou-kan/</url><categories><category>查理芒格</category><category>价值投资</category><category>video</category></categories><tags><tag>查理芒格</tag><tag>价值投资</tag><tag>video</tag></tags><content type="html"> 2018年5月红周刊在奥马哈对查理.芒格的深度访谈</content></entry><entry><title>Linux下C/C++程序崩溃错误定位思路</title><url>https://lizj3624.github.io/post/fix-crash/</url><categories><category>Linux</category><category>addr2line</category><category>crash</category></categories><tags><tag>Linux</tag><tag>addr2line</tag><tag>crash</tag></tags><content type="html"> Linux下开发的C/C++程序崩溃后错误定位的思路。
coredump定位 Linux下开发的C/C++崩溃后可以产生coredump文件，通过coredump文件可以定位崩溃点。但是必须前期设置coredump， 详细的设置步骤和定位方法可以参考另一篇文章: Linux下的cordump设置和使用。
addr2line定位 有时候上线环境没有开启cordump，又着急定位问题，可以通过addr2line粗略定位崩溃点。
下面我们详细说明这个思路：
一般Linux下程序崩溃时会有segfault信息，可以通过dmesg命令查看，以nginx崩溃为例说一下
nginx[55279]: segfault at 48 ip 000000000049259c sp 00007fffec5b7350 error 4 in nginx[400000+1ed000] nginx[55276]: segfault at 48 ip 000000000049259c sp 00007fffec5b7350 error 4 in nginx[400000+1ed000] 简单说一下segfault信息:
ip 000000000049259c 发生错误时指令的地址
sp 00007fffec5b7350 堆栈指针
error 4 为用户态内存读操作访问出界，读非法地址，可以对照参考：
bit2:值为1表示是用户态程序内存访问越界，值为0表示是内核态程序内存访问越界
bit1: 值为1表示是写操作导致内存访问越界，值为0表示是读操作导致内存访问越界 bit0: 值为1表示没有足够的权限访问非法地址的内容，值为0表示访问的非法地址根本没有对应的页面，也就是无效地址
Linux下addr2line命令用于将程序指令地址转换为所对应的函数名、以及函数所在的源文件名和行号。 当含有调试信息(-g)的执行程序出现crash时(core dumped)，可使用addr2line命令快速定位出错的位置。
定位命令查看, 需要依赖debuginfo包
addr2line -e /usr/lib/debug/nginx/sbin/nginx.debug -fCi 000000000049259c ngx_http_v2_process_request_body /usr/src/debug/nginx/build/nginx-1.15.8/src/http/v2/ngx_http_v2.c:3975 引用 DMESG和ADDR2LINE定位SEGFAULT
拒绝超大coredump-用backtrace和addr2line搞定异常函数栈</content></entry><entry><title>费城半导体指数</title><url>https://lizj3624.github.io/post/sox/</url><categories><category>半导体</category><category>科技股</category></categories><tags><tag>半导体</tag><tag>科技股</tag></tags><content type="html"> 费城半导体指数。英文全称PHLX Semiconductor Sector，简称SOX，由费城交易所创立于1993年，为全球半导体业景气主要指标之一。
费城半导体指数为美国四大指数之一，主要以半导体产业为主，是作为全球半导体周期的重要观察指标。
成分股共有30只，包括应用材料、超微、博通、台积电、飞思卡尔、英飞凌、英特尔、美光、意法半导体、德仪、赛灵思、英伟达等。
费城半导体指数-英为财情</content></entry><entry><title>美元指数</title><url>https://lizj3624.github.io/post/dollar-index/</url><categories><category>宏观经济</category><category>美元指数</category></categories><tags><tag>宏观经济</tag><tag>美元指数</tag></tags><content type="html"> 美元指数 美元指数（英文常写作DXY、DX和USDX)，衡量美元相对一篮子其它货币的价值，其它货币中包含美国一些主要贸易伙伴的货币。 当美元相对篮子中的其它货币上涨时，美元指数走高，当美元下跌时美元指数走弱。
美元指数是反映美元升值和贬值情况的一个指标。
美元指数衡量美元兑6个全球货币的走势：欧元、瑞郎、日元、加元、英镑和瑞典克朗。
美元指数上涨意味着什么 1973年美元指数发布之初的基础价格是100，此后其价值一直与这个价格做比较。美元指数在其历史上的交投范围一直都很宽广。
美元指数的历史高点是在1985年3月5日创下的163.83，历史低点是在2008年4月22日创下的71.58。截至2021年3月31日，美元指数报在93.26 – 低于100的初始价值，也低于其它货币的价值。
首先，美元指数上涨，意味着美元是在升值。美元指数的涨跌既然代表美元升值或贬值，上涨自然就是在升值。
不过，这种升值仅仅是相对的，即相对于其他货币来说，也就是常说的对外升值。美元升值，其他的货币相对于美元来说就会贬值。
另外，也并不是其他所有货币在美元的升值下，都会对美元贬值。因为一国货币的升值和贬值，不仅跟其他货币的升值和贬值有关，也跟自身的因素有关。就比如卢布，在美元的升值下不仅没有贬值，反而还升值了。
受美元升值影响最大的货币应该就是欧元，因为二者的汇率基本上是反着走的，即美元升值，欧元对美元就会贬值。
而人民币同样也会受到一定影响，在美元指数快速上涨时，人民币对美元也存在比较大的贬值压力，只是受到的影响没有欧元那么大而已。
而对内，也就是在美国国内，美元非但没有升值，反而还在快速贬值。因为美国的通货膨胀已经达到了几十年的高点，说明美国国内的物价涨得很快，而物价涨得越快，就意味着美元在美国国内贬值得越快。
再次，美元指数的上涨，意味着美元在回流美国。美国发行的美元，并不是都在美国国内，而是分布在世界各地。因为美元是最重要的国际货币，担任着国际主要的支付和结算货币，因此基本上各个国家都会储备一些美元。
在美元指数上涨下，这些流落在其他国家的美元，就有可能回流美国。因为美元指数上涨是美联储加息的表现之一。美联储加息，意味着美国利率上升，持有美元的收益也会上升，从而吸引在其他国家的美元回流美国。而这又可能会对其他国家的经济和金融市场造成一定冲击。
可见，美元指数上涨，并不只是美元升值那么简单。
引用 什么是美元指数
美元指数上涨意味着什么？仅仅意味着美元在升值吗？
美元指数变化-新浪</content></entry><entry><title>债务危机: 我的应对原则-瑞.达利欧</title><url>https://lizj3624.github.io/post/debt-crises/</url><categories><category>宏观经济</category><category>桥水</category></categories><tags><tag>宏观经济</tag><tag>桥水</tag></tags><content type="html"> 经济出现泡沫的基本特征 以传统尺度来衡量，物价较高。
物价低估了未来物价在这些高位基础上的快速上涨。
存在普通的看涨情绪。
人们通过高杠杆融资购买。
买家进行了超长期的远期购买(如积累库存、签署远期购买合同等)，以进行投机或保护自己免受未来物价上涨影响。
新买家(即之前没有进入市场的买家)已进入市场。
刺激性货币政策有助于泡沫扩大，而紧缩政策有助于泡沫破裂。</content></entry><entry><title>Yusen戴雨森: 因为相信，所以看见</title><url>https://lizj3624.github.io/post/yusen/</url><categories><category>投资</category><category>video</category></categories><tags><tag>投资</tag><tag>video</tag></tags><content type="html"> 2021.6.12号真格基金合伙人，聚美优品联合创始人戴雨森在老虎证券「老虎7周年」Openday发表了主题为《因为相信、所以看见 VS 因为看见、所以相信》的演讲，视频非常有看点，干货满满，再此收录一下。
演讲要点 从一级市场到二级市场，随着公司越来越成熟，投资逻辑是一个从"因为相信所以看见"，到"因为看见所以相信"的演变过程。但是二级市场要想赚大钱，如果要拿住好几年的特斯拉，比特币，或者是腾讯，其实也是需要“因为相信所以看见”的。
我们往往会高估一个新技术在短期内的成长，但低估它长期的价值。
通过《跨越鸿沟》中Innovators、Early Adopters、Early Majority、Late Majority、Laggard四类人群，来分析拆解技术创新的过程，用于指导分析科技股。
如果我们把跨越鸿沟的图和Gartner的Hype Curve（泡沫曲线）的图叠加一下的话，就会发现泡沫的产生和破灭，以及泡沫之后的成长，跟跨越鸿沟是关联的。
菩萨畏因，凡夫畏果；菩萨会关注这个原因，但凡夫往往沉浸在对结果的关注上，而忽略了对原因，对自己提高的追求，对于公司价值认知提高的追求。
财富会找到自己真正的主人（Money will find its own master）
阿尔法书院整理演讲全文: Yusen 戴雨森：财富会找到自己真正的主人
视频转载自B站</content></entry><entry><title>人的成长过程就是控制兽性、保持人性、追求神性</title><url>https://lizj3624.github.io/post/human/</url><categories><category>人性</category><category>人文</category></categories><tags><tag>人性</tag><tag>人文</tag></tags><content type="html"> 这篇文章摘录自王光斌，戴艳的《教育的批判：基于常识的教育生态反思》中的第八章 教育理性的消解及其功能的变异，特别喜欢其中的"人的成长过程就是控制兽性、保持人性、追求神性"这句话，在此摘录这篇文章
教育理性的消解及其功能的变异 人的成长过程就是控制兽性、保持人性、追求神性的自我提升过程。 教育是实现这一切的主要途径。教育使人获得理性，包括科学理性、人文理性、审美理性。 教育理性的控制功能造就了人的高贵的精神性。教育理性的消解及其功能的变异，预示着人的精神危机的到来。
人具有兽性、人性、神性，这三个层面的属性决定了人是最复杂的生命体。 兽性即人的动物性本能，是人源自动物界而与生俱来的属性；人性即通过后天教育而养成的人文属性，是它使人脱离动物而成为人；神性是在人性基础上升华而成的最为高贵的特性，人的伟大或神圣皆缘于这一精神品质。“人与一般动物的区别在于人是精神性存在，有意识和自我意识。失去这种精神性，失去对自我的认识，也就失去了人的特异性，使人降格而与一般动物无异。”
人的成长过程就是控制兽性、保持人性、追求神性的过程，这个过程的完成程度决定了人的高贵程度。而这一切主要是通过教育来实现的。 因为是教育使人获得理性，这一理性的控制功能造就了人的高贵的精神性。教育理性主要包括科学理性、人文理性和审美理性。教育理性一旦被消解，其功能发生变异或者丧失，就预示着人的精神危机的到来，人类就会处于非理性的存在状态。
一、教育的理性及其功能
人生之旅，永远在修行。修行的过程就是不断获得理性并坚守理性的过程。理性使人具有正确判断真假、善恶、美丑的能力，对理性的坚守使人自觉追求真善美，进而成为精神性的存在，成为真理性、道德性、诗意性的人。这个至关重要的理性作为一种判断能力和意志力，它的获得途径就是教育，因此可以称之为教育的理性。
教育理性的功能就是控制，它规范人们成长的方向和目标。 恶是人与生俱来的，没有后天的教育所带来的理性力量的控制，恶根就会生长壮大，开出“恶之花”。
请看生活中婴幼儿的表现：其母亲抱别的小朋友，他会以哭闹的方式来表示抗议，他天生以为其母亲属于他自己，只能抱他，不能抱别人。有时这种抗议表现得更为极端强烈，他甚至会抓掐对方、殴打对方，以维护自己的“权益”。几个幼儿在一起玩，经常发生矛盾，多半是因为争抢玩具。而争抢的原因并非玩具不够多，而是“先天”认为小伙伴正在玩的玩具是最好的，他也要玩那个玩具。
教育要传承关于自然和社会的经验知识（科学），使人认识事物，把握事物发展规律，概言之就是求真，培养人的科学理性。科学理性使人掌握自然、征服自然、改造自然。这个自然当然也包括人自己，“人是人的自然存在物”。
科学理性是教育实现控制功能的前提之一。 人具备科学理性，就能实现人的本质力量，最大限度地避免人的生存悲剧。人类产生和发展的过程，始终伴随着与大自然的博弈，博弈的基本目标就是生存，高级目标就是发展———确立人的主体性和主宰地位。而人参与博弈的资本就是科学理性。没有科学理性，人类就会丧失参与万物竞争并最终胜出的能力。而这种能力的获得要靠教育：经验的传承，技能的获得，思维的训练。因此，教育理性必须包含科学理性，教育内容、教育形式、教育逻辑概莫能外。
教育还要传承关于人自身的经验知识（人文），使人认识自己，把握人自身的发展规律，说白了就是求善，培养关于人的人文理性。 教育传承人文，培养人的人文素养，健全人性、提升人格，以教化自然人成为社会人，追求人生的价值，尽力避免人的价值悲剧———人可以赋予与人发生关系的一切事物以价值意义———避免人无意义的生死循环，抵制世间“祛魅”给人带来的虚空感，保持人生存发展和革新创造的原动力。人文精神使人生有了价值意义，缺少人文精神人生就是虚空的生老病死过程，人就与动物无异。**因此人生是修行，死亡是“毕业典礼”，但“毕业评语” 是大不相同的：或重于泰山，或轻于鸿毛；或流芳百世，或遗臭万年；或伟大，或平庸；或怀念，或遗忘。**这些评价是基于精神层面的，是人文的价值判断。
所以人文理性的功能就是规定人向上提升的方向，避免人向下堕落，规定人创造价值，避免虚空。 人的欲求就是创造价值，价值就是满足人的欲求，否则就无价值。当然，人的欲求既是物质的也是精神的，目的就是塑造完整、完美的自己。马克思主义经典作家说：人的一切行为的背后，都有利益作为驱动。这是千真万确的，否则人就失去创造的动力。然而，利益本身就是一种价值。所以，人文理性要解决的人生问题就是：超越苦难命运、混乱生活、无序人生的虚空的异化生存，建构有价值的充实的常态生活，避免异化生活带来的负面价值。人类追求美妙而浪漫的爱情，就是对动物物种繁衍行为的超越。人类不再是一男一女随意在一起的动物，而是要在茫茫人海中寻觅自己的另一半。性爱升华为情爱，必然是具有人文理性的人才能做到的。
教育更要传承人的审美经验和知识，培养人的想象力和感受力，即求美，培养人的审美理性。“ 人直接需要美，因此审美因素渗透到他的整个生活中，人不仅按照物质必然性，而且也按照美的规律进行创造。”生活事实正是如此，吃、穿、住、行都遵循美的规律：饮食不仅要求营养搭配科学合理，还要讲究色、香、味俱全；穿衣不只求避寒遮羞，还要色调搭配、款式适合，穿出气质和美感；住房不只是要求遮风挡雨，还要求舒适有品位；生活运动中不但要求秩序之美，还要追求凌乱中的自由自在。
审美活动就是要创造最大限度剔除各种限制自由舒适的空间（现实的和艺术的），让人处于自由舒适状态，形成完美人格。换言之，就是超越人的现实生活困境。现实中常见的生活困境就是人的异化：人们的行为，往往偏离事物（包括自己） 的本质，走向人的对立面，使人自己成为非我的存在、非常的存在，不独立、不自由的存在，成为非我力量的奴隶。即马克思说的：人的本质力量成为人的反对力量。借助网络语言来表述就是“房奴”“车奴” “孩奴” “手机控” “电脑控” 等，人在被“奴”、被“控”之中浪费时间、虚耗生命。所以审美理性的作用就是帮助人摆脱在现实生活中被“控”的不自由状态，达到诗意的栖居。
总之，教育是有控制功能的，理论上讲是教育使人具有理性，通俗来说就是教育使人具有教养和能力。教育的控制功能是通过科学理性、人文理性、审美理性实现的。 科学理性缺失，人就会丧失对真理的判断力，就会在谬误中受难；人文理性缺失，人就会失去对道义和爱的感受力，只能在仇恨与争斗中生存；审美理性缺失，人就会没有了对自由和美的感受力，就做不到诗意的栖居。
二、教育理性的消解
理性的力量很重要，但理性却不是万能的，事实是人的任何一种能力都是有限的。 教育作为人类的自觉活动，其理性也同样如此，并且还会不断被消解。当人类非理性的力量超过理性的力量时，理性的消解就发生了。法西斯主义就曾经消解了德国人的理性，把最富于理性的日耳曼民族推进战争轨道；美国“９·１１”事件也是非理性的恐怖主义的典型事例。
教育理性的消解，主要表现为真理性被伪理性替代，价值理性被实用理性所遮蔽。 先说伪理性对真理性的替代。请看下面的事例：文艺复兴时期，伽利略因害怕挨揍而在与罗马教廷的斗争中妥协了，其学生为他没有成为坚持真理的英雄而指责他，为他惋惜，并感叹“没有英雄的国家真不幸”。但伽利略说：“需要英雄的国家才不幸。”这是一个伪理性试图取代真理性的故事。显然，伽利略更具有真理判断力。因为妥协还是坚持只是一种态度，对真理无损，真理依然存在，不会改变———日心说仍然有其合理性，地球照样还是圆的，而不会变成方的。一个右派的妥协是这样的：“白纸黑字，这话当然是我说的，但是对是错，就等待历史评判吧。”这就是理性的智慧、智慧的理性，是在妥协中表现出的巨大的勇气和力量。
上述事例都是理性对非理性的胜利，但现实中同样有不少非理性消解理性的事例，造成许多非理性的存在。
１９５０年代末的“大跃进”及其“共产风、浮夸风” 就是非理性的历史存在。想用三五年就“超英赶美”，想一夜之间就跑步进入共产主义，生产上可以大放“卫星”———水稻亩产可达十万斤。这些匪夷所思的事情之所以发生，是集体丧失理性的狂热导致的。这种狂热源于一种非理性的观念———人有多大胆，地有多大产。这个观念又源于非理性的政治宣传需要，而政治宣传也是一种教育。所以归根结底是因为教育理性被消解。这种情况并非人们没有基本常识，而是政治对教育的强迫造成教育应有的真理性被伪理性取代了。
再说实用理性对价值理性的遮蔽。 教育的科学理性固然具有工具理性的特征，但不完全等同于工具理性，它还包含更为重要的科学精神，具有价值理性属性。而人文理性和审美理性实质上就是价值理性，是人的主体性的体现，对于人的修为更重要，正所谓“善比真重要，美比善重要”。中国本来有着伟大的人文和审美传统，但由于实用理性传统和现代物质主义的负面影响，教育的价值理性———科学精神、人文精神和审美精神常被遮蔽，而只剩下工具理性。教育理性被消解了，实用理性取代了价值理性。先秦时期的善恶之辩本没有辩出结果，但汉代”罢黜百家，独尊儒术”之后，孔孟之道的“性善论” 借助政治之力占了上风，中国成了假定“君子国”，这导致了人们对恶的忽视，没有深入剖析，只是简单否定，所以恶得以横行。假定人人都是君子的国度，变成了小人国，假定人人都是小人的国度，反而造就出大批的君子，这是早就被历史所证明了的“法乎善，取其恶”。
只肯定人性之善，不敢正视甚至故意隐瞒人性之恶，丧失对恶的批判能力，不能制定控制恶的制度，恶就会泛滥成灾。 这就是物质的实用理性取代了精神的价值理性，人们丧失价值判断力的恶果。为善言善，为恶言恶，效果往往不佳。一个对恶一无所知的人怎能很好地理解并接受善呢？没有科学精神，我们就永远停留在“知其然，不知其所以然”的层面上。 人文精神缺失，我们就永远是冷漠的看客———在“观看”农民工跳楼中增强自己的优越感，在别人的苦难中获得无聊的快意。没有审美理性，人们只体会到生活的艰难、工作的辛苦，不能领略生活、工作的快乐。
总之，在常态生活中，理和法的底线经常被突破，如官场的腐败万象，商场的贿赂成风、民众对求神拜佛的热衷、江湖义气对法律的挑衅，都是实用理性取代价值理性，理性被消解的非理性现象。这种突破具体影响到教育领域，就造成了教育的浮躁甚至是堕落：如“学而优则仕” 变为“仕而优则学”，官员、商人都成了大学教授、博士；“真的假文凭” 和“假的真文凭” 大肆泛滥；师生之间存在的种种不正当交易；等等。
三、教育功能的变异
人是万物的尺度，也是自己的尺度。教育的主体是人，人的主体性通过教育得以显现。从这个意义上讲，教育实际上是自我教育，人通过教育的控制功能实现对客观世界以及对自己的控制，使人作为人而存在。但是教育理性的消解必然带来教育功能的变异。具体表现就是科学理性变异为科学至上和技术中心主义，继而发展为物质主义。人文理性虽然在苦苦支撑，但掩盖不了节节败退的现实，诚信缺失、道德失范的事实谁又能视而不见？而诗意的审美理性则使自身陷入唯美主义泥淖，变得华而不实，成为人们用以回避现实的美丽鸵鸟，或者公开走向媚俗主义，成为丑恶的帮凶或导师。
科学理性使人得以控制自然之恶，让自然为人所用，为人的发展服务。但在这个过程中，人类也获得了征服自然和改造自然的满足感，从而产生了科学崇拜和物质崇拜，于是不自觉地踏上了科学至上和技术中心主义的迷途，以为科学可以解决一切，技术可以带来一切，人的物质欲望被激发了，人成为科学的工具、技术的载体、无限的物质欲望的追求者。科学家发现了核裂变后，人类掌握了核技术，但人类在和平利用核能的同时，也给人类自身制造了核威胁，核威胁成为高悬于人类头上的“达摩克利斯之剑”。医学只管最大限度地延长个体生命期限，却不顾自然生命体的生死极限，更不考虑一个垂危生命的尊严、价值和意义，有无必要再维持。在没有做好科学伦理方面的准备之前便盲目发展克隆技术，大量克隆濒临灭绝的物种和人类自己，我们将无法应对自然进化规律被破坏之后的混乱。还不清楚转基因食物是否有害，人们就大量生产和食用转基因食品，谁知道是否会因此而祸从天降？人类疯狂地消耗地球资源，肆无忌惮地破坏自然环境，地球已经面目全非，达到承受极限，以此为代价建立的现代文明，终有一天会轰然倒塌，人类终将自食恶果。物极必反，人类发展到最强大的时候，离自我毁灭也不远了，就如一朵花开到最艳之后就是凋谢。这就是科学理性变异的结果———科学理性应该是控制人类的疯狂的，但却反过来助长了这种疯狂。
人的自我意识使人不仅能打开身体的眼睛看世界，进而把握世界，还能闭上身体的眼睛，打开“心灵的眼睛”，认识自己，提升自己。这个过程就是要控制人的动物性和物质性，强化人的高贵的精神性。这是人文理性的价值所在，即以人文精神合理控制人的动物性的物质欲望。“人是有心者，人是用心者”，人若“无心”或“用心”失败（教育的失败），丧失精神性，就会陷入“创造物质—满足欲望—创造更多的物质—满足更大的物质欲望”的怪圈。当下的社会状况是“享受物质财富的现代人实际上也被物质所虏，在拥有物质的同时也被物质所拥有，沉溺于物质，被物质所包围，患上了严重的‘物欲症’”。你占有了手机，同时也被手机控制，你成了“手机控” “低头族”，就是这样。其实物质已经比较丰富的现代人的焦虑和压力大都来自于物质欲望的无限膨胀所导致的虚幻的不满足。房子越住越大，车子越换越好，票子越挣越多，但永不满足。正如一个网友所说的：我们正处在“一个不够”的时代———一部手机不够，一份薪水不够，一辆车子不够，一栋房子不够……我们对外面的世界过度需求，对每天的自己过度使用。“一” 不再是单纯的数字，而是一个欲求不满的代名词。虽然趋利避害、趋乐避苦是正常的人性，即人们常态的目标和方向，但仅是为了满足人性深处的劣根性导致的炫耀心理而过度追求财富就是一种病态，因为炫耀性消费始终是虚假性消费，是一种浪费资源的异化消费。攀比、跟风和盲从都是价值理性缺乏所导致的人的劣根性的外在表现。“甘于受生命必然性、生命压力的驱使，安于生命本能，忘记或懒于超越生命现状，只是疯狂地追求财富、疯狂消费，结果是除了将生命的躯壳打扮得光鲜亮丽外，就剩下极度的空虚和无聊的虚荣以及别人无益的羡慕与赞赏。而这些并非生命必然的消费需求竟是伪消费伪需求。”生活中的“购物狂”就是实例：用不上也购买一大堆，这些东西最后只能变成污染环境的垃圾。此时最需要人们具有价值判断力，需要人文精神和审美精神发挥作用———人们需要明白什么东西对自己有价值，什么是自己需要的，什么样的生活是自己向往的诗意生活。不明白就无法选择。但价值理性在哪里呢？西哲说“适度的物质贫困有利于人们思想”，反过来说就是“过度的物质富裕不利于人们思想”，人的价值理性就这样在过度的物质消费中变异了。人的独立自由变成了人身依附或“圈子里的人”，爱情变成了青春肉体的待价而沽，生命的尊严演变为除夕夜的灭门惨案，财富的获得靠权力寻租或商场的尔虞我诈。生活的诗意被生活的焦虑和压力取代，被华而不实的唯美主义所粉饰，被低俗、庸俗、恶俗的媚俗主义所装扮。不接地气的唯美和以俗为美，都是以丑为美。这就是价值理性功能变异的结果。
教育理性是以整体理性的方式实现控制功能的。但是由于科学教育、人文教育、审美教育的分离与偏颇，以及实用理性和物质主义的影响，教育的整体理性一定程度上被消解，教育理性的控制功能发生变异，教育就只是把人变成技能的载体———工具。这样的教育造就了现实中非理性的荒诞存在：在正义的名义下掠夺，在真理的光环下欺骗，在发展的借口下破坏，在对幸福的追求中异化（丧失自由）。因此，教育理性的回归、教育功能的恢复，应该是教育改革发展应注意的问题。
引用 教育的批判：基于常识的教育生态反思 - 王光斌, 戴艳著 - Google 图书
人的成长过程就是控制兽性、保持人性、追求神性_腾讯新闻</content></entry><entry><title>1991年苏联解体的历史教训</title><url>https://lizj3624.github.io/post/soviet-union/</url><categories><category>苏联解体</category><category>历史</category><category>video</category></categories><tags><tag>苏联解体</tag><tag>历史</tag><tag>video</tag></tags><content type="html"> 1991年貌似强大的苏联轰然倒塌，苏共下台，当年央视专门播放节目，分析苏联解体的原因，我们了解一下，居安思危，学习历史可以知兴替。
0：0：0 序言 5:05 第一集 苏共兴衰的历史轨迹 39:05 第二集 苏共的基本理论及指导方针 1:08:40 第三集 苏共的意识形态工作 1:28:08 第四集 苏共的党风 1:52:25 第五集 苏共的特权阶层 2:17:10 第六集 苏共的组织路线 2:46:15 第七集 苏共的领导集团 3:22:42 第八集 苏共对西方世界西化、分化战略的应对</content></entry><entry><title>粉单市场</title><url>https://lizj3624.github.io/post/pink-sheet/</url><categories><category>美股</category><category>粉单市场</category></categories><tags><tag>美股</tag><tag>粉单市场</tag></tags><content type="html"> 滴滴从美股退市后进入粉单市场，下面科普一下什么是粉单市场；进入粉单市场后，对拥有滴滴股票的投资者有什么影响。
粉单市场原名National Quotation Bureau，简称NQB(全国报价局)，它既不是在SEC注册的股票交易所，也不是NASDAQ系统的OTC，而是隶属于一家独立的私人机构 (Pinksheets LLC)， 有自己独立的自动报价系统―OTCQX。发展历程1913年在1913年成立，为一私人企业，因最初是把报价印刷在粉红色的单子上而得名。
发展历程 1963年：1963年NQB被出版业大财团买下，使得NQB仍以印刷的方式出书寄提供信息。
1997年：1997年NQB更换新经营团队，以电子揭示看板的新技术提供客 户柜台买卖中心的交易信息。
2000年：2000年6月，NQB改名Pink Sheets LLC(Liability Limited Company)。
今天的粉单交易市场，已纳入纳斯达克最底层的一级报价系统，是美国柜台交易(OTC)的初级报价形式。
广义的美国OTC市场包括NASDAQ、OTCBB和粉单市场，按其上市报价要求高低依次为：NASDAQ===> OTCBB ===>粉单。
结构特点 粉单市场的功能就是为那些选择不在美国证券交易所或NASDAQ挂牌上市、或者不满足挂牌上市条件的股票提供交易流通的报价服务。 在粉单市场报价的是那些"未上市证券(Unlisted Securities)"，具体包括：
由于已经不再满足上市标准而从NASDAQ股票市场或者从交易所退市的证券。
为避免成为"报告公司"而从OTCBB退到粉红单市场的证券。
其它的至少有一家做市商愿意为其报价的证券。
在美国证券交易实务中，粉单市场里交易的股票，大多是因公司本身无法定期提出财务报告或重大事项报告，而被强制下市或下柜。 因此，投资人通常称这种公司为"空头"或"空壳"公司，该类股票为“垃圾股票”。上市没有特别要求，而且粉单市场没有连续公布财务等信息的要求。 值得一提的是公司在粉单市场交易是不需要交费的。
监督制度 粉红单市场不是一个股票交易所，它不受证券监管当局的监管，只要每天交易结束时公布挂牌公司的报价即可。 但是NASD监管当局(NASDR)和SEC会对粉红单市场和黄单市场上证券的所有做市商进行严格的监管。
建立规范做市商行为的规则以管制做市商的商业行为。
为证券从业人员建立资格标准。
随时检查会员的财务及经营状况，以及是否违反相关规则和条例。
调查证券的违规行为。
用相关法律约束处罚违规者。
对投资者和投诉予以回应等等。
由上可知，因为粉红单市场上市报价的条件要求很低，在这个市场上报价的许多证券都是Penny Stock(仙股)，且资料不全，信息披露不及时，投资风险很大， 即为聪明的消息灵通的投资者提供了巨大的投资机会，又潜藏着极大的投资风险。粉红单市场上主要是那些喜欢冒险的激进投资者及风险投资人。
进入粉单市场影响 在粉单市场上，股票代码后缀是"Y"，代表存托凭证ADR，不是普通股票，比如腾讯ADR的代码是TCEHY，瑞幸咖啡退市前，在纳斯达克的代码是LK，现在在粉单市场上，代码也改为了LKNCY, 滴滴进入粉单市场后股票代码变成DIDIY。 在粉单市场上的投资，常常具有投机性，这也是为什么美国监管部门警告投资者，如果要投资这一市场，必须对所投资的标的进行深入全面的调研。
目前来看进入粉单市场还可以交易，不过交易应该不如纳斯达克或者纽交所方便，不能理解退市进入粉单市场就归零。
以后就看滴滴退市后满足证监会的审查要求，APP等上架，合规运营，重新上市后如何处理粉单市场的股票
引用 粉单市场（pink sheet）是什么概念？
瑞幸暴涨近50%！一文读懂：美股粉单市场到底是什么？</content></entry><entry><title>桥水基金瑞.达利欧-经济机器是怎样运行的</title><url>https://lizj3624.github.io/post/enc-m/</url><categories><category>宏观经济</category><category>video</category></categories><tags><tag>宏观经济</tag><tag>video</tag></tags><content type="html"> 桥水基金瑞.达利欧讲解宏观经济是如何运行的 视频讲解的宏观经济比较言简意赅，图文并茂，非常适合普罗大众了解宏观经济的运行方式。</content></entry><entry><title>kubernetes中配置管理ConfigMap</title><url>https://lizj3624.github.io/post/k8s-configmap/</url><categories><category>kubernetes</category><category>cloudnative</category><category>configMap</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>configMap</tag></tags><content type="html"> CongfigMap ConfigMap对象用于为容器中的应用提供配置文件等信息，它们将相应的配置信息保存于对象中，而后在Pod资源上以存储卷的形式挂载并获取相关的配置，以实现配置与镜像文件的解耦。 例如为Tomcat的JVM配置堆内存大小等，在容器中启动时，我们可以向容器命令传递参数，将定义好的配置文件嵌入镜像文件中、通过环境变量(Environment Variables)传递配置数据，以及基于Docker卷传送配置文件等。
创建ConfigMap ConfigMap的配置样例myconfig.yaml
apiVersion:v1kind:ConfigMapmetadata:name:game-demodata:# 类属性键；每一个键都映射到一个简单的值player_initial_lives:"3"ui_properties_file_name:"user-interface.properties"# 类文件键game.properties:|enemy.types=aliens,monsters player.maximum-lives=5 user-interface.properties:|color.good=purple color.bad=yellow allow.textmode=true通过命令创建kubectl create myconfig.yaml
Pod中使用ConfigMap 可以使用四种方式来使用ConfigMap配置Pod中的容器：
在容器命令和参数内 容器的环境变量 在只读卷里面添加一个文件，让应用来读取 编写代码在Pod中运行，使用Kubernetes API来读取ConfigMap 下面是一个Pod的示例，它通过使用game-demo中的值来配置一个Pod：
apiVersion:v1kind:Podmetadata:name:configmap-demo-podspec:containers:- name:demoimage:alpinecommand:["sleep","3600"]env:# 定义环境变量- name:PLAYER_INITIAL_LIVES# 请注意这里和 ConfigMap 中的键名是不一样的valueFrom:configMapKeyRef:name:game-demo # 这个值来自 ConfigMapkey:player_initial_lives# 需要取值的键- name:UI_PROPERTIES_FILE_NAMEvalueFrom:configMapKeyRef:name:game-demokey:ui_properties_file_namevolumeMounts:- name:configmountPath:"/config"readOnly:truevolumes:# 你可以在 Pod 级别设置卷，然后将其挂载到 Pod 内的容器中- name:configconfigMap:# 提供你想要挂载的 ConfigMap 的名字name:game-demo# 来自 ConfigMap 的一组键，将被创建为文件items:- key:"game.properties"path:"game.properties"- key:"user-interface.properties"path:"user-interface.properties"引用 ConfigMap
Kubernetes之ConfigMap详解及实践</content></entry><entry><title>SaaS公司估值的锚</title><url>https://lizj3624.github.io/post/saas-value/</url><categories><category>SaaS估值</category><category>科技股</category></categories><tags><tag>SaaS估值</tag><tag>科技股</tag></tags><content type="html"> 这篇讲解的《SaaS公司估值的锚》非常不错，介绍一种SaaS估值的方法，基于SaaS Capital编造的SaaS指数，在此上基础根据ARR增速，市场天花板，金额续费率，获客效率，毛利率等方面，适当调整指数的系数得出估值倍数，公司估值=ARR * 4 * 倍数。本文转自宽带资本公众号的《SaaS公司估值的锚》
估值定量模型 美股二级市场对于SaaS有相对成熟的估值方法，一般按照EV/NTM Revenue的倍数来估值。这里的NTM revenue就是未来12个月的收入预测（next twelve month revenue），会采用投行的一致性预测或者投资者对于业务增长的预期。而EV=公司市值+总负债-现金（SaaS公司的市值，也就是股权价值和EV差距不大，不考虑优先股和其他）；所以给定估值倍数就可以算出上市SaaS公司的市值。二级市场的历史估值倍数可以看下图。
上市SaaS公司EV/NTM revenue multiple中位数
▲ 注：Meritech Capital编制，含04年Salesforce上市后的近60家SaaS公司
因为一级市场的好公司绝大部分都以上市为目标，二级市场的估值方法是一级市场最重要的参考。那如何把二级市场的估值方法与一级市场挂钩呢？
第一步要做的就是统一收入的口径，因为NTM revenue这个预测性数据并不是那么容易获得。
美国的一家融资&amp;研究机构SaaS Capital，总结了一个定量的SaaS估值公式：EV=ARR*估值倍数(t)。这里的ARR用Annual Run Rate来替代Annual Recurring Revenue，比如某SaaS公司Q4的确认收入是1000万美元，那Annual Run Rate=4000万美元，这个数值实际上跟Annual Recurring Revenue是比较接近的。
之所以用这个数，是因为上市SaaS公司并不披露Annual Recurring Revenue，但是会披露季度收入，所以可以用季度收入来计算annual run rate，从而把一级市场和二级市场的估值体系打通，我们认为这是一种可以参考的估值方法。
那估值倍数(t)如何确定呢？SaaS Capital认为应该主要考察以下指标，并根据各指标的行业benchmark来调整。
当前上市公司的倍数和非上市公司折价 上市公司的倍数是公开可计算的（SaaS Capital会定期更新），2020年3月31日上市公司的ARR（注意这里和下面的ARR都是annual run rate，是近似的annual recurring revenue）倍数是8.2。
在这个基础上，非上市公司因为流动性和风险等因素，需要进行折价。根据SaaS Capital服务过的上百家公司案例，平均的折价是28%，也就是说当前非上市公司的估值倍数基准是8.2*0.72=5.9倍。
ARR规模和ARR同比增速 增速越快，给的估值倍数越高，这是大家都可以接受的。但在规模小的时候，做到高速增长比规模大的时候容易得多；并且，到底多快算快呢？这个问题就涉及到和规模类似的SaaS公司对比，这个数据在国内是非常难以获得的。好在国外也有几个研究机构（SaaS Capital，KBCM，OpenView等），每年都会对数百家非上市SaaS公司做全面的调研，形成SaaS benchmark报告免费发布。
所以从这个指标开始，需要引入另一份研究报告，OpenView 2019 Expansion SaaS Benchmarks，作为各个指标评估和赋值的基础。另外，2018年和2019年美股市场有26家SaaS公司上市（另有Qualtrics和Adaptive Insights在提交招股书后和正式发行前，分别被SAP和Workday被收购了），这些公司的指标也是非常有参考意义的，因为如果目标是美股上市，早晚需要和已上市的SaaS公司们做最直接的对比，所以在后面的分析中每个指标也选取了这28家公司在IPO时点的数值作为参考。
市场的天花板（Total Addressable Market） 这是一个主观性很大的评估，由于TAM不像其他指标是实实在在的经营结果，并且估算TAM的过程也很主观。SaaS Capital认为TAM不构成一个加分项，只有在TAM很小的时候构成一个减分项。关于TAM后面展开分析，简单说，低于10亿美元天花板就是个减分项。
金额续约率 SaaS商业模式优于传统软件的核心在于收入的可预期性和客户生命周期中的累积效应。我们做过一个20年的DCF模型，分别测算65%-110%金额续费率对应的企业价值，差距是非常大的。作为对照，在其他指标都正常的情况下，金额续费率对于企业价值的撬动是最大的。
获客效率 获客效率是增长效率的指标。获客效率国内一般会采用LTV/CAC指标，但如果金额续费率超过100%，这个公式就失效了。其他衡量销售效率的指标有：Magic Number、CAC Ratio、CAC Payback period，实际上这几个指标内涵接近。都是围绕营销费用与ARR新增的关系，是更加通用的获客效率指标。
毛利率和收入结构 毛利率反映的是收入的质量，如果低于一定的比例就是一个减分项。美股上市公司的整体毛利率是75%左右。如果一个公司有SaaS和非SaaS两部分业务，其中非SaaS业务的部分过高，就应该分开估值，而不能全部按照SaaS来估值。
估值方法的总结 如下图所示，2020年3月31日上市公司的估值倍数是8.2倍的ARR。2009年5月，最低值为1.5倍，18年中达到了历史最高的11.4倍，历史中位数是7倍。整体波动是非常大的。
▲ *注：*SaaS Capital编制，含48家SaaS公司，不包括收入结构、毛利率、客单价超出正常范围的SaaS公司
美国SaaS公司的benchmark 公司规模和增速 根据OpenView的报告，非上市公司随着规模增大，增速会先短暂上升，然后持续下降。具体估值的时候，可以根据所评估的SaaS公司当前时点ARR规模，对号入座，看ARR增速是在哪个分位。一般认为增速每超过平均增速的100%，就可以获得50%的溢价。比如一家2500万美元ARR的公司，如果YoY增速达到100%，那增速这一条就可以获得0.5*（100%/40%-1）=0.75倍溢价，也就是估值倍数可以调整为5.9+5.9*0.75=10.33倍。
▲ Source: OpenView 2019 Expansion SaaS Benchmarks
2018年和2019年上市的28家SaaS公司，中位数的ARR是2.08亿美元。中位数的YoY增速是38.5%。可以说是在非常大的体量下保持着高速的成长。
▲ Source: Company S-1, Meritech Capital
市场天花板 SaaS公司的招股书（S-1）会在Market Opportunity一节中，分析自己的市场空间（Total addressable market，TAM）。一般会根据自己的产品对应的市场，援引IDC、Gartner等咨询机构的分析报告，或者以自己的ACV乘以潜在客户数来计算。18和19年上市的SaaS公司，中位数TAM是250亿美元。
值得注意的是，到上市的规模，SaaS公司都会有多条产品线产生收入，每个产品线可以对应不同的市场，这样SaaS公司的TAM就合理地被撑大了。以下是CrowdStrike和Datadog对于自己潜在市场空间的分析。
CrowdStrike的分析
DataDog的分析
▲ Sourc**e: Company S-1, Meritech Capital
那么到美股上市的SaaS公司市场空间最小需要多大呢？可以简单做一个算术题，假设公司IPO时有1亿美元收入，需要在此基础上保持25%的增长率5年，5年后公司的收入大约是3亿美元。假设公司占据30%的市场份额，那TAM必须在10亿美元以上。可以说TAM过小，是国内绝大部分SaaS公司的最大痛点。但是TAM是动态的，市场会成长，公司的产品线也可以扩大，也可以并购扩张。2004年Salesforce IPO的时候，招股书分析认为CRM市场的TAM是71亿美元，而2019年 Salesforce的年收入是171亿美元，并且还在高速成长。
金额续费率 金额续费率是一个非常核心的数值。我们认为，金额续约率很大程度上决定了一家公司的上限。美国市场SaaS公司的金额续费率是非常优秀的，各个规模的非上市公司的中位数金额续约率都在100%左右，25分位的最低为82%。
▲ Sourc**e: OpenView 2019 Expansion SaaS Benchmarks
而上市公司的中位数为119.5%，最低的金额续约率为Dropbox的90%，最高的Pivotal达到了158%，超过130%有9家。如何实现如此的高的金额续费率，非常值得所有SaaS市场的参与者做单独做深入的研究。
▲ Sourc**e: Company S-1, Meritech Capital
获客效率 获客效率，除了大家都知道的LTV/CAC之外，还有以下两个指标：
CAC Ratio的本质是每投入一块钱的销售费用，在下季度产生的净新增ARR。而CAC payback Period是投入的一块钱销售费用，需要多少个月的回本。简单地理解，CAC ratio越高，CAC Payback Period越短，获客的效率越高。对于创业者来说，如果CAC Payback Period非常优秀，那就是继续增加销售投入的信号。如果CAC payback period过于长，那可能就需要评估销售策略或者团队。一般认为CAC Payback Period小于12个月就是优秀的数字。（做SMB和enterprise的又有一些差别）
▲ Sourc**e: OpenView 2019 Expansion SaaS Benchmarks
不过，需要注意一下，OpenView在自己的报告里认为被调查的公司在“under-report”自己的获客效率。一般随着收入规模的增长，获客效率会先提高再下降。
▲ Sour**ce: Company S-1, Meritech Capital
上市公司因为收入大，客单价高，中位数的CAC Payback Period在27个月。
毛利率 毛利率反映的是收入的质量。SaaS公司的收入中，可能有一部分是非订阅模式的，订阅模式的比例很重要。OpenView的survey中，非上市公司的订阅收入的占比在90%左右，优秀的公司订阅模式的比例达到了100%。IPO公司的部分，订阅收入占比为92%。IPO的SaaS公司的整体毛利率中位数在73.5%，最优秀的公司可以实现80%以上的毛利率。这里需要注意的是，SaaS Capital认为非订阅模式的比例一般不超过20%，如果超过20%就需要用分部估值法。
▲ Sou**rce: OpenView 2019 Expansion SaaS Benchmarks
▲ Source: Company S-1, Meritech Capital
▲ Sour**ce: Company S-1, Meritech Capital
综合以上的数值，SaaS Capital给了2个案例。
结合案例总结 ❶ 上市SaaS公司的估值倍数是在不断变化的，融资时点很重要。
❷ 这个估值的方法，在具体调整估值倍数的时候，仍然存在比较大的主观性。比如案例1给的growth rate溢价，并没有按照每100%增速倍数，给予50%估值溢价的公式，而是比这个值（50%*(230%/40%-1)=8.8）低一些。
❸ 其他指标在决定估值倍数的影响相对要小于growth rate。但是在给估值之前，在更重要的投与不投的这个决策中，其他指标是一样重要的。比如市场空间很小，毛利率很低，金额续费率很低，都可能是个否决项。毕竟美股上市公司的数据摆在那里，如果核心指标低于上市公司太多，即使上了市，市场的热情也要打很大的折扣。
❹ 这个定量估值的模型，提供了一种看待估值的锚，也就是在讨价还价的过程中，可以有一个值得参考的估值。看看到底是贵了还是便宜了，偏差的幅度是多少。同样重要的是，这个计算的过程，提供了一种相对全面的、结构化地评估SaaS公司的思路。再结合上市公司和调研报告的benchmark，创业者和投资者可以更好地理解自己所处的位置。
❺ 一个“典型”的美股SaaS公司IPO时大约有2亿美元ARR，38.5%的增速，120%的金额续费率，各条产品线所在市场的TAM之和为250亿美元，综合毛利率73.5%，订阅收入占比92%
中国SaaS行业的一些观察 SaaS市场空间 IDC的数据显示中国的企业IT支出在2018年为880亿美元，占GDP的比例为0.66%，低于美国和英国（4%，3.7%），日本和德国（2.1%，2.2%），韩国（1.1%），甚至低于印度（0.8%）。
另外，中国企业IT支出中的软件比例偏低，约为20%。即企业软件市场的规模约176亿美元，而2018年SaaS市场为21亿美元，可以算出中国SaaS在软件市场的渗透率约为12%。2019年中国的SaaS市场规模为30亿美元，同比增长41%。作为对比，2018年美国的企业IT支出为8300亿美元，其中软件的比例约为35%，软件市场为2900亿美元，假设SaaS的渗透率为25%（这个渗透率有不同的说法），则美国SaaS市场规模达到了725亿美元。根据Gartner的报告，2019年全球企业软件市场的规模大约为4570亿美元，其中SaaS的市场规模为1000亿美元。
也就是说，静态地看，虽然中国的GDP达到了美国的近70%，中国企业IT支出只有美国的10.6%，软件支出为美国的6.1%，SaaS支出仅为美国的2.9%。所以中国SaaS的规模还在非常小和早期的阶段。但在美股上市的要求是一样的，所以这些年没有纯粹意义的SaaS公司在美国上市是非常正常的。
但是中国的整体增速肯定又是快于美国的。那么10年之后，我们会处于一个什么样的位置呢？我们做了一个很简单的测算。
中国SaaS市场的规模是由GDP的增长，企业IT支出占GDP的比例，企业软件占企业IT的支出比例，SaaS占企业软件的比例决定的。
假设到2030，中国的GDP能够保持5%的复合增长，达到25万亿美元，企业IT支出的比例为1.2%，软件占企业IT支出比例达到30%，SaaS占企业软件的比例达到25%，那么中国SaaS市场到2030年的规模可以到234亿美元（大约相当于2011年全球SaaS市场的规模），这里面就有接近8倍的市场空间。
未来10年，在中国行业数字化、云化的趋势下，对于这个测算结果的可实现性值得保持乐观。在234亿美元的市场下，相信会有一大批可以实现标准美股IPO的SaaS公司。从投资timing看，现在大概真的到了一个好的投资SaaS时间点。
软件创业模式的选择 我们认为，好的SaaS产品提供了一种双赢的商业模式，即客户获得更好的产品和服务，软件公司获得更高的总LTV。但这里面有一些前提，最核心的需要有足够的TAM，足够的金额续费率。
现阶段中国的国情是，IT预算占比大的很多行业（大部分是国有企业），往往因为安全性和采购习惯问题，不接受SaaS的模式。对于软件创业者来说，如果选择只做SaaS，往往意味着做不了银行、运营商等优质客户，市场规模立马小了1个数量级，就很难做到上市的规模了。并且由于缺少这些大型的优质客户，金额续费率指标也难以达到100%，因为小客户会有相当大的自然死亡率，也很难有多产品扩展的空间。
反观美国，SaaS公司完全可以做所有行业的美国财富1000强的客户。所以在现在这个时点，软件公司创业完全是可以继续做On-Premise的，On-Premise作为中国软件市场的主流，仍然会持续很长时间。退一步说，只要软件产品做好标准化、做出足够的竞争优势，在未来软件云化的时代，也可以学习国外的微软、Adobe，国内的广联达去做云化转型。
产品方向选择和增长方式 在中国SaaS市场相对比较局限的空间里，我们发现过去几年发展起来的中国SaaS公司，很多是在美国是没有清晰对标的。这些公司的企业家往往根据自己的洞察和技术能力，创造了远远强于现有解决方案的产品或者发掘了原本不存在的全新市场，扎进去并做到了相当大的规模，我们把这个能力叫做定义赛道的能力。我们看到的酷家乐、聚水潭、乐言、云帐房等SaaS公司就是代表。
另外，美国软件公司往往通过扩张软件产品线来实现成长，这在中国并不容易。中国SaaS公司努力拓展SaaS+，也是打破天花板的一种方式。SaaS+广告，SaaS+交易在国内都有不错的先例。由于国内各行业的整体交易关系并不稳定，产业的变化很快，通过SaaS产品切入做交易，或许可以实现改变整个产业链的结果。
资本市场选择 前面分析美股IPO SaaS公司的数据，可以发现在美股上市的门槛是相当高的（想象一下做到1亿美元ARR并保持25%以上增速的难度）。但是中国的SaaS公司其实是可以走国内资本市场退出的，做到中等规模，实现一定的利润A股上市，可能会比瞄准美股上市更现实。而且A股给予软件公司的溢价是相当高的，40-60倍左右的PE是非常正常的倍数，流动性也很好。所以建议SaaS公司测算一下，自己在什么情况下可以盈利。今年刚上市的电商SaaS光云科技就是例子：2019年营业收入4.65亿，净利润9600万，最新市值（5月15日）冲到了231亿。
最后，即使短期内存在这样的问题，我们依然坚信中国SaaS市场是面向未来的，是有足够的潜力的。我们的信心来自于中国经济的发展，劳动生产率的提高，各行业的数字化转型以及新技术的不断落地，更重要的是来自于中国企业家们强大的远见、创造力和执行力。相信在不久的将来中国的企业软件市场和SaaS市场，会和消费互联网那样水大鱼大。
引用 The SaaS Capital Index
What&rsquo;s Your SaaS Company Worth?
2019 EXPANSION SAAS BENCHMARKS
2018 Review: High-growth SaaS IPOs
2019 Review: High-growth SaaS IPOs
How China’s Cloud Market Differs from Others
Gartner Says Global IT Spending to Grow 3.7% in 2020
Gartner Forecasts Worldwide Public Cloud Revenue to Grow 17.5 Percent in 2019
云悦资本SaaS与产业互联网系列深度研究合集（11篇）：技术篇、商业模式篇、战略篇、估值篇、投资逻辑篇
海外SAAS行业深度报告（一）
SaaS 通识系列 6：SaaS 常用指标</content></entry><entry><title>Linux下的cordump设置和使用</title><url>https://lizj3624.github.io/post/cordump/</url><categories><category>Linux</category><category>coredump</category></categories><tags><tag>Linux</tag><tag>coredump</tag></tags><content type="html"> coredump是进程崩溃前的快照，对程序员定位问题非常有用，再次记录一下coredump的设置和使用。
设置coredump # 1. 设置core_uses_pid echo "1" > /proc/sys/kernel/core_uses_pid # 2. 设置core_pattern, 进程所属用户必须有目录权限 echo "/myservers/srv/bin/core-%e-%p-%t" > /proc/sys/kernel/core_pattern # 3. 设置ulimt echo "ulimit -c unlimited" >> /etc/profile &amp;&amp; source /etc/profile # 4. 重启服务 使用coredump gdb + 可执行文件名 + coredump文件 即可开始调试coredump文件, 通过b定位段点。
手工产生coredump gcore $pid
gdb generate-core-file</content></entry><entry><title>美国股市百年跌荡启示录</title><url>https://lizj3624.github.io/post/us-stock-history/</url><categories><category>美股</category><category>历史</category></categories><tags><tag>美股</tag><tag>历史</tag></tags><content type="html"> 读史可以明智，对于投资美股的人来说，很有必要了解美股历史上的几次大崩溃， 了解每次崩溃的前因后果，让自己逃离崩盘，保护美股收益，并可以抄底一些优质股票。
由于担心疫情重创美国经济，美股纳值从2020年2月19号的高点(9839)暴跌到3月23号的6631点， 短短的20几天跌幅达33%。美联储通过印钞和"开开飞机撒钱"的方式拯救美国经济，在这宽松 的刺激下，美股一路走高，2021年11月22号美股迎来历史的高点(16212)，由于宽松的政策， 引发了高通胀，美联储加息的预期越来越迫切，美股一路下跌，截止到2022.5.29号，美联储 加息两次(3.16号加息25个基点到0.25%至0.5%的水平，5.4号加息50个基点到0.75%至1.00%)， 再叠加大宗商品上涨，俄乌冲突，导致美股在5.20号跌到11035点，相对于高点已跌了32%。 一些科技成长股跌幅到70~80%，真是损失惨重。 下面是读《崩溃与救援：美国股市百年跌荡启示录》记录的一下崩溃的前后信息，期望以前帮助 自己再以后辨别股市崩溃。
1907年的大恐慌 就像每一次现代股市崩盘都有一支外部催化剂一样，每一次崩盘都是由一种新式的、鲜为人知的金融创新模式推动的， 它将举债经营模式引入了一个已经不稳定的体系中。1907年的状况就是信托公司实际上没有受到监管，是“海盗式”的。 除了绝对缺乏准备金，许多抵押给信托公司的抵押品也缺乏流通性，无法大批出售用来偿还贷款。 清算那些未开垦的土地可能需要几个月的时间，即使可以缩短时间，也会损失惨重。这就解释了为什么银行被禁止拥有土地， 除非是通过行使止赎权取得的。为工业组合提供过渡性贷款而购买的设施和机器，在企业以外不使用的地方毫无价值， 即使确实有价值，在贷款得到满足之前，也可能需要几个月的时间来出售和重新安置。与所有导致现代股市崩盘的金融交易一样， 信托公司在阳光明媚的时候可以运转良好，可一旦乌云密布，大风四起，信托公司就无法放下船帆。 与此相反，它们扎根于内部的无节制结构一旦有风吹草动，缺点就会暴露无遗。
杠杆式投机意味着股价下跌1美元会给举债的股东带来2美元的损失。这些损失可能会迫使投资者出售， 让股价再降3美元，对其余举债持股者造成6美元的损失。随后会有些人被迫出售股票，将价格再压低9美元， 使其余股东蒙受更大损失，他们当中一些人则会以任何价格继续被迫出售。
但是杠杆式投机并不都是金融的，它也很可能是行为的。一个储户知道信托公司能够支付更高的利息，因为它们的存款准备金较少， 而流动性资产更多，他可能会要求信托公司返还存款的投资收益，并警告朋友们也这样做。
尽管如此，在10月21日这天，1907年的“恐慌”仍然到来了。股市在前一周已经下跌了5.9%，整个1907 年已下跌35.5%，情况变得越来越糟糕。
纽约证券交易所于10月24日，也就是周四那天按时关闭。道琼斯指数收盘时几乎在58.18点呈持平状态，远高于当天的低点，但整个1907年仍下跌了38.3%，10月份则下跌了14.1%。
人们的担忧仍在继续，道琼斯指数显示股市疲软的状况依旧，11月15日，道琼斯指数触底，收于53.00 点，下跌了43.8%，比1906年的最高点下降了50%，这个低点一直延续到年末。 截至1907年12月31日，1907 年最后一个交易日收盘时，道琼斯平均工业指数已经下跌了37.7%，是1931年以前的最差业绩，也是股市损失排名第二的时期。
1927年大崩溃和大萧条 前因 美国经历了"咆哮的二十年"，积累了大量的财富，黄金存储最多。
道琼指数从1921的75点上涨至1929年的381点，涨幅到406%。
美联储宽松的政策
后果 10月28日星期一，这是美国股市有史以来最糟糕的一天。10月29日周二是第二倒霉的日子。 许多人表示，鉴于交易量更大， 对市场造成的危害会是长期的。1987年10月19日之前，这两天的纪录没有被超越过。道琼斯指数的跌幅曾达到27.1%， 到了1929年底收盘时下跌了17.2%。
道琼斯指数于1929年9月3日收于381.17点，于1932年7月8日收于41.22点。直到1954年11月23日，才再次创下历史新高。
1987年黑色星期一 1987年10月19日星期一，道琼斯指数下降了508点，跌幅22.6%。
2008年金融风暴 2008年11月12日，道琼斯指数下跌了411.30点，收于8282.66点，当年已下跌37.6%。 2008年11月19日，当天，道琼斯指数下跌427.47点，次日又下跌444.99点，收于7552.29点。道琼斯指数当年已下跌43.1%，只比1931年的情况好一些。 道琼斯指数已经回吐了自2003年3月12日以来的所有涨幅。标准普尔500指数甚至更糟糕，收于752.44 点，为1997年4月以来的最低水平。 2008年11月，美国已经失去了55.3万个工作岗位，而截至当年11月，已经失去了190万个工作岗位，这一数字最终或许将会超过200万。 2008年结束时，道琼斯指数收于8776.39点，全年下跌了33.8%。 道琼斯指数在2009年3月9日最终收于6547.05点，比2007年创下的历史高点下跌53.8%。
2010年闪电风暴 相关 崩溃与救援：美国股市百年跌荡启示录
李奇霖：回望1929
李奇霖：美股暴跌的启示
从繁荣疯狂到资本寒冬，美国大萧条最完整的形成和破灭
复盘美股十次熊市，进入熊市的必要条件是什么？</content></entry><entry><title>Kubernetes中Deployment DaemonSet StatefulSet</title><url>https://lizj3624.github.io/post/kubernetes-deploy/</url><categories><category>kubernetes</category><category>cloudnative</category><category>deployment</category><category>daemonset</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>deployment</tag><tag>daemonset</tag></tags><content type="html"> kubernetes集群有几种部署和管理POD的工具，下面简单介绍一下。
ReplicaSet ReplicaSet是支持基于集合的标签选择器的下一代Replication Controller(新版本已不再使用)， 它主要用作Deployment协调创建、删除和更新Pod，和Replication Controller唯一的区别是，ReplicaSet支持标签选择器。 在实际应用中，虽然ReplicaSet可以单独使用，但是一般建议使用Deployment来自动管理ReplicaSet， 除非自定义的Pod不需要更新或有其他编排等。
## 查看RellicaSet资源 $ kubectl get rs Deployment 根据声明的YAML文件信息部署POD，并将POD调度到资源占用少的node节点上，会调用ReplicaSet管理POD副本。 主要适合如下场景：
部署无状态应用 管理Pod和ReplicaSet 部署，滚动升级 弹性扩容等 看一下kubernetes官方提供deployment yaml资源文件 apiVersion: apps/v1 kind: Deployment ## 资源类型 metadata: name: nginx-deployment ## 名称 labels: app: nginx ##标签 spec: replicas: 3 ## 副本数量 selector: matchLabels: app: nginx ## deployment根据这个标签，选择管理POD template: metadata: labels: app: nginx ## Pod的标签，跟selector保持一致 spec: containers: - name: nginx ## 容器镜像 image: nginx:1.14.2 ## 镜像版本 ports: - containerPort: 80 ## 容器的端口 DaemonSet DaemonSet(守护进程集)和守护进程类似，它在符合匹配条件的kubernetes集群的node节点上均部署一个Pod。 DaemonSet的场景:
集群存储守护程序，如glusterd、ceph要部署在每个节点上提供持久性存储。 集群日志守护程序，如fluentd、logstash，在每个节点运行容器。 节点监视守护进程，如prometheus监控集群，可以在每个节点上运行一个node-exporter用进程来收集监控节点的信息。 apiVersion: apps/v1 kind: DaemonSet ## 资源类型 metadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: # 这些容忍度设置是为了让守护进程在控制平面节点上运行 # 如果你不希望控制平面节点运行 Pod，可以删除它们 - key: node-role.kubernetes.io/control-plane operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule containers: - name: fluentd-elasticsearch image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers StatefulSet StatefulSet主要用于管理有状态应用程序的工作负载API对象。 比如在生产环境中可以部署ElasticSearch集群、MongoDB集群或者需要持久化的RabbitMQ集群、 Redis集群、Kafka集群和ZooKeeper集群等。和Deployment类似，一个StatefulSet也同样管 理着基于相同容器规范的Pod。不同的是StatefulSet为每个Pod维护了一个粘性标识。 这些Pod是根据相同的规范创建的，但是不可互换，每个Pod都有一个持久的标识符，在重新调度时也会保留， 一般格式为StatefulSetName-Number。比如定义一个名字是Redis-Sentinel的StatefulSet，指定创建三个Pod， 那么创建出来的Pod名字就为Redis-Sentinel-0、Redis-Sentinel-1、Redis-Sentinel-2。 而StatefulSet创建的Pod一般使用Headless Service(无头服务)进行通信。
apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx --- apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: selector: matchLabels: app: nginx # 必须匹配 .spec.template.metadata.labels serviceName: "nginx" replicas: 3 # 默认值是 1 minReadySeconds: 10 # 默认值是 0 template: metadata: labels: app: nginx # 必须匹配 .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: k8s.gcr.io/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ "ReadWriteOnce" ] storageClassName: "my-storage-class" resources: requests: storage: 1Gi 引用 Deployment
DaemonSet
StatefulSet
资源调度-Deployment，StatefulSet，DaemonSet</content></entry><entry><title>Kubeadm中的Token过期问题</title><url>https://lizj3624.github.io/post/kubeadm-token/</url><categories><category>kubernetes</category><category>cloudnative</category><category>kubeadm</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>kubeadm</tag></tags><content type="html"> kubeadm以及token node节点加入kubernetes集群是通过在node节点执行kubeadm join命令完成的，具体类似如下：
$ kubeadm join 192.168.56.104:6443 --token l18cgl.jlp49w8zyz94vogn \ --discovery-token-ca-cert-hash sha256:1672cd600e7e686b554ce79ee31a79d8fc8da34c339e7763d4601a149be8faa2 如上命令一般是kubernetes集群的master节点初始化成功后，返回的node节点加入的命令。 在参看CentOS8 安装部署Kubernetes-1.20中介绍。 其中token是为加入node节点集群的标识，如果token不对或者过期时，node节点就加入失败。 token默认下是24小时，如果过期时，执行kubeadm join就是提示如下错误信息：
error execution phase preflight: couldn't validate the identity of the API Server: could not find a JWS signature in the cluster-info ConfigMap for token ID "jrc6he" To see the stack trace of this error execute with --v=5 or higher token过期解决思路 master节点重新token，用新token再执行kubeadm join命令。
$ kubeadm token create //默认有效期24小时,若想久一些可以结合--ttl参数,设为0则用不过期 jrc6he.dg2to0m4dhgrecv2 ## 用新token，在执行kubeadm join ## 查看当前有效的token $ kubeadm token list</content></entry><entry><title>Kubernetes中的Ingress资源</title><url>https://lizj3624.github.io/post/kubernetes-ingress/</url><categories><category>cloudnative</category><category>kubernetes</category><category>ingress</category></categories><tags><tag>cloudnative</tag><tag>kubernetes</tag><tag>ingress</tag></tags><content type="html"> Ingress是为kubernetes集群中服务service提供对外访问的接口，主要HTTP/HTTPS访问。 Ingress公开了从集群外部到集群内服务的HTTP和HTTPS路由。流量路由由Ingress资源上定义的规则控制。
下面是一个将所有流量都发送到同一Service的简单Ingress示例： Ingress是由Ingress controller、Ingress资源和相应的service资源。最常见的Ingress控制器是 kuberneteres官方开源的ingress-nginx， 还有其他版本的控制器，在kubernetes官方登记的其他控制器。 主要根据ingress-nginx介绍一下ingress。
创建控制器 ingress-nginx已经写好创建控制器的yaml文件，可以直接创建，有特殊需求的可以根据这个文件改进一下。
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/cloud/deploy.yaml ## 查看创建controller $ kubectl get pods -n ingress-nginx NAME READY STATUS RESTARTS AGE nginx-ingress-controller-6979d75b9d-2hf8f 1/1 Running 0 5h28m 具体ingress-nginx创建可以查看这里
用如下步骤演示一下ingress的用法
创建ingress Ingress资源需要指定apiVersion、kind、metadata和spec字段。 spec部分指明了域名(host)，url以及转发到service信息。
查看下面创建简单Ingress的yaml文件
apiVersion:networking.k8s.io/v1kind:Ingressmetadata:name:tomcat-ingress # ingress的名字namespace:tomcat # ingress所在命名空间spec:rules:- host:tomcat.ns.com # 域名http:paths:- path:/ #urlpathType:Prefixbackend:service:name:mytomcat-http # service的名称port:number:8080# service的端口可以通过如下命令查看创建的ingress资源
## 创建 $ kubectl apply -f tomcat-app.yaml ## 查看 $ kubectl get ingress 创建service 部署应用服务(tomcat)，并创建服务(service)
apiVersion:apps/v1kind:Deploymentmetadata:name:tomcatinfra ## 部署应用名称namespace:tomcatspec:replicas:1selector:matchLabels:app:tomcatinfra ## 应用服务的标签，service通过这个标签选择应用的podstemplate:metadata:name:tomcatinfralabels:app:tomcatinfraspec:containers:- image:saravak/tomcat8 ## 指定应用的镜像name:tomcatappports:- containerPort:8080---apiVersion:v1kind:Servicemetadata:name:mytomcat-http ## 服务的名称namespace:tomcat ## 命名空间，必要有Ingress, 应用在同一命名空间spec:type:ClusterIPports:- port:8080## 服务端口targetPort:8080## app pod端口selector:app:tomcatinfra ## 应用名称创建服务
## 创建 $ kubectl apply -f tomcat-srv.yaml ## 查看服务 $ kubectl get svc 这时候nginx controller中的nginx的配置应该新增了转发tomcat.ns.com的信息。
kubectl -n ingress-nginx exec -it nginx-ingress-controller-6979d75b9d-2hf8f -- cat nginx.conf 这时可以将域名tomcat.ns.com解析的IP改成controller所在宿主机的IP，然后curl http://tomcat.ns.com/将 请求转发到部署的tomcat应用上。
引用 Ingress
Ingress 控制器
ingress nginx</content></entry><entry><title>Kubernetes中的Namespace详解</title><url>https://lizj3624.github.io/post/kubernetes-namespace/</url><categories><category>kubernetes</category><category>cloudnative</category><category>namespace</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>namespace</tag></tags><content type="html"> 在Kubernetes中，名字空间(Namespace)提供一种机制，将同一集群中的资源划分为相互隔离的组。 同一名字空间内的资源名称要唯一，但跨名字空间时没有这个要求。 名字空间作用域仅针对带有名字空间的对象例如Deployment、Service等， 这种作用域对集群访问的对象不适用例如StorageClass、Node、PersistentVolume等。
命名空间作用 命名空间为集群中的对象名称赋予作用域，命名空间还可以让用户轻松地将策略应用到集群的具体部分， 命名空间最大的好处之一是能够利用Kubernetes RBAC(基于角色的访问控制)。
将命名空间映射到团队或项目上，为每个单独的项目或者团队创建一个命名空间。
使用命名空间对生命周期环境进行分区，命名空间非常适合在集群中划分开发、staging以及生产环境。
使用命名空间隔离不同的使用者，可以解决的用例是根据使用者对工作负载进行分段。
预配置的三个命名空间 default向集群中添加对象而不提供命名空间，这样它会被放入默认的命名空间中。
kube-public是让所有具有或不具有身份验证的用户都能全局可读。
kube-system用于Kubernetes管理的Kubernetes组件，一般规则是避免向该命名空间添加普通的工作负载。
三个预制的命名空间，有kubernetes创建和管理
使用命名空间 命名空间的使用可以有kubectl和yaml资源管理维护。
## 创建命名空间tomcat kubectl create namespace tomcat ## 查看命名空间 kubectl get ns kubectl describe namespace tomcat ## 查看命名空间tomcat上的pods, 通过-n参数指明命名空间 kubectl get pods -n tomcat ## 在命名空间上创建资源(service, ingress, pod)等，通过在资源文件指明namespace namespace: tomcat ## 在指定命名空间运行pod kubectl run nginx --image=nginx --namespace=nginx ## 删除命名空间 kubectl delete namespace tomcat 还可以通过yaml的资源创建命名空间，然后执行kubectl apply -f tomcat.yaml
apiVersion:v1kind:Namespacemetadata:name:tomcat引用 命名空间
超长干货 | Kubernetes命名空间详解</content></entry><entry><title>Kubernetes集群重置</title><url>https://lizj3624.github.io/post/kubernetes-reset/</url><categories><category>cloudnative</category><category>kubernetes</category></categories><tags><tag>cloudnative</tag><tag>kubernetes</tag></tags><content type="html"> 移除所有工作节点 ## 查看节点 kubectl get node ## 删除指定节点 kubectl delete node &lt;node-name> 所有工作节点删除工作目录，并重置kubeadm rm -rf /etc/kubernetes/* kubeadm reset Master节点删除工作目录，并重置kubeadm rm -rf /etc/kubernetes/* rm -rf ~/.kube/* rm -rf /var/lib/etcd/* rm -rf /var/lib/cni/ rm -fr /etc/cni/net.d ## 重置 kubeadm reset -f 重新init kubernetes kubeadm init</content></entry><entry><title>CentOS8 安装部署Kubernetes-1.20</title><url>https://lizj3624.github.io/post/centos8-kubernetes/</url><categories><category>kubernetes</category><category>cloudnative</category><category>centos</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>centos</tag></tags><content type="html"> CentOS8环境通过kubeadm工具安装部署kubernetes集群，集群有三台虚拟机组成，一台master，两个node。
环境准备 准备三台CentOS8服务器，主机名与静态IP地址如下表所示（参考下边 master 节点服务器的配置）：
角色 主机名 ip地址 master master 192.168.56.104 node node1 192.168.56.101 node node2 192.168.56.108 [root@myk8s-01 ~]# cat /etc/redhat-release CentOS Linux release 8.2.2004 (Core) 下面以 master 服务器为例，进行相应的配置（node 节点也需要做同样的配置）
查看系统版本 [root@myk8s-04 ~]# cat /etc/centos-release CentOS Linux release 8.3.2011 关闭防火墙 [root@myk8s-04 ~]# systemctl stop firewalld [root@myk8s-04 ~]# systemctl disable firewalld 配置网络 [root@myk8s-04 ~]# cat /etc/sysconfig/network-scripts/ifcfg-enp0s3 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s3 UUID=8583e7ca-8aa4-46b8-960e-7e055f8dd626 DEVICE=enp0s3 ONBOOT=yes HWADDR=08:00:27:62:C1:C1 添加阿里源 [root@myk8s-04 ~]# rm -rfv /etc/yum.repos.d/* [root@myk8s-04 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 配置主机名 ## 设置主机名 [root@myk8s-04 ~]# hostnamectl set-hostname myk8s-08.host.com ## 将如下加入/etc/hosts [root@myk8s-04 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.56.104 myk8s-03.host.com master 192.168.56.108 myk8s-08.host.com node 192.168.56.101 myk8s-01.host.com node 关闭selinux [root@myk8s-04 ~]# sed -i 's/enforcing/disabled/' /etc/selinux/config [root@myk8s-04 ~]# setenforce 0 关闭swap，注释swap分区 [root@myk8s-04 ~]# swapoff -a ## 将/etc/fstab中最后一行注释掉 #/dev/mapper/cl-swap swap swap defaults 0 0 [root@myk8s-04 ~]# vim /etc/fstab 安装部署docker CentOS8安装部署docker步骤请参考这里
安装相应的依赖包
[root@myk8s-04 ~] yum install vim bash-completion net-tools gcc -y 添加aliyun docker仓库加速器 [root@myk8s-04 ~]# mkdir -p /etc/docker [root@myk8s-04 ~]# cat /etc/docker/daemon.json { "exec-opts": ["native.cgroupdriver=systemd"], "log-driver": "json-file", "log-opts": { "max-size": "100m" }, "storage-driver": "overlay2", "registry-mirrors": ["https://jxfzcj2d.mirror.aliyuncs.com"] } ## 重新加载配置，重启docker [root@myk8s-04 ~]# systemctl daemon-reload [root@myk8s-04 ~]# systemctl restart docker 阿里云docker镜像加速器文档参考这里
测试验证 [root@myk8s-04 ~]# docker info ## 保证Cgroup Driver是systemd [root@myk8s-04 ~]# docker info|grep "Cgroup Driver" Cgroup Driver: systemd 安装时遇到问题，CentOS8默认安装了Podman，再次安装docker时提升冲突，因此需要协助Podman和Buildah，再次安装docker
Cgroup Driver不是systemd的时候，改/etc/docker/daemon.json中的"exec-opts": [&ldquo;native.cgroupdriver=systemd&rdquo;]
安装kubectl、kubelet、kubeadm # 1. 添加阿里kubernetes源 [root@myk8s-04 ~]# cat /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg # 2. 安装部署 [root@myk8s-04 ~]# yum -y install kubectl kubelet kubeadm [root@myk8s-04 ~]# systemctl enable kubelet 初始化k8s集群 kubeadm初始化脚步 [root@myk8s-04 ~]# kubeadm init --kubernetes-version=1.21.1 \ > --apiserver-advertise-address=192.168.56.104 \ > --image-repository registry.aliyuncs.com/google_containers \ > --service-cidr=10.10.0.0/16 --pod-network-cidr=10.122.0.0/16 由于kubeadm 默认从官网k8s.grc.io下载所需镜像，国内无法访问，因此需要通过–image-repository指定阿里云镜像仓库地址。
POD的网段为: 10.122.0.0/16， APIServer地址就是master本机IP。
集群初始化成功后返回如下信息：
[init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.1. Latest validated version: 19.03 [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder "/etc/kubernetes/pki" [certs] Generating "ca" certificate and key [certs] Generating "apiserver" certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master] and IPs [10.10.0.1 192.168.1.25] [certs] Generating "apiserver-kubelet-client" certificate and key [certs] Generating "front-proxy-ca" certificate and key [certs] Generating "front-proxy-client" certificate and key [certs] Generating "etcd/ca" certificate and key [certs] Generating "etcd/server" certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost master] and IPs [192.168.1.25 127.0.0.1 ::1] [certs] Generating "etcd/peer" certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost master] and IPs [192.168.1.25 127.0.0.1 ::1] [certs] Generating "etcd/healthcheck-client" certificate and key [certs] Generating "apiserver-etcd-client" certificate and key [certs] Generating "sa" key and public key [kubeconfig] Using kubeconfig folder "/etc/kubernetes" [kubeconfig] Writing "admin.conf" kubeconfig file [kubeconfig] Writing "kubelet.conf" kubeconfig file [kubeconfig] Writing "controller-manager.conf" kubeconfig file [kubeconfig] Writing "scheduler.conf" kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env" [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [kubelet-start] Starting the kubelet [control-plane] Using manifest folder "/etc/kubernetes/manifests" [control-plane] Creating static Pod manifest for "kube-apiserver" [control-plane] Creating static Pod manifest for "kube-controller-manager" [control-plane] Creating static Pod manifest for "kube-scheduler" [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s [kubelet-check] Initial timeout of 40s passed. [apiclient] All control plane components are healthy after 98.007042 seconds [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.20" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master as control-plane by adding the labels "node-role.kubernetes.io/master=''" and "node-role.kubernetes.io/control-plane='' (deprecated)" [mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: mwxojd.djyh86ktwwwyv0qp [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.56.104:6443 --token n9ymj8.nscmc7jz344d9maa \ --discovery-token-ca-cert-hash sha256:13164b268a07c60fcfe9b71cfba98dc36f630a7c64a471397fd52cf3631f46a7 记录生成的最后部分内容(kubeadm内容)，此内容是在其它节点加入Kubernetes集群时执行。
创建kubectl [root@myk8s-04 ~]# mkdir -p $HOME/.kube [root@myk8s-04 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@myk8s-04 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config [root@myk8s-04 ~]# source &lt;(kubectl completion bash) &amp;&amp; echo 'source &lt;(kubectl completion bash)' >> ~/.bashrc 查看节点pod [root@myk8s-04 ~]# kubectl get node NAME STATUS ROLES AGE VERSION myk8s-04.host.com Ready control-plane,master 28h v1.21.1 [root@master ~]# kubectl get pod --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-7f89b7bc75-6jzcr 0/1 Pending 0 11m kube-system coredns-7f89b7bc75-fzq95 0/1 Pending 0 11m kube-system etcd-master 1/1 Running 0 11m kube-system kube-apiserver-master 1/1 Running 0 11m kube-system kube-controller-manager-master 1/1 Running 0 11m kube-system kube-proxy-t8jlr 1/1 Running 0 11m kube-system kube-scheduler-master 1/1 Running 0 11m master当时Ready状态就说明成功了
安装calico网络 安装Calico网络 [root@myk8s-04 ~]# kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml configmap/calico-config created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created poddisruptionbudget.policy/calico-kube-controllers created 查看pod和node [root@myk8s-04 ~]# kubectl get pod --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-744cfdf676-87n8d 0/1 ContainerCreating 0 45s kube-system calico-node-kfnf5 0/1 PodInitializing 0 46s kube-system coredns-7f89b7bc75-6jzcr 0/1 ContainerCreating 0 13m kube-system coredns-7f89b7bc75-fzq95 0/1 ContainerCreating 0 13m kube-system etcd-master 1/1 Running 0 13m kube-system kube-apiserver-master 1/1 Running 0 13m kube-system kube-controller-manager-master 1/1 Running 0 13m kube-system kube-proxy-t8jlr 1/1 Running 0 13m kube-system kube-scheduler-master 1/1 Running 0 13m [root@myk8s-04 ~]# kubectl get node NAME STATUS ROLES AGE VERSION master Ready control-plane,master 13m v1.20.1 向集群中加入node node节点也需要执行如上的环境准备、安装docker、安装kubectl kubeadm kubelet的步骤，然后再执行如下步骤
# 1. 更新admin.conf文件，每个node节点都比跟master的保持一致 [root@myk8s-04 ~]# scp /etc/kubernetes/admin.conf root@192.168.56.101:/etc/kubernetes # 2. 在节点1执行如下命令 ```shell [root@myk8s-01 ~]# mkdir -p $HOME/.kube [root@myk8s-01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@myk8s-01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/confi [root@myk8s-01 ~]# echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile [root@myk8s-01 ~]# source ~/.bash_profile # 3. 加入node节点到集群，也就master初始化成功后返回在master上查看节点信息 [root@myk8s-01 ~]# kubeadm join 192.168.56.104:6443 --token n9ymj8.nscmc7jz344d9maa \ --discovery-token-ca-cert-hash sha256:13164b268a07c60fcfe9b71cfba98dc36f630a7c64a471397fd52cf3631f46a7 # 4. 查看节点 [root@myk8s-01 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION myk8s-01.host.com Ready &lt;none> 5h14m v1.21.1 myk8s-04.host.com Ready control-plane,master 5h27m v1.21.1 myk8s-08.host.com Ready &lt;none> 113m v1.21.1 node 节点的 docker 配置文件 /etc/docker/daemon.json 尽量跟 master 节点保持一致
可以通过这个命令：journalctl -f -u kubelet 引用：k8s 集群之使用 kubeadm 在 Centos8 上部署 kubernetes 1.20</content></entry><entry><title>CentOS8 安装部署Docker</title><url>https://lizj3624.github.io/post/centos-docker/</url><categories><category>cloudnative</category><category>docker</category><category>centos</category></categories><tags><tag>cloudnative</tag><tag>docker</tag><tag>centos</tag></tags><content type="html"> CentOS8的YUM源默认不支持docker安装，默认是redhat的Podman容器，再次记录一下CentOS8通过YUM安装部署docker的步骤。
更新YUM源 国内用户推荐使用阿里云的YUM源
# 1. 备份 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup # 2. 更新YUM源 ## CentOS 8 (centos8官方源已下线，建议切换centos-vault源） wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo ## CentOS 7 wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo ## CentOS 6 （centos6官方源已下线，建议切换centos-vault源） wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-6.10.repo # 3. 更新YUM缓存 yum clean all &amp;&amp; yum makecache 安装步骤docker # 1. 更新YUM yum update ## 更新依赖库 yum install -y yum-utils device-mapper-persistent-data lvm2 ## 设置YUM源，选择国内阿里云，中央仓库（http://download.docker.com/linux/centos/docker-ce.repo） yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ## 查看YUM支持版本 yum list docker-ce --showduplicates | sort -r # 2. 选择版本安装 yum install docker-ce-20.10.7 # 3. 启动Docker，然后加入开机启动 systemctl start docker systemctl enable docker # 4. docker-compose安装 curl -L https://get.daocloud.io/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m) > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose</content></entry><entry><title>Kubectl常用命令</title><url>https://lizj3624.github.io/post/kubectl/</url><categories><category>kubernetes</category><category>cloudnative</category><category>kubtctl</category></categories><tags><tag>kubernetes</tag><tag>cloudnative</tag><tag>kubtctl</tag></tags><content type="html"> kubectl命令行是管理kubernetes集群的工具，学习好kubectl命令行对管理kubernetes很重要，一般安装kubernetes后都会自带这个工具。
语法 kubectl [command] [TYPE] [NAME] [flags] command：指定要对一个或多个资源执行的操作，例如 create、get、describe、delete。
TYPE：指定资源类型。资源类型不区分大小写， 可以指定单数、复数或缩写形式。例如pod、pods、srv等资源
NAME：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 kubectl get pods。
flags: 指定可选的参数。例如，可以使用 -s 或 -server 参数指定 Kubernetes API 服务器的地址和端口。
kubectl get pods -A -o wide 常用命令 创建和更新资源 # 使用 example-service.yaml 中的定义创建服务。 kubectl apply -f example-service.yaml # 使用 &lt;directory> 路径下的任意 .yaml, .yml, 或 .json 文件 创建对象。 kubectl apply -f &lt;directory> # 使用 example-service.yaml 中的定义创建服务。 kubectl create -f example-service.yaml apply可以在资源不存在时创建，存在时根据配置重新修改资源，但是create只能在没有时创建，存在时会抛出错误
获取资源 # 以纯文本输出格式列出所有pod，并包含附加信息(如节点名)。 kubectl get pods -o wide # 获取命名空间为ingress-nginx上pods，并以纯文本输出 kubectl get pods -n ingress-nginx -o wide # 获取命名空间ingress-nginx中名字为nginx-ingress-controller-6979d75b9d-cbml4的pod的信息，并以文本格式输出 # 如果没有指明命名空间就是default命名空间 kubectl get pod -n ingress-nginx nginx-ingress-controller-6979d75b9d-cbml4 -o wide # 查看所有命名空间 kubectl get namespaces # 列出名字为web的rc kubectl get replicationcontroller web # 列出service信息 kubectl get svc -o wide # 列出Ingess信息 kubectl get ingress # 列出namespace为tomcat中的ingress，如果指明namespace默认default kubectl get ingress -n tomcat # 获取所有resource kubectl get all kubectl describe - 显示一个或多个资源的详细状态，默认情况下包括未初始化的资源。 # 查看所有节点描述信息 kubectl describe node # 查看所有service描述信息 kubectl describe svc # 查看名为nginx的service描述信息 kubectl describe svc nginx # 查看name为nginx-ingress的ingress信息 kubectl describe ingress nginx-ingress 删除资源 # 删除名称为nginx-6799fc88d8-chjq8的pod，这样删除后由于通过deployment或者rs创建的pod，新的pod还有可能被创建 kubectl delete pod nginx-6799fc88d8-chjq8 # 删除所有带有 '&lt;label-key>=&lt;label-value>' 标签的 Pod 和服务。 kubectl delete pods,services -l &lt;label-key>=&lt;label-value> # 删除所有 pod，包括未初始化的 pod。 kubectl delete pods --all Pod容器操作 # 在pod的容器中执行ls命令 kubectl -n ingress-nginx exec -it nginx-ingress-controller-6979d75b9d-cbml4 -- /bin/ls # 默认在pod 123456-7890的第一个容器中运行“date”并获取输出 $ kubectl exec 123456-7890 date # 在pod 123456-7890的容器ruby-container中运行“date”并获取输出 $ kubectl exec 123456-7890 -c ruby-container date # 切换到终端模式，将控制台输入发送到pod 123456-7890的ruby-container的“bash”命令，并将其输出到控制台/ # 错误控制台的信息发送回客户端。 $ kubectl exec 123456-7890 -c ruby-container -i -t -- bash -il Pod容器日志 # 返回仅包含一个容器的pod nginx的日志快照 kubectl logs nginx # 返回pod ruby中已经停止的容器web-1的日志快照 kubectl logs -p -c ruby web-1 # 持续输出pod ruby中的容器web-1的日志 kubectl logs -f -c ruby web-1 # 仅输出pod nginx中最近的20条日志 kubectl logs --tail=20 nginx # 输出pod nginx中最近一小时内产生的所有日志 kubectl logs --since=1h nginx kubectl logs -f -l app=nginx --all-containers=true kubectl logs -f -n kube-system calico-node-wzmz5 -c calico-node 其他 lable标签 # 给名为foo的Pod添加label unhealthy=true kubectl label pods foo unhealthy=true # 给名为foo的Pod修改label为 'status' / value 'unhealthy'，且覆盖现有的value kubectl label --overwrite pods foo status=unhealthy # 给 namespace中的所有pod添加label kubectl label pods --all status=unhealthy # 仅当resource-version=1时才更新名为foo的Pod上的label kubectl label pods foo status=unhealthy --resource-version=1 edit编辑配置文件 # 编辑名为“docker-registry”的service kubectl edit svc/docker-registry # 使用一个不同的编辑器 KUBE_EDITOR="nano" kubectl edit svc/docker-registry # 编辑名为“docker-registry”的service，使用JSON格式、v1 API版本 kubectl edit svc/docker-registry --output-version=v1 -o json cp命令 # 将“/tmp/foo_dir”本地目录拷贝到默认命名空间的远端pod的“/tmp/bar_dir”目录下 kubectl cp /tmp/foo_dir &lt;some-pod>:/tmp/bar_dir # 复制/tmp/foo本地文件到/tmp/bar在远程pod在一个特定的容器 kubectl cp /tmp/foo &lt;some-pod>:/tmp/bar -c &lt;specific-container> # 将/tmp/foo文件拷贝到远程pod中的/tmp/bar目录下 kubectl cp /tmp/foo &lt;some-namespace>/&lt;some-pod>:/tmp/bar 引用 kubectl 概述 | Kubernetes</content></entry><entry><title>怎么理解Web 3.0？</title><url>https://lizj3624.github.io/post/web3/</url><categories><category>blockchain</category><category>web3</category></categories><tags><tag>blockchain</tag><tag>web3</tag><tag>cryptocurrency</tag></tags><content type="html"> 区块链技术的兴起后，web3.0被提出，什么是web3.0，可以看看这篇文章，转载自公众号[分布式实验室]
我们今天听到的「Web 3.0」或「Web3」，是由以太坊联合创始人、Polkadot创建者Gavin Wood在2014年提出的概念，用以代表互联网的下一个时代——互联网形态向着更民主的范式转变。正如Gavin Wood接受采访时所说，他对Web3的定义很简单：“Less trust, more truth.”。
但早在1998年，万维网创始人、著名计算机科学家蒂姆·伯纳斯-李（Tim Berners-Lee）就提出过相似的概念——“语义网”，它暗示了对于互联网的新想法：互联网将更加自主、智能和开放。
当下Web3还处于萌芽时期，各种概念层出不穷，充满了不确定性。人们不停地质问Web3到底是什么，但没有人能够准确地预测未来，关于它将在何时、以何种方式到来，我们不得而知，但趋势已现黎明之曙光，面对新事物，我们能做的就是尽可能地去了解它。
从信息互联网到价值互联网 为了更好地理解Web3，我们有必要先来回顾一下互联网过去几十年的发展历史，这有助于我们了解互联网是如何走到今天的——从Web1到Web2，以及我们为什么需要Web3。
Web1实现了信息的数字化 1989年，蒂姆·伯纳斯-李（Tim Berners-Lee）写下了名为《Information Management: A Proposal》的论文，将“网络”描绘成一个通过超文本链接相互连接的信息系统网络，这标志着万维网的诞生，并从此开启了Web1时代。
从万维网诞生，一直到2004年这段时期，就是Web1的时代。Web1是一个只读的网络，建立在开放的、分散的和社区管理的协议之上。这一时期的互联网是由静态网页组成的，典型的应用场景和代表性产品就是搜素引擎与门户网站，用户只能阅读由网站运营者提供的内容，并且无法与页面的内容进行交互。
Web1的本质是聚合、联合、搜索，其聚合的对象是杂乱无章的网络信息，但没有解决人与人之间沟通、互动和参与的需求，所以Web2应运而生。
Web2从“只读”变成“可交互” Web2的概念是在2004年O&rsquo;Reilly Media Web2.0大会由发起者Tim O&rsquo;Reilly首次提出，这位提出了开源软件、创立了全球首家门户网站的传奇人物认为：“Web2作为互联网建设的一种新模式，创新之处是内容从“只读”变为“交互”，用户不光能接收内容、还能创造内容，是一个强调用户生成内容的网络环境。”
和许多重要的概念一样，Web2被提出时并没有一个明确边界，尽管当时在谷歌的引用次数超过了950万，但人们对于Web2的含义仍然存在着巨大的分歧，有人说Web2是毫无意义的营销概念，还有一些人则认为它是新的未来，这和今天大家对Web3的态度很相似。
相比Web1，在Web2时代，用户可以在网络平台上传自己的文字、图片、视频等内容，不再是内容的被动接收者，也可以与其他用户进行交流，互联网从平台向用户的单向传播，变成了用户与用户间的双向传播。于是社交网络开始兴起，各种社区和应用程序逐步诞生和发展，这些App鼓励大家生产和交流信息。
Web2时代，人们成了各种应用的用户，在这些产品中创造了大量的内容，而这些数据又由中心化的平台掌握，平台作为信息的分发中心，可以通过算法向不同的人推送不同的内容，这种情况下，平台的价值与用户数和流量紧紧绑定在一起。由于不同平台之间数据并不互通，这就使得谁拥有的信息数据越多，谁就能更好地抢夺流量。
Web2催生了一大批平台和互联网寡头，这些中心化的互联网行业巨头塑造了一套用户靠“出卖”自己隐私数据和注意力来换取服务的互联网世界运行规律，并以用户的数据和流量作为燃料，来驱动游戏、广告、电商、会员服务这四大变现模型的运转。这种模式下，人们的注意力和时间构成平台的流量，但流量以及产生的数据却归属于平台，而非用户本身，这给Web3的诞生带来了契机。
Web3代表了下一代去中心化互联网，让价值更好地回归个人 正如Web2的诞生一样，Web3的到来，寄予了人们想要解决目前互联网存在问题的希望，Web3代表了一个无中介的读写网络，即一个去中心化的互联网，其目的是让价值更好地回归个人。
去中心化是与中心化相对的一个概念，在一个中心化的系统中，其它的节点必须依赖中心才能生存，中心决定了节点。在一个去中心化的系统中，分布有众多的节点，每个节点都具有高度自治的特征，每一个节点都是一个“小中心”。
互联网是基于软件的高级网络，其核心层相对简单，由数十亿个完全可编程的计算机组成，任何连接到互联网的计算机可以自由运行用户选择的软件。软件只是将人类思维进行编码，任何你想要表达的内容，加上正确的激励措施，都可以通过互联网迅速传播。思考和创造是人类生存的原因和价值，互联网为创造提供了无限的空间。
Web1和Web2实现了信息的互联互通，Web3时代，价值互联将成为可能，价值的传递比信息的传递更加重要。互联网技术让信息能够在全球范围内得到分发，且种类丰富、价格低廉、可快速复制，但这些特点却与“价值”是相对立的，根据经济学的定义，任何有价值的东西，无论是金钱还是资产，都应该是稀缺的、难以获得的。
基于去中心化网络的Web3将彻底改变经济系统，改变产品的交付和消费方式，改变企业运作、组织协同和个人工作的方式。互联网这个巨型数据交换网络正向着一个越来越复杂的生态系统演进，在这个系统中，我们每个人都是一个小中心，个人创造的价值可以通过代币的形式进行交换，使得价值更好地回归个人，而不是被中心化的平台所掠夺。
中心化平台已经占据主导地位太长时间了，以至于大部分人都忘了还有更好的构建网络服务的方式。去中心化并不是解决互联网所有问题的灵丹妙药，但它比中心化系统提供了一个更好的方法。
社会文化思潮的转变 任何事物得以流行，都有其社会背景，Web3概念大热的背后是“去中心化”和“去信任中介”思潮的兴起。
人类社会在“中心化”与“去中心化”之间轮回 去中心化这种思想在人类诞生的时候就已经存在了，其主旨是弱化中心，实现人与人之间直接沟通、直接交易、直接传播。去中心化，并非不要中心，而是由节点来自由选择中心，自由决定中心。在中心化的系统中，由中心决定节点，节点离开了中心无法生存，必须依赖中心而存在。
而在去中心化系统中，任何节点都可以成为一个中心，任何中心都不是永久的，而是阶段性的，任何中心对节点都不具有强制性。正如我们所身处的浩瀚宇宙，就是由无边无界的物质组成，没有中心点。
纵观人类社会的整个发展过程，“中心化”与“去中心化”的思想一直贯穿其中。从分布式、去中心化的原始人群、部落和氏族公社到中心化结构的国家出现，从去中心化的市场经济到中心化的计划经济&hellip;&hellip;人类社会的进化就是从“去中心化”到“中心化”的不断反复。
长期以来，“中心化”依托上帝的视角的优势，以天子之名号令诸侯，在人类社会的各个领域都已成为趋势和主流，但正所谓“物极必反”、“孤阴不生，独阳不长”，当中心化走到极致时，去中心化思潮就开始从个体、局部和细微之处发掘和积聚能量。
当下，“去中心化”是一个被严重误解的概念，去中心化不代表没有中心，而是一种平衡，绝对的中心化和去中心化都没有意义，我们需要不断地调整它们之间的关系。
基于分布式共识的信任机制，可以让人类更好地进行大规模协作 人类是唯一一个能够跨越时间和空间进行大规模协作的物种，这对我们走上食物链顶端具有重要的意义。而人类之所以能够大规模协作，是因为我们可以虚构故事，共同想象出一些客观世界不存在的概念，因而建立起更大的组织认同感。人类可以为了某种虚构的故事而奉献自己的一切，这就意味着能够建立起更大的协作网络。
国家、民族、宗教、阶级、法律、公司、货币等等都是一种建立在共同想象基础之上的认同感叙事，这些虚构的故事成为了人与人之间的信任中介，使得我们能够进行大规模协作。在农业经济和工业经济下，信任主要靠人际信任和制度信任维系，而数字经济中的信任关系是数字信任。当下，互联网主要以各种中心化的机构为信任中介。
Web3的核心创新之一是基于区块链技术带来的分布式共识，其愿景是把共识数字化、编码化、去信任中介化，这意味着用户可以与陌生人达成有约束力的协议，而不需要依赖任何中介或中心化机构，加密货币是这种技术的初步应用，而Web3的愿景在于用同样的技术基础来变革其他形式的人类互动。
Web3技术全景 基于区块链技术的基础设施 区块链脱胎于比特币系统，从本质上讲，它是一个共享数据库，存储于其中的数据或信息，具有“不可伪造”、“公开透明”、“集体维护”等特征，基于这些特征，区块链奠定了坚实的“信任”基础，创造了可靠的“合作”机制。
Web3的基础设施基于区块链技术，Web3.0 Foundation将Web3的技术栈定义为由L0~L4组成的5层架构系统，如下图所示：
Web3技术栈
L0提供数据分发和互动能力，主要包括：
点对点互联网覆盖协议（Peer-to-peer (p2p)）：一个允许节点以分散的方式进行通信的网络套件。
平台中立的计算描述语言（Platform-neutral computation description language）：一种在不同物理平台（架构、操作系统等）上执行相同程序的方式。例如EVM（以太坊）、UTXOs（比特币）和Wasm。
L1提供分发和互动数据的能力，主要包括：
零/低信任度互动协议：描述不同节点如何相互作用并信任来自每个节点的计算和信息的协议。大多数加密货币，如比特币和ZCash，都符合零/低信任交互协议的定义，它描述了节点参与协议所需遵循的规则。
数据分配协议：描述数据如何在去中心化系统的各个节点之间分配和交流的协议。例如IPFS、Swarm和BigchainDB。
瞬时数据公共/子信息传递：描述不打算永久存储的数据（如状态更新）如何被传达以及如何让节点意识到其存在的协议。例如Whisper和Matrix。
L2增强了L1的能力，进行提升扩展性、加密消息传递、分布式计算等功能。
状态通道（State channels）：区块链通过让节点在链外相互通信，通过在主链上“打开”和“关闭”通道，只写初始和最终结果，而不是在链上记录每个状态转换，从而提高可扩展性的一种方式。例如比特币的Lightning Network和以太坊的Raiden Network。
Plasma协议：Plasma是通过创建区块链的“树”来提高可扩展性的另一种方式，主链是树的根，而“子”区块链尽可能少地与更高级别的链互动。例如Loom的PlasmaChain和OmigeGO Plasma。
加密存储（Encrypted storage）：使用密码学对数据进行数学加密和解密，包括静态（即存储在特定的计算机上）和动态（即从一台计算机传输到另一台）。例如静态指的是存储加密，动态指的是传输加密（HTTPS就是一种传输加密）
重型计算（Heavy computation）：可以理解为如果需要进行大量的计算，例如在数组中推送大量的对象提供一种方法，允许计算分散在许多计算机中，并证明计算是正确进行的。例子包括以太坊的 Golem 和TrueBit。
分布式秘密管理（Distributed secret management）：允许信息只被授权方访问，包括复杂的场景，如“解密此信息需要所有六个签名者使用他们的密钥”或“7个签名者中的任何5个必须同意”等等。
预言机（Oracles）：将链外数据（如天气结果或股票价格）注入区块链的一种方式，一般供智能合约使用。
L3是人类可读语言和库的层。在这一层，开发人员可以适当抽象并进行程序开发，包括可扩展协议的API和语言：
各种开发应用程序的语言，如：Solidity和Vyper（Ethereum），Plutus（Cardano）和Rust（Substrate）。
使编程更加容易的各种框架，如：ethers.js、web3.js和oo7.js。
L4是技术栈顶层，参与者主要是普通用户。用户可以在这一层和单个或多个区块链应用等进行互动，而不需要知道如何编程和实现细节，案例有Status、MetaMask、MyCrypto等。
去中心化应用（DApp）程序架构 Web3去除了管理中心，无需数据库集中存储应用程序的状态，也不需要集中的网络服务器来存放后端的逻辑，Web3的应用程序（DApp）架构与Web2时代的App有很大不同，Web3可以利用区块链在互联网上的去中心化状态机上构建应用程序。
状态机是由状态寄存器和组合逻辑电路构成的，能够根据控制信号按照预先设定的状态进行状态转移，是协调相关信号动作、完成特定操作的控制中心。区块链可以理解为一种被实例化为创世状态的状态机，并且有非常严格的规则（即共识）来定义该状态如何转换。
没有存在的实体控制这个去中心化的状态机，状态机是由网络中的每个人共同维护的。与Web2后端被控制的方式不同，在Web3生态中，我们可以编写智能合约，定义应用程序的逻辑，将应用程序部署到去中心化的状态机上，这意味着，每个想构建区块链应用的人，都可以在共享状态机上部署代码。以下是该架构示意图：
Dapp架构图
区块链：以太坊提供了一个可编程的区块链，是一个全球可访问的、具有确定性的状态机，由点对点（Peer to Peer）的节点网络共同维护。以太坊状态机上的状态变化，是由网络的参与者遵循的共识规则所控制的。
以太坊的设计，就是一个世界上任何人都可以访问、写入的状态机，因此，以太坊不属于任何单个实体，而是由网络中的每个参与者共同拥有。狭义来说，以太坊是一系列协议，其核心是一个能执行遵守协议的任何复杂的代码的以太坊虚拟机。以太坊虚拟机是图灵完备的，开发者可以在虚拟机上使用像JavaScript、Python这样的友好的编程语言来创建应用，以太坊作为一个平台为不同的区块链应用提供服务。
智能合约：智能合约是一个在以太坊区块链上运行的程序，定义了区块链上发生的状态变化背后的逻辑。抽象概来说，智能合约是一种可以自动化执行的规则，现实生活中的合约，合约制定完成后需要有专门的执行角色，而智能合约将这个步骤自动化，只有满足智能合约中制定的条件就会被执行。
智能合约是用高级语言（编程语言）编写的，如Solidity或Vyper。由于智能合约代码存储在以太坊区块链上，所以任何人都可以检查网络上所有智能合约的应用逻辑。
以太坊虚拟机（Ethereum Virtual Machine，即EVM）：虚拟机是计算机系统的仿真器，可以在一个完全隔离的系统中，提供真实计算机的功能。系统虚拟机可以提供一个可以运行完整操作系统的完整系统平台，例如Windows系统、MAC OS系统等。
程序虚拟机就是可以在仿真器里单独运行计算机程序，如果购买了云服务商提供的虚拟机，就可以在虚拟机上面安装各种软件和运行各种任务。通过以太坊虚拟机，可以执行智能合约中定义的逻辑，处理以太坊全球可访问状态机上发生的状态变化。EVM不理解像Solidity和Vyper这样的高级语言，必须将高级语言编译成Bytecode才可以在EVM中执行。
前端：前端定义了用户界面逻辑，承载着和用户的交互，同时也需要和智能合约中定义的应用逻辑进行联动，才能提供功能。为了确保前端应用程序与区块链交互时有一套统一的方法，每个以太坊客户端（Provider）都遵循了JSON-RPC规范。JSON-RPC是一个无状态、轻量级的远程程序调用协议（RPC），定义了几个数据结构及其处理规则，与传输无关，因此这些概念可以在同一进程中使用。
通过以太坊客户端连接到区块链，就可以读取存储在区块链上的状态，但如果想写入状态，还需要在向区块链提交交易之前，用私钥“签署”交易，否则节点将不接受该交易。目前主流的方式是通过开源的以太坊钱包MetaMask来进行签名。
一种全新的基于Token的激励方式 区块链是从比特币系统中提炼出来的一种底层支撑技术，Token原本是区块链上激励“矿工”的一种经济手段，在加密数字货币的发展过程中，有大量的组织也希望能够发行自己的Token，区块链2.0——以太坊及其订立的ERC20标准应用而生，基于这个平台和标准，任何人和组织都可以在以太坊上发行自己定义的Token，极大地降低了发行的难度和速度，Token开始以代币的身份为大众所熟知。
随着NFT技术的兴起，Token的概念也在不断延伸，它可以代表任何数字权益和价值，由此我们可以认识到，加密数字货币也只不过是一种特殊的Token，在一个可以运行Token的平台上发行加密数字货币是一件易如反掌的事情。
Token之所以如此重要，是因为它提供了一种将价值和控制权赋予用户和构建者，而不是简单地赋予中心化公司的机制。
基于DAO的组织协作模式 随着信息技术的发展以及组织自身复杂性的不断增加，传统组织的雇佣关系、管理模式等已经很难适应复杂多变的环境以及新一代个体对组织的要求。一种新兴的组织治理模式——DAO（Decentralized Autonomous Organization，去中心化自治组织）应运而生，为解决现有的组织管理问题提供了很好的思路。
DAO是基于区块链核心思想理念衍生出来的一种组织形态，由达成同一个共识的群体自发产生的共创、共建、共治、共享的协同行为，是区块链解决了人与人之间的信任问题之后的附属产物。
与传统的自上而下的组织形式不同，DAO鼓励所有成员积极参与，并按照创始准则对参与者进行奖励。传统组织需要不同层级成员之间的高度信任，而DAO的核心规则和治理由智能合约进行，任何人都可以随时查阅该代码。
DAO是一种围绕透明度和包容性建立的新型组织，这些原则可以适用于各式组织，包括非营利组织、集体、合作社和投资基金等。
Web3生态概览 除了技术方面的革新，Web3的创新还体现在丰富的应用生态和组织形式，目前主要有以下5个主流的应用领域：
DApp Dapp是分布式的应用程序，运行在分散和不可变更的区块链网络上，其核心是通过智能合约将交易条款写入代码的自动执行协议，交易双方不需要互相信任，当预先设定的条件得到满足时，智能合约便会自动结算。从使用者的角度来看，Dapp与Web2的应用程序类似。Dapp因其独特的特性而享有众多优势，其中包括：
开源：任何人都可以看到这个程序的源代码。
分布式：所有数据和记录都存储在公共的、不可改变的区块链上。分布式使这些数据高度安全，免受篡改、黑客的攻击和入侵。
使用加密令牌来保证网络安全。
由于数据分布在多台计算机上，Dapp不会存在因停机而不能使用的情况。
DeFi DeFi（Decentralized Finance，去中心化金融）是一套不再依赖旧有、低效的基础架构，而是利用密码学、去中心化和区块链来构建的新型金融体系，在这套体系下，人们可以以更有效、公平和开放的方式使用金融服务，完成付款、借贷和交易。区块链技术使得DeFi具有以下特点：
高效：即便交易双方可能位于完全不同的地理位置，法律法规也不同，所有的操作也几乎可以立即处理完毕，最重要的是，大多数DeFi协议都可在无人干预或少量人力参与的情况下进行。
公平：所有服务均完全无需许可、不受审查。
开放：任何人都可以构建新的Defi应用程序，为生态系统做出贡献。与传统金融相反，新应用程序可利用现有协议，构建于现有解决方案之上。
无需许可：任何能使用浏览器和接入互联网的人均可访问，无需文件验证、收入证明，不限国籍或种族，每个人都被平等对待。
不受审查限制：没有其他方可以拒绝我们访问服务。即便有行为不良者，也无法改变充分去中心化系统的规则。
NFT NFT（Non-Fungible Token，非同质化代币）是一种不可伪造的数字资产，由于独特性而存在价值。可替代性（Fungibility）是指一种商品的一个单位是不可区分的，可以相互交换。比如1元的硬币可以与其它任何1元的硬币互换。不可替代性是艺术品、收藏品和房地产等独特商品的属性，一个NFT可能代表一件独特的数字艺术品。
对于在网络和数字空间花费越来越多时间的年轻人来说，数字资产正在变得越来越重要。用户购买了NFT后就拥有了这个NFT的所有权，可以转让、出售、抵押、出借、或者保留起来供自己欣赏。NFT的早期应用案例包括数字艺术、游戏、体育纪念品、收藏品等等。
NFT还为创作者提供了新的盈利方式，他们可以直接出售自己的作品，而不需要依赖中介，粉丝也可以直接参与创作者的事业，在支持的艺术家和创作者时，还可以有更多的参与感。除此之外，由于区块链的透明性和可追溯性，艺术家们还可以从二次销售中获得佣金。
2021年，随着更多知名的参与方进入NFT领域，NFT的热度呈指数型增长。NBA Top Shot（来自NBA的官方授权收藏品）总销售额达2亿美元，但营销花费却很低。流行音乐Katy Perry和NFL player Rob Gronkowski为粉丝们推出了NFT。Ellen DeGeneres和Kings of Leon，在新冠期间，没有演出的日子里，通过出售NFT为慈善事业筹集资金。这样的例子很多，属于NFT的时代才刚刚开始。
DAO DAO（Decentralized Autonomous Organization，去中心化自治组织）是围绕透明度和包容性建立的一种新型组织治理模式，是参与成员共有的社区，由成员的共识而非集中领导来管理，其特点是：
去中心化：规则不能被单个人物或中心化的一方所改变。
自治：投票的统计和决定执行，都遵循写入智能合约的逻辑来计算投票和执行决定，不需要人为干预。
组织特性：可以协调分布在各地的分布式社区利益相关者间的活动。
DAO代表了链上治理的运用。在传统的公司治理中，公司会规定某些政策的章程，例如如何选举董事会等，DAO可以将类似的政策和章程用代码写成智能合约，将这一概念延伸到数字世界。智能合约是运行在区块链网络上的稳定的计算机程序，可以自动和自主执行。
GameFi GameFi，即Game+DeFi，是游戏与金融相融合的一种模式。也叫链游，指构建在区块链技术上的游戏。GameFi将去中心化的金融产品通过游戏的方式呈现，把DeFi的规则游戏化，用户不仅可以将数字资产作为游戏中的装备或工具，还可以在参与游戏的过程中获得收益及奖励。
区块链游戏是另一个去中心化技术为创作者打造新盈利方式的例子，游戏中的物品，如工具、皮肤、升级、头像和经验值等都是由玩家拥有的NFT，可以用现实世界的金钱在二级市场上进行交易，并在游戏中传递。
区块链游戏促进了 P2E（Play-to-earn）模式的发展，一个典型的例子就是在新冠疫情期间，一些菲律宾人靠类似Axie Infinity的游戏赚钱，缓解因为隔离所造成的经济困难。
Web3催生了新的商业和市场策略 基于DAO的组织形式和Token的激励模式使得Web3的用户不再只是产品的使用者，而是所有者和建设者，Web3不再是由中心化的领导来制定有关产品或服务的所有决策，而是由社区共建。在这一背景下，一些新的市场策略产生了。
Meme（模因） “Meme”一词是由理查德·道金斯（Richard Dawkins）在其著作《自私的基因》中造出来的。他将Meme与生物学的基因类比，后者能以人为宿主进行自我复制，Meme和基因最终都会影响人类进化。
虽然现在很多人对于Meme的认知是玩梗，但它的实际内涵远不止此，Meme代表了一种共享的亚文化或对现实的认知。Meme影响着我们周围的一切，从政治、宗教到甚至某个民族国家的确切概念。各法定货币其实也是某种Meme，随着加密货币的出现，这一事实变得更加清晰。尽管货币不是加密技术的唯一用例，加密领域的Meme也会随着时间而演化，但加密技术被用于货币，这是时间最长、也可以说是最强大的Meme之一。
Meme可以以一种高度信息密集的方式表示归属感、社区、善意等，并在社区迅速传播。一个典型的利用Meme进行市场推广的案例是NFT项目Pudgy Penguins，该项目得益于其模因能力而启动，发售后该系列的8888只企鹅在20分钟内售罄。另一个Meme影响个人和群体的例子是PFP（个人资料图片），人们将自己的NFT设置为社交媒体的个人资料头像，传递身份、归属感等信息，这些举动反过来也会引发其他的Meme，进一步推动病毒式传播。
空投 空投是指项目方向用户分发Token，以奖励项目想要激励的特定行为的一种方式。这些Token可以发送给特定区块链上的所有现有地址，或定向发送给有特定行为的地址。空投这种方式近来被广泛用于解决项目的冷启动问题，用以奖励和激励早期用户。
2020年，Uniswap向所有使用过该平台的人空投了400UNI；2021年9月，dYdX项目方向用户空投了 DYDX；2021年11月，ENS对拥有ENS域名的任何人进行了空投，任何在2021年10月31日之前拥有 ENS域名的人都有资格申请$ENS，这些项目代币持有者拥有对ENS协议的治理权。
空投在NFT领域也越来越受欢迎。著名的BAYC（Bored Ape Yacht Club，无聊猿猴游艇俱乐部）项目在2021年8月28日创建了相应的MAYC（Mutant Ape Yacht Club，突变猿猴游艇俱乐部），并向每一个BAYC NFT的持有者空投一个突变猿NFT，此外还发行了10000个新的突变猿供新的参与者购买。
创建MAYC一方面可以奖励无聊猿持有者，另一方面，新创造的10000个NFT允许新来者以较低层次的成员身份进入BAYC生态系统，这既保持了更广泛的社区可访问性，又没有稀释原始系列的独特性。
开发者赠款 开发者赠款是指从协议金库中向以某种方式改进协议的个人或团队发放赠款的一种形式。这可以作为 DAO组织的一种有效启动机制，因为开发者活动是协议成功的重要组成部分。当前具有开发者赠款的项目和协议的例子包括Celo、Chainlink、Compound、以太坊和Uniswap等。
开发者赠款不仅仅只面向给开发人员，从协议开发到bug赏金、代码审计，以及编程之外的其它活动，都可以授予赠款。Compound甚至有一种与业务发展和集成相关的赠款，用于资助任何促进 Compound使用的集成，比如Compound与Polkadot的集成推进方就获得了这笔赠款。
Web3仍然存在很多问题和局限 去中心化并非是万能稻草，互联网已经经历了几个去中心化周期，个人计算机通过提供一种任何人都可以构建，且无人控制的架构来分散计算，但微软想出了围绕专有操作系统进而重新集中控制这个行业的办法。开源软件、互联网和万维网用自有软件和开放协议打破了专有软件的束缚，但在几十年内，各种互联网巨头建立了基于大数据的巨大新垄断。
过去的每一次重大工业变革几乎都伴随着金融泡沫，任何新技术的革命，都将经历一个炒作周期，投资人热衷于投资各种项目，是因为这些投机行为能让他们变得富有，但不一定代表其有实际的意义和价值，泡沫终将破灭，历史上可以参考互联网繁荣后的大萧条。
现在的交易所很赚钱，但本质上交易的是高估的投资性资产，并非真金白银。区块链和现实世界的法律与商业机制对接也还处于缓慢进展中，投机行为的盛行进一步分散了对基础设施的建设。
Web3技术也存在一定的局限性。首先是可扩展性亟待提高，由于Web3去中心化的特点，在上面的交易会相对缓慢。由于节点众多，交易等状态的改变需要由矿工处理并在整个网络中传播，这需要花费较长的时间，牺牲了效率。其次是可访问性和用户体验尚且不足，使用门槛较高，目前缺乏Web3和现代网络浏览器的有效整合，大多数普通用户无法访问Web3。
此外，由于使用Web3应用需要连接区块链钱包，对于普通用户来说使用门槛和学习成本较高，这可能是目前Web3应用推广最大的障碍之一。最后是成本问题，在以太坊虚拟机上的每一个操作都有相对应的gas成本，智能合约通常包括多个操作，执行一个智能合约的操作加起来甚至可能花费数十万gas。由于成本高昂，大多数成功的Dapp只在区块链上放了很小的一部分代码。
结语 “如果你问1989年的人们，为了使生活变得更好，他们需要什么，他们的答案不可能是一个用超文本连接的信息节点组成的去中心化网络。”
我们正处于互联网新时代的黎明之际，由于Web3的复杂性以及Web2商业和经济模型的成熟，实现从Web2向Web3的飞跃可能需要数十年的时间，这种改变是困难的，因为互联网的下一次迭代需要一种与当下主流思想不同的思维范式。
对Web3不屑一顾是很容易的，我们可能还需要数年之久才会探索出最好的模型，然而历史不会重演细节，但过程却重复相似，以史为鉴，可以知兴替，历史上所有的巨大变革都伴随着不断的反复，总有人唱衰，总有阶段性倒退，但正是这些局部和阶段性的反复给那些真正有远见的人留下了机会和位置。
我们仍然处于不断质问掌握这一切意味着什么的最初阶段，在这个过渡时期，将给企业家、人才、投资者和任何类型的生态系统参与者带来许多机会。
坚信时间是宇宙唯一的货币，保持开放的心态，在Web3做一个坚持长期主义的builder。未来已经到来，只是还没有均匀分布，Web3的大门才刚刚开启，值得我们期待和拥抱，能够在这个时代躬身入局，在浪潮中上下求索，我们是幸运的，WAGMI！！！</content></entry><entry><title>mRNA疫苗原理</title><url>https://lizj3624.github.io/post/mrna/</url><categories><category>mRNA疫苗</category><category>生物技术</category></categories><tags><tag>mRNA疫苗</tag><tag>生物技术</tag></tags><content type="html"> 公众号看到mRNA疫苗科普的文章，感觉不错，再次收藏一下
前言: mRNA疫苗：疫苗行业新王朝的崛起 2020年初，一场突如起来的传染病大流行给全世界带来了巨大变数。拥有与18年前“非典”罪魁祸首SARS病毒相似的部分结构，新型冠状病毒（SARS-CoV-2）甚至拥有了更强大的传染能力和应对温度变化的能力。全球每月新增病例数一路走高，春夏秋冬的自然变化对病毒几乎无影响。在此情况下，人类把终结这一疫情大流行的唯一希望寄托在疫苗的出世。各国医疗机构、企业纷纷投入这一领域中。新冠疫苗研发既让企业履行了社会责任，同时也给予企业巨大的市场空间。全球总人口超过77亿，建立起全球性的免疫屏障需要百亿剂以上的新冠疫苗。在此双重激励下，全球涌现出许多优秀的疫苗企业，以中美德三国为领导者，在1年内用前所未有的速度研制出相应的新冠疫苗，让深陷疫情泥潭的世界看到了曙光。而这些优秀的疫苗中，刚刚登上舞台便最为闪耀的一个品种是mRNA疫苗。
mRNA疫苗打破了传统灭活、减毒疫苗的免疫激活模式，创新性地利用人体本身细胞生产抗原，以此激活特异免疫。mRNA疫苗具有极高的有效保护率，同时相较于其他创新型疫苗（如：DNA疫苗、病毒载体疫苗）具有更高的安全性。在研发上，mRNA疫苗能够快速地更新迭代以应对不断出现的变异毒株。由于mRNA疫苗不需进行体外转译，因此生产过程也有所缩短，仅需要60-70天。
美国疫情的好转印证了mRNA疫苗的有效性。自美国总统拜登签署“百日疫苗接种计划”后，美国每日新增病例显著下降。
国内第一轮疫苗接种已接近尾声，短期内疫苗需求落至低点，但海外疫情持续蔓延，市场机会可观。长期来看，随着灭活疫苗有效期临近以及病毒变异加速，在2021年底2022年初国内可能会出现第二轮疫苗需求的高峰。
mRNA的应用前景非常广阔。除了能够用于预防传染性疾病，mRNA疫苗也为治疗肿瘤、免疫疾病带来了新的星火。在新冠疫情前，国际mRNA厂商的研究重点集中在肿瘤的治疗上。目前国际mRNA疫苗三巨头为：BioNTech、CureVac、Moderna，均布局了多条针对肿瘤的管线。除传染病和肿瘤免疫疾病外，mRNA疫苗在许多基因相关的疾病中都有开发潜能。在后新冠疫情时代，mRNA疫苗仍旧具备大幅增长的潜力。
mRNA疫苗的技术壁垒在于序列设计和递送系统。序列设计需要公司拥有大量长期的数据积累，不断训练优化平台。优秀的序列设计能够提高mRNA在体内的留存和作用时间，降低免疫原性，使mRNA序列更高效地表达抗原蛋白。递送系统则是mRNA的运载火箭，负责将mRNA成分完整地运送至目标靶点，并且在合适的时机和环境条件下及时释放。同时，递送载体需要经过人体免疫系统的层层保护，容易引起过敏等免疫反应，伤害疫苗的安全性。递送系统还很大程度决定了mRNA疫苗的储藏条件和储藏时限。目前拥有此技术的公司非常稀少，同时具有专利保护壁垒，是mRNA疫苗行业“卡脖子”的技术之一。
艾博生物、斯微生物是国产mRNA疫苗进展最快的两家企业，除此之外，复星医药获得了BioNTech新冠疫苗大中华区的代理，mRNA新冠疫苗能否为公司创造盈利值得持续关注。
免疫系统及疫苗工作原理 免疫系统概览 人体免疫系统是一个以功能作为定义的系统，而非由器官作为定义的系统。其中包含皮肤、黏膜等物理屏障，肝脏等器官分泌的蛋白化学物质，也包括巨噬细胞、T细胞等生物类保护分子。
免疫系统可分为固有性和获得性免疫。
固有性免疫是人体天生带有的免疫系统，具有非特异性、反应快速等特点。获得性免疫则具有特异性，在首次感染时反应较慢。
一般情况下，抵御外源性入侵物质的第一道防线是固有性免疫。固有免疫中又可分为外部防御和内部防御。外部防御的典型是皮肤以及黏膜，是人体整套防御系统的排头兵。若外部防御被突破，内部防御将筑起第二道防线，其中包括吞噬细胞、抗微生物蛋白质、自然杀手细胞（NKcell）等。
若固有免疫无法成功防御入侵，获得性免疫则会启动。由于获得性免疫具有特异性，因此针对特定入侵物质的防御效果较为明显。常见的获得性免疫可分为体液免疫和细胞免疫。目前，几乎所有疫苗的最终目的都是激活此处所提到的获得性免疫。
获得性免疫作用原理 如其名，获得性免疫指后天得到的免疫。具体可分为体液免疫和细胞免疫。
体液免疫的核心细胞是B细胞（B cell）。原始B细胞在接触到外源性抗原后便被激活，并根据抗原成长分化为特异性B细胞，开始分泌特异性抗体。抗体能够识别入侵病原体表面的抗原，并与其结合。抗体本身没有杀死病原体的物质，但它能够与病原体结合使其失去感染其他细胞的能力，同时引导其他免疫细胞，例如巨噬细胞，将病原体吞噬，一些抗体能加速病原体细胞的分解。根据克隆选择理论（thecolonal selection theory），病原体被杀灭后，特异化B细胞会继续留在体内，成为免疫系统的一段“记忆”。若再次遇到相同抗原时，留存的B细胞便能快速扩增、分泌抗体，而不需重新从原始B细胞开始分化。因此，首次感染时，B细胞特异免疫反应较慢；而后二次感染时，B细胞特异免疫反应速度则非常迅速。同时，由于特异性B细胞会留存于体内，抗原出现频率越频繁，针对此抗原的特异性B细胞扩增数量越多，因此，特异免疫的反应也会越来越快越来越强。这是许多疫苗需要多剂次加强的原因。
细胞主导免疫的核心细胞是T细胞（T cell）。T细胞分为2类：辅助T细胞（CD4+）和杀手T细胞（CD8+）。当外源性蛋白质进入体内，部分蛋白会被抗原呈递细胞（Antigen Presenbting Cell，APC）捕捉。常见的APC包括树突细胞（DendriticCell，DC）、B细胞等。APC通过TLR（Toll-Like Receptor）分辨是否是外来抗原。若识别结果为外来抗原，APC会将抗原片段以抗原-MHC结合体的形式暴露在APC细胞膜表面。当辅助T细胞的受体（TCR）与MHC-抗原结合时，辅助T细胞会开始复制并释放细胞素，激活B细胞和杀手T细胞。杀手T细胞被激活后通过MHC结构与APC结合，并释放穿孔素和颗粒酶。穿孔素会附着在目标细胞膜上形成穿孔，颗粒酶通过穿孔进入细胞内部溶解细胞。当病原体消灭后，部分CD4+和CD8+T细胞会继续留在体内，称为记忆T细胞。与记忆B细胞类似，记忆T细胞拥有对抗原的特异性。若未来遭遇相同的外来抗原，T细胞能够迅速扩增激活，杀灭入侵的病原体。
总体而言，获得性免疫的激发来源于对抗原的识别。当某一病原体首次入侵时时，由于没有现成的特异化B细胞和T细胞，获得性免疫的应答时间较长。原始B细胞和T细胞需要时间分化形成特异性免疫细胞。在完成首次杀灭后，部分特异化的B细胞和T细胞会留存于体内成为记忆B细胞、记忆T细胞。若未来再次遭遇相同抗原入侵，无需原始B/T细胞重新分化，记忆B细胞和T细胞将自我扩增、激活，迅速启动免疫应答。
疫苗一般性原理 疫苗的目的是让人体形成特异性的记忆B细胞和记忆T细胞。在免疫记忆形成后，若人体遭到此病原体袭击，获得性免疫能够迅速应答，在病原体大规模感染其他细胞前，将病原体和已被感染的细胞杀灭。
目前，绝大部分疫苗的逻辑是通过递送抗原，使人体自发形成特异性免疫反应。相较于直接注射抗体或特异性T细胞，人体自发形成的免疫具有更好的持续性，同时免疫原性更低。直接注射的外源性抗体或T细胞本质上也属于外来物质，在人体内容易遭受免疫系统攻击。同时，抗体和T细胞本身具有半衰期，免疫有效时间短。由于直接注射的抗体或T细胞无法成为人体免疫记忆的一部分，因此，人体不能直接复制注射进入的抗体或T细胞，所以无法在遭遇抗原时快速扩增，免疫反应较弱。
直接递送抗体或T细胞的做法不适用于预防领域，但在部分治疗领域能够发挥作用。目前关注度较高的抗体药便是将人为制造或编辑的抗体导入人体内，直接由注入的抗体对特定细胞进行杀伤或抑制。CAR-T疗法则是直接递送经过人为编辑的T细胞（称为CAR-T细胞）进入体内，由这部分改装过的CAR-T细胞直接杀伤目标细胞（例如肿瘤细胞）。
疫苗通过递送抗原激发人体特异性免疫反应。但与自然界中病原体入侵形成免疫记忆不同，疫苗往往只递送无毒无害的某一抗原片段进入人体。抗原本身是无害的，可视作一种标识，供免疫细胞进行识别。因此，疫苗本身并不带有毒性。
mRNA疫苗 mRNA疫苗是一种核酸疫苗，通过将病毒的部分mRNA片段注入人体细胞内产生抗原，再由此激发特异性免疫反应，达到形成免疫记忆的效果。
mRNA疫苗治疗原理：“巧”用自身细胞加强特异性免疫 DNA是存储人体遗传信息的载体。人体内绝大部分细胞都带有DNA。但是DNA本身无法直接对人体产生影响，各类蛋白质才是能够左右表象的物质（例如：抗原、激素）。DNA需要转化为蛋白质才能够将遗传信息表达出来。整个DNA转化为蛋白质的过程分为两大步，第一步：DNA转化为mRNA，这一步骤称为转录（transcription），发生在细胞核内；第二步：mRNA转化为蛋白质，这一步骤称为转译（translation），发生在细胞质中。可以看到，mRNA是DNA转化为蛋白质的中间体，这也是它名称的由来，即信使RNA（messenger RNA）。通俗来讲，DNA类似于底稿，DNA发生的改变会一直存在于体内，由此细胞分裂新产生的细胞也会继承这些改变，因此DNA的改变有很大概率会伴随一生，其中性细胞中DNA的变化甚至能够遗传至下一代。mRNA类似于说明书，能够指导自身细胞生产出特定的蛋白，但是mRNA的改变不会被分裂产生的新细胞继承，也不会遗传至下一代个体中。蛋白则是最终生产得到的工具，对生物个体的各项指标直接产生作用。同样地，蛋白不会被继承或遗传。这一条转录转译链被称为生物学“中心法则”。mRNA疫苗利用了两步表达的机理，使疫苗在不改变DNA序列的同时，为人体免疫系统的激活提供更准确的抗原蛋白以及更持久的抗原体内留存时间，使被激活的特异性免疫更精准，同时免疫效果得到巩固。
具体来分析mRNA新冠疫苗的机理。mRNA疫苗中的mRNA片段编码新冠病毒表面的某些蛋白或受体，例如刺突蛋白（S蛋白）。疫苗递送人工编辑后的mRNA进入人体细胞，在体内“借用”人体自身细胞转译mRNA为蛋白质。此类mRNA在经过转译后会表达成为病毒所具有的某种抗原蛋白。虽然产生的抗原是由自身细胞制造，但由于其氨基酸序列具有外源性，APC中的TLR并不识别此段序列，因此仍旧会激发B细胞和T细胞针对此抗原蛋白的特异性免疫反应，并建立免疫记忆。
LNP递送系统：递送疫苗有效物质进入预定轨道的运载火箭 如今，病毒遗传信息序列的解码和反向序列合成已不是难题。如何将合成好的mRNA序列递送进入人体细胞变成了mRNA疫苗研发的重要挑战之一。
人体细胞结构从外至内可分为细胞膜（cellmembrane）、细胞质（cytoplasm）、细胞核（nucleus）。mRNA转译成蛋白质的过程发生在细胞质中，因此，mRNA疫苗要发挥作用，必须先将编辑好的mRNA转递进细胞质中。进入细胞质需要通过细胞膜，细胞膜由磷脂双分子层构成，磷脂分子头部具有亲水性，尾部具有疏水性，两层磷脂尾部相对形成双分子层，能够有效控制水分子、离子、大分子物质通过。mRNA作为大分子（300-5000kDa），在不破坏细胞膜的前提下，进出细胞只能以内含体（endosome）通过胞吞作用（endocytosis）。通常情况下，内含体进入细胞质后，会被直接送至溶酶体（lysosome）进行分解。为保证mRNA在转译前保持完整性，mRNA需要在内含体与溶酶体结合前打破内含体包膜（endosomaldisruption）并逃离。逃离内含体进入细胞质后，mRNA便会在细胞质内游动，直至到达核糖体（ribosome）并在此转译为肽链，最终折叠成为蛋白质。
对于mRNA疫苗和药物，递送系统有两大职责：一是有效包裹和保护mRNA在到达靶点前维持稳定，二是帮助mRNA有效成分进入细胞，三是在mRNA到达溶酶体前将其释放进入细胞质中。
LNP是目前最具潜力的递送载体之一。LNP（Lipid Nanoparticle）是脂质微粒的总称，其中又包括脂质胶团（micelle）、脂质体（liposome）等。LNP与细胞膜的组成成分相似，均由脂质分子构成。脂质分子的两条长尾通常呈平行状态，在此状态下，脂质形成的双分子层稳定。在进入细胞质酸性环境后，部分脂质的头部质子化，呈现阳离子形态，与其他阴性离子态的脂质分子相吸引，尾部张开。原本双分子层的形式被破坏，形成头部聚集在一起的环状。之前包裹在内的mRNA便可逃逸出内含体，进入细胞质等待转译。
为了提高载体对包裹成分的保护能力，通过在载体外部连接PEG可以进一步增强载体的稳定性。
mRNA疫苗相较于其他技术路径疫苗的优劣势分析 （1）mRNA疫苗 vs. 灭活疫苗：具有明显的免疫保护力优势
与传统灭活疫苗、裂解疫苗相比，mRNA疫苗激活特异免疫的路径不相同。传统疫苗激活特异性免疫的方式是直接将抗原蛋白注射进入人体，引起免疫反应；而mRNA是将编码病毒抗原的mRNA注入体内，由人体自身细胞产生对应的抗原，以此激活特异性免疫。理论分析，mRNA疫苗能够呈现更多的抗原，同时能更持久地激活巩固特异性免疫。原因在于，传统灭活疫苗的抗原呈递数量是一定的，即最终到达体内引起免疫反应的抗原数量只能够小于或等于疫苗中含有的抗原数量。同时，灭活疫苗呈递抗原的过程是一次性的，注射时疫苗呈递的抗原即为所有抗原，这些抗原的降解时长即为持续激活免疫的时长，此后不会有新增抗原。而mRNA疫苗抗原呈递的过程是可短暂持续的，呈递的mRNA可指导多个核糖体产生抗原蛋白，直至mRNA 降解。由于细胞能够不断根据mRNA生产抗原蛋白，因此抗原数量受疫苗剂量所限制较小，从时间维度上看，抗原不会在短时间内迅速被消耗完毕。抗原数量水平越高、保持时长越长，形成的特异性免疫记忆越强烈，免疫应答更快、持续时间越长。
（2）mRNA疫苗 vs. DNA疫苗：更高效，逆转录风险较小
与核酸疫苗中另一路径的DNA疫苗相比，mRNA疫苗更有效也更安全。DNA疫苗需要将包裹的有效成分递送通过两层屏障：细胞膜和细胞核膜，最终进入细胞核内开始抗原蛋白的表达。多层屏障导致有效成分难以进入反应场所，免疫激活更难。同时，由于DNA疫苗呈递的有效成分需要进入细胞核内，导致外源遗传片段逆转录进入人体DNA的概率增加，引起肿瘤癌症的概率增加。相较而言，由于mRNA疫苗导入的外源物质不需进入细胞核，发生外源遗传片段逆转录进入人体自身DNA的概率较小，因此引起肿瘤癌症的概率极小。
（3）mRNA疫苗 vs. 病毒载体疫苗：适用人群覆盖全面，逆转录风险较小，机会成本更低
LNP为递送mRNA片段到达靶点、定点释放提供了支持。另一大受到较高关注度的载体平台是病毒载体平台，常见的类别有腺病毒（Adenovirus）、腺相关病毒（Adeno-Associated Virus，AAV）、慢病毒（lentivirus）。病毒载体通过去除病毒本身的有害物质，保留感染能力，将目标物质递送进入细胞内，由细胞产生抗原蛋白，进而引起特异性免疫反应。病毒载体反应的一大缺陷是，若接种者本身体内含有针对此病毒载体的抗体（如腺病毒、AAV、慢病毒，而非针对目标抗原的抗体），或在短时间内快速产生了抗体，则病毒载体疫苗无法将有效成分递送进入预定的细胞质内。相比之下，LNP的结构由脂质分子构成，载体引起免疫反应的几率较小，能够更有效地递送有效成分至目标靶点。除此之外，部分病毒平台有发生逆转录的概率，会将外源基因整合进入人体DNA中，可能导致肿瘤、免疫疾病等。同时，病毒载体疫苗具有更高的机会成本。当人体接受病毒载体疫苗注射后，体内会自动产生针对此载体的抗体和其他特异免疫反应。此后再次运用相同或相似病毒载体作为递送系统给药时（例如一些肿瘤治疗药物），会更容易遭到免疫系统的攻击，难以成功将药物递送至靶点。
mRNA新冠疫苗临床数据解析：No pain, no gain mRNA疫苗的临床运用历史始于2020年新冠疫情。根据WHO数据，截止2021年5月7日，全球共有15款mRNA疫苗在研，其中包括已纳入WHO紧急使用名单（Emergency Use Listing，EUL）的2款mRNA疫苗：由辉瑞/BioNTech联合研发的BNT162b2，以及由Moderna研发的mRNA-1273。
mRNA疫苗展现了令人振奋的保护率 2020年11月18日，辉瑞发布了BNT162b2的III期临床试验结果，结果显示疫苗整体保护率高达95%。2021年3月31日，Moderna发布了mRNA-1273的III期临床试验结果，结果显示疫苗整体保护率也达到94.1%，与BNT162b2的数据非常接近。2款mRNA疫苗同时展现出极为优异的保护率，共同预示着mRNA疫苗技术在激活免疫系统上的令人震惊的高效，也让科学界对mRNA疫苗技术未来在其他疾病领域可能带来的改变充满期待。同时，mRNA疫苗在65岁及以上的老年群体中，仍能高效地激发免疫反应，保护率稳定在高水平。
（1）辉瑞/BioNTech mRNA疫苗（BNT162b2）有效性
临床试验数据分为两部分。第一部分，样本人群为在实验前或实验开始时均未感染新冠病毒的人群，本样本人群共有36523人，其中疫苗组18198人，均接受2剂BNT162b2注射；另外18325人为安慰剂组，接受2剂安慰剂注射。在完成2剂接种7天后，疫苗组出现8例新冠感染者，安慰剂组出现162例，疫苗有效保护率达到95.0%。
第二部分样本人群包括感染和未感染新冠病毒的人群。样本人数40137人，其中疫苗组19965人，安慰剂组 18325人。在完成2剂接种7天后，疫苗组中出现9例新冠感染者，安慰剂组169例。疫苗有效保护率达到94.6%。
根据年龄段划分，BNT162b2对16-64岁人群的保护率为95.1%，对65岁及以上的老年群体保护率则维持在了94.7%。数据显示了mRNA疫苗在人群中激活免疫系统的能力基本不受接种者年龄的影响。
（2）Moderna mRNA疫苗（mRNA-1273）有效性
全球领先上市的另一款mRNA新冠疫苗是Moderna公司与美国国家过敏及传染疾病研究所（NIAID）研发的mRNA-1273。这款疫苗的技术路径与辉瑞/BioNTech的mRNA疫苗相同，临床结果也展现了令人振奋的保护率，以及较低的不良反应发生概率。
根据Moderna公司给医疗服务机构的事实陈述，mRNA-1273的保护率达到约94.1%（95%CI：89.3%-96.8%）。
在针对18岁以上人群的临床试验中，科学家将样本人群分为两组：疫苗组14134人，均接受2剂mRNA-1273注射；另外14073人为安慰剂组，接受安慰剂注射。在完成第2剂接种14天后，疫苗组中出现新冠病例11例，每年每千人病例数为3.328；安慰剂对照组中出现新冠病例185例，每年每千人病例数为56.510。由此测得，疫苗保护率约为94.1%，与辉瑞/BioNTech的mRNA新冠疫苗临床有效率非常相近。Moderna和辉瑞/BioNTech mRNA疫苗的临床实验结果都显示出采用mRNA技术路径的疫苗具有极高的有效性。
本次临床试验的样本人群中包含了65岁及以上的老年人群，疫苗组中有3583位老年人，其中出现4例新冠感染；安慰剂组中有3552位老年人，其中出现29例新冠感染。因此，mRNA-1273对于65岁及以上的人群的有效保护率为86.4%，表现仍旧非常优秀。
（3）国药集团灭活疫苗（WIV04/HB02）有效性
为了更直观地展现mRNA疫苗与传统疫苗在不同指标上的差别，我们在此引用使用最为广泛的灭活型疫苗进行对比。国药集团及北京生物研究所、武汉生物研究所共同研发的WIV04和HB02是2款最先上市的传统灭活疫苗。
2021年5月26日，JAMA发布了国药集团2款灭活新冠疫苗的临床III期结果。临床结果展现了不错的保护率，整体保护率均在70%以上，远远超出了世界卫生组织50%的要求。
具体数据如下：接种WIV04 的12743人中，出现26例新冠感染；接种HB02的12726人中，出现21例新冠感染；安慰剂组共12737人，出现95例新冠感染。由此可计算得到WIV04的保护率为72.8%（95%CI：58.1-82.4），HB02的保护率为78.1%（95%CI：64.8-86.3）。2款灭活疫苗整体保护率相近，但是与2款mRNA疫苗>90%的保护率相比，仍旧略逊一筹。
mRNA疫苗不良反应：短期反应略高于传统疫苗，需要时间验证长期安全性 除了有效保护率外，疫苗的另一重要指标是不良反应发生的种类和概率。总体来说，灭活疫苗因其成熟的技术和研发生产经验，不良反应发生频率较低，反应程度也较为温和。mRNA疫苗则运用了全新的技术，目前得到的安全数据只反映了接种后短期内可能发生的不良反应，是否会对人体造成长期的影响还需要时间进行长期的观察。
从理论分析，mRNA疫苗通过使部分人体细胞表达外源抗原来激活免疫，除了抗原本身会引起免疫反应，这部分表达抗原的自体细胞可能也会引起较强烈的免疫反应。灭活疫苗则是直接呈递抗原，因此免疫反应较小。
（1）辉瑞/BioNTech mRNA疫苗（BNT162b2）安全性
临床试验记录了样本人群每剂次接种后7天以内的不良反应，并将样本人群分为3个年龄阶段：12-15岁、18-55岁、56岁及以上，以研究疫苗对青少年和老年人是否安全。总体来说，第二次接种后绝大多数各类不良反应出现的概率均高于第一次接种后。局部不良反应中，注射处疼痛报告比例较高，第一次、第二次接种后报告疼痛的比例为83.1%、77.8%（对应安慰剂组14.0%、11.7%），其中严重疼痛以致于无法进行日常活动的比例为1.0%、1.2%（对应安慰剂组0.1%、0.0%）。系统性不良反应中报告最多的是头痛和疲惫。在18-55岁主要年龄层的研究中，第一次接种后头痛和疲惫的出现几率分别为41.9%、47.4%（对应安慰剂组33.7%、33.4%），第二次接种后的几率分别为51.7%、59.4%（对应安慰剂组24.1%、22.8%）。其他不良反应中，接种第一剂疫苗后，呕吐、腹泻出现的概率分别为1.2%、11.1%，但安慰剂组的对应概率也分别达到1.2%、11.7%，不良反应出现概率与疫苗组持平甚至更高，因此无法判断此类不良反应的出现是否和疫苗接种有因果关系。相较于第一剂接种，第二剂接种后出现不良反应的概率要更高，出现发热的频率达到15.8%（对应安慰剂组0.5%），发冷、肌肉疼痛和关节疼痛的出现频率也较高，分别为35.1%（对应安慰剂组3.8%）、37.3%（对应安慰剂组8.2%）、21.9%（对应安慰剂组5.2%）。
56岁及以上人群接种疫苗后不良反应的发生频率并未显示出疫苗会对老年群体造成更严重的副作用，老年人群报告的不良反应发生频率甚至略低于18-55岁年龄段的水平。不同种类的不良反应发生规律与18-55岁年龄层类似，头疼和疲惫的发生频率较高。 12-15岁年龄层人群接种疫苗后不良反应的发生规律与其他两个年龄层相似，不良反应发生概率略高于其他两个年龄层。12-15岁年龄层人群接种疫苗后出现发热的概率较高。接种第一剂后的发热概率为10.1%（对应安慰剂组1.1%），接种第二剂后的发热概率为19.6%（对应安慰剂组0.6%）。
根据CDC数据，截至2021年1月18日，接种BNT162b2疫苗后引起的过敏反应在每百万人中仅出现5例，概率极低。
（2）Moderna mRNA疫苗（mRNA-1273）安全性
Moderna mRNA-1273的临床不良反应研究记录了每剂次接种后7天以内的不良反应，将样本人群分为2个年龄阶段：18-64岁、65岁及以上，同时每个年龄层中分为疫苗组和安慰剂组。总体来说，第二次接种后绝大多数各类不良反应出现的概率均高于第一次接种后。
局部不良反应中，疼痛仍旧是占比最高的，第一次和第二次接种后报告疼痛的比例分别为86.9%、89.9%（对应安慰剂组19.1%、18.7%）。其中三级疼痛报告比例分别为3.2%、4.6%（对应安慰剂组0.2%、0.2%）。
系统性不良反应中，疲惫报告比例仍旧最高，第一次和第二次接种后报告疲惫的比例分别为38.4%、67.6%（对应安慰剂组28.8%、24.6%），与BNT162b2数据相近。
不良反应种类中，除注射处疼痛外，报告最多的不良反应是头痛和疲惫。在18-55岁主要年龄层的研究中，第一次接种后头痛和疲惫的出现几率分别为41.9%、47.4%（对应安慰剂组33.7%、33.4%），第二次接种后的几率分别为51.7%、59.4%（对应安慰剂组24.1%、22.8%）。其他不良反应中，接种第一剂疫苗后，呕吐、腹泻出现的概率分别为1.2%、11.1%，但安慰剂组的对应概率也分别达到1.2%、11.7%，不良反应出现概率与疫苗组持平甚至更高，因此无法判断此类不良反应的出现是否和疫苗接种有因果关系。相较于第一剂接种，第二剂接种后出现不良反应的概率要更高，出现发热的频率达到15.8%（对应安慰剂组0.5%），发冷、肌肉疼痛和关节疼痛的出现频率也较高，分别为35.1%（对应安慰剂组3.8%）、37.3%（对应安慰剂组8.2%）、21.9%（对应安慰剂组5.2%）。
65岁及以上人群接种疫苗后不良反应的发生规律与18-64岁年龄层类似，局部不良反应中疼痛的出现频率较高，第一次和第二次注射后出现概率分别为74.0%、83.2%（对应安慰剂组12.8%、12.0%）。系统性反应中，头疼和疲惫的发生频率较高。第二剂接种后，发热、发冷、肌肉关节疼痛等不良反应出现概率较第一剂接种后数据上升较为明显。
2款mRNA疫苗的III期临床试验不良反应数据方面接近，局部反应中疼痛最为普遍，在主要人群中第一剂次和第二剂次平均出现概率为82.4%、85.0%（对应安慰剂组16.3%、15.6%）。系统性不良反应中疲惫与头痛出现比例较高，在18岁及以上人群接种第二剂次后，疲惫与头痛的报告比例分别为，三级及以上疲惫的出现概率平均为7.68%（对应安慰剂组0.67%），三级及以上头痛的出现概率为3.99%（对应安慰剂组0.99%）。
（3）国药集团灭活疫苗（WIV04/HB02）安全性
传统疫苗例如灭活疫苗相较而言较为安全，不良反应出现频率低。灭活疫苗采用的技术路径相对简易，外源物质不需要进入细胞（mRNA需要进入细胞质），因此激发的免疫反应较温和。从临床数据来看，灭活疫苗这一技术路径已经过长期不同种类疫苗的验证，并未发现长期对人体有负面影响。
由于统计标准不同，从国药集团2款灭活疫苗的III期临床数据中，我们摘取了第一剂接种后0-28天内（期间部分样本人群接种了第二剂疫苗）发生的不良反应报告。发生最普遍的仍旧是疼痛，平均发生频率为21.8%（对应安慰剂组27.9%），显著低于mRNA疫苗80%左右（对应安慰剂组15%左右）的水平，并且疫苗组数据小于对照组数据。系统性不良反应中，报告频率较高的是疲惫与头痛，分别为11.3%、13.4%（对应安慰剂组10.8%、13.0%），其中三级疲惫与头痛报告比例分别为1.1%、1.0%（对应安慰剂组&lt;0.1%、&lt;0.1%），显著低于mRNA疫苗数据。
从不良反应发生比例来看，灭活疫苗接种后短期内各项不良反应发生比例明显低于mRNA疫苗。虽然三款疫苗临床试验对于不良反应的定义不同，对照组不同，数据收集周期有差别，但数据上巨大的差异仍能或多或少地体现出mRNA疫苗会带来较多较强烈的不适。发热，作为能够进行横向量化对比的不良反应之一，在接种mRNA疫苗后出现频率远远高于接种灭活疫苗后的频率。接种灭活疫苗后发热（38.0°C以上）的发生比例平均为0.4%，38.5°C以上的发生比例为0.2%；接种mRNA疫苗后发热（38.0°C以上）的平均发生比例为17.1%，39°C及以上的平均发生比例为1.7%，均高于灭活疫苗的对应数据。
mRNA疫苗临床数据特点：No pain，no gain mRNA疫苗同时具有高保护率和相对更多的不良反应。英美俗语“Nopain, no gain” （“没有痛苦便没有收获”），贴切地形容了mRNA疫苗的特点。
mRNA疫苗对新冠病毒的保护率高达94%以上，国药传统灭活疫苗的保护率虽远远高于WHO和FDA建议标准的50%，但不足80%，与mRNA疫苗差距明显。
同时，两款mRNA疫苗均对64岁以上的老年人群展现了非常可观的保护率。BioNTech的BNT162b2对64岁以上群体的保护率为94.7%，仅比16-64岁群体数据低0.4%。Moderna的mRNA1273对64岁以上人群的保护率也高达86.4%，仍旧高于灭活疫苗的整体数据。
mRNA疫苗严重/致命性不良反应罕见但需关注 mRNA疫苗的各项不良反应发生率都较为明显地高出灭活疫苗对应水平，会让接种者在短期内产生更多的不适感。但在临床试验中并未出现严重甚至致命性的不良反应。
各类新冠疫苗在真实世界中开始运用后，不出意外地，开始出现一些此前在实验阶段未曾出现的不良反应，例如血栓伴血小板减少症候群、心肌炎和心包炎等。
根据美国CDC和FDA数据，截至2021年6月21日，美国共有3款新冠疫苗可供使用，分别为2款mRNA疫苗（辉瑞/BioNTech、Moderna）和1款病毒载体疫苗（强生/杨森）。目前美国共接种3.18亿剂次新冠疫苗，其中病毒载体疫苗（强生）接种剂次超1200万剂次，mRNA疫苗超3亿剂次。
综合3款新冠疫苗的数据，接种后发生过敏的概率为每百万人中2-5人（概率0.0002%-0.0005%）。
美国疫苗不良反应报告系统（VAERS）目前接到有关心肌炎、心包炎的报告616起（发生概率0.0001%），CDC和FDA已确定其中393项，其中大部分发生在mRNA疫苗接种后，发生人群集中在男性30岁以下的青中年群体。
CDC和FDA确定了有关接种病毒载体新冠疫苗后发生血栓伴血小板减少症候群（TTS）的报告36例（发生概率&lt;0.0003%），接种ModernamRNA新冠疫苗后发生TTS的报告1例。
VAERS显示接种新冠疫苗后出现死亡案例5479例（0.0017%），其中是否存在和疫苗的因果关系仍需进一步观察分析。
mRNA疫苗与灭活疫苗各有优势，但不可否认的是mRNA疫苗借着新冠疫情的契机已经展示了自己的临床潜力，并且在研发和生产上也具有独特的优势，会在下文详述。
新冠疫情为mRNA疫苗登上舞台带来机遇 mRNA疫苗效果初显，免疫屏障减缓病例新增 mRNA疫苗的临床表现喜人，在现实生活中，mRNA疫苗的针对新冠病毒的有效保护性也得到了宏观数据的支撑。部分国家大规模的疫苗接种逐渐形成了一道免疫屏障，新增新冠感染数量有明显放缓的趋势。
美国是此前新冠疫情最为横行肆虐的国家。根据美国CDC数据，2020年12月美国月新增新冠病例619万例；2021年1月新增达到627万例，累计确诊2613万例，死亡病例数44.8万人，是世界上累计确诊最多，死亡病例数最多的国家。2020年12月下旬，辉瑞/BioNTech和Moderna的疫苗相继获得紧急使用准入。2021年1月20日，新任美国总统拜登上台，并于就职第二天立即签署了数条有关推动疫苗接种的行政指令，并确定了“100天1亿剂次接种”的目标。2021年2月，美国累计接种7524万剂次，每一百人中有14.88人接种了至少1剂次，每一百人中7.41人完成了完整的疫苗接种；3月，累计接种1.48亿剂次，每百人中有28.72人接种至少一剂，15.97人完成完整接种。相应地，美国2月新增新冠病例数下跌至251万例，降幅约60.0%；3月进一步下降至175万例，降幅约30.3%。
数据直观地反映了疫苗接种率与新增新冠病例数之间相反的关系。虽然新增病例数的下降有许多其他因素，但是新冠疫苗毫无疑问是新增数量腰斩的一大主要因素，同时非常明显地抑制了美国的第三波疫情。
短期：国产mRNA疫苗应聚焦海外放量 新冠疫情爆发后，国内各科研机构、企业迅速响应，开始研发针对新冠病毒的疫苗，并且在短短不到两年的时间内取得了亮眼的成绩。截至2021年6月4日，国内获批上市的疫苗包括国药与北京生物、武汉生物研制的灭活疫苗、科兴的灭活疫苗、康泰生物的灭活疫苗、康希诺的腺病毒载体疫苗、智飞生物的重组蛋白疫苗。
短期内，国内新冠疫苗市场已被传统的灭活疫苗占据。截至2021年6月4日，国内疫苗接种剂次已达7亿剂次。18-59岁年龄层为新冠疫苗适龄人群，以2020年第七次全国人口普查数据为标准，我国15-59岁人口约8.94亿人。大部分适龄人群已接受第一剂注射。
大部分疫苗需要多次接种完成完整的免疫过程，在此过程中，接种同一厂家或技术路径的疫苗能够较为稳妥地实现免疫激活的既定目标。目前没有已完成的临床试验可以证实接种不同技术路径的疫苗的安全性，或是能够达到预定的免疫效果。因此，后续疫苗很大可能仍会按照同一厂家同一路径完成接种，短期内mRNA新冠疫苗在国内市场的空间有限。
虽然国内市场已较为饱和，但与此同时，海外疫情持续发酵。2021年3月，全球新增新冠确诊人数1404万例，4月新增2319万例，累计确诊人数也一路飙升。
美国疫情控制已经证实了疫苗带来的免疫屏障能够有效降低新增病例数，建立覆盖全球的免疫屏障是世界经济重回正常的必经之路。由于全球新冠疫苗获WHO紧急使用的种类少，且产能有限，疫苗仍旧处于紧缺状态，尤其是经济科技相对落后的发展中国家。2021年5月，全球新冠疫苗累计接种19.07亿剂次，每百人中接种至少1剂次的约10.73人。根据世界银行数据，2019年全球15-64岁人群占比65.252%，若不考虑患有基础疾病无法接种的人群，则适龄人群中每百人未接种任何疫苗的人数为54.522人。全球人口为77.95亿，则未接种任何新冠疫苗的适龄人数约为42.50亿人，以每人2剂次折算，则理论空间为85.00亿剂次。
全球疫苗产能紧张，拥有疫苗技术和生产能力的国家十分有限，许多国家无法得到疫苗，尤其是经济科技较为落后的发展中国家。因此，新冠疫苗的海外市场有非常巨大的发展空间。
中长期：病毒变异或削弱一代疫苗效力，mRNA疫苗可快速反应应对变异 新冠的大范围传播增加了病毒变异的可能性。现有疫苗能否防范变异病毒成为社会关心的热点之一。普通群众对疫苗有效性感到担忧，投资者则关心是否会影响现有疫苗的放量情况。针对这一问题，mRNA疫苗效力遭到削弱的幅度有限，而对于传统灭活疫苗将会是一个严峻挑战。
mRNA疫苗：锚定S蛋白为靶点，变异影响有限 病毒变异对现有mRNA疫苗的影响有限，几乎没有可能出现使疫苗完全失效的情况。现有mRNA疫苗以新冠病毒的刺突蛋白（S蛋白）为抗原，人体产生的特异免疫会以刺突蛋白为标志物，对表达此蛋白的细胞分子发动攻击。因此，若刺突蛋白没有发生显著变异，疫苗激活的特异免疫仍能够识别病毒，病毒其他部分发生变异并不会影响这一识别过程。而刺突蛋白发生明显变异并使病毒维持相同感染能力的几率较小。刺突蛋白是新冠病毒打开人体细胞的钥匙，人体细胞上的对应受体则是锁孔，只有当钥匙与锁孔匹配时才能打开细胞的大门。若钥匙形状明显改变（刺突蛋白发生明显变异），则大概率无法与锁孔匹配，也就无法入侵细胞。因此，刺突蛋白变异会改变病毒的感染机理，大概率造成病毒感染能力丧失或减弱。通过锚定S蛋白，mRNA疫苗仍旧维持了部分针对变异病毒的保护性。长期来看，mRNA疫苗也需要更新迭代，以更精准地适应新型变异病毒。
mRNA疫苗的一大优势是可以通过简单的修改基因序列来产生不同的抗原。若病毒序列变异导致现有疫苗有效率明显下滑，mRNA疫苗厂商可以通过重新对病毒测序来确定变异后的刺突蛋白序列，并以此制成新的疫苗。
此外，mRNA疫苗可以同时包含针对多种不同病毒亚型的对应编码，达到同时激发几种特异免疫的效果。
灭活疫苗：一代疫苗逐渐无法应对多种变异 灭活疫苗依靠失去活性的整个病毒激发免疫反应。因此产生的免疫记忆并不锚定S蛋白，而是针对病毒携带的任意一种或多种抗原，因此每个接种者产生的特异免疫都不尽相同。因此，但病毒发生变异时，此前作为病毒识别抓手的抗原有可能发生改变，导致免疫系统无法识别出病毒。
国内第二轮新冠疫苗需求或为mRNA疫苗带来机遇 国内大规模接种的疫苗品种为灭活疫苗，根据上文分析，以SARS-CoV-2病毒为目标靶点的第一代灭活疫苗在应对病毒的不断变异中，效力会出现下降，造成免疫逃逸的风险。同时，目前公认的灭活疫苗的保护期约6个月，根据我国新冠疫苗接种剂次趋势，2021年底将出现第二轮新冠疫苗的需求潮。
国内新冠疫苗接种次数趋势如下：2021年3月27日突破1亿剂次、4月21日突破2亿剂次、5月9日突破3亿剂次、5月16日突破4亿剂次、5月24日突破5亿剂次、5月30日突破6亿剂次、6月3日突破7亿剂次、6月8日突破8亿剂次、6月15日突破9亿剂次、6月20日突破10亿剂次。每增加1亿剂次的间隔分别为25天、18天、7天、8天、6天、4天、4天、7天、5天，基本呈现出加速趋势。根据全国第七次人口普查结果，15-59岁人口约8.94亿人。以完整免疫需要接种2剂次新冠疫苗为标准，我国本轮新冠疫苗需求量约17.88亿剂次。
由于缺失大部分数据，我们无法得知数据中有多少人已完成整套接种。仅有2021年6月10日当日数据提到截至当日完成整套接种流程的人数，约为2.233亿人。以2剂次为标准，折算为4.466亿剂次，截至当日全国接种剂次总数为8.45亿剂次，用于完成整套接种的剂次数占总接种剂次数的26.42%。按照6个月保护期计算，截至2021年12月10日左右将有2.233亿人需要第二轮新冠疫苗接种。根据2021年6月10日数据，截至当日接种了一剂次的人数为3.984亿人，这一部分群体在2021年7月10日前将接种第二剂次，并且在2022年1月10日前开始进行第二轮的接种，届时国内市场将有约4亿剂次的新需求。
mRNA疫苗生产流程 第一步：DNA质粒制备 mRNA疫苗的生产可分为三大阶段，一是DNA原液制备，二是mRNA原液的制备，三是利用脂质微粒进行包封。在此，我们以辉瑞/BioNTech新冠疫苗BNT162b2的生产流程为例进行阐述。
原液制备开始于质粒构建。通常使用的DNA质粒为环状质粒，质粒上含有设计好的序列模块，其中包括刺突蛋白编码。利用电流打破细胞膜，并将环状DNA质粒引入大肠杆菌。此后，大肠杆菌被储藏于含有大量营养物质的溶液中进行繁殖扩增。大肠杆菌每20分钟分裂一次，4天内可以得到数万亿DNA质粒。提取并纯化DNA质粒，过滤溶液，去除细菌及其他物质。利用酶将纯化后的环状DNA质粒切割为链状。将所得溶液分装冷藏，通过质量控制环节，并运送至下一阶段的生产加工场所。此阶段生产过程耗时10天，若将质控和运输环节纳入考虑则共耗时约17天。
第二步：体外转录 第二阶段的目的是将DNA链转化为mRNA。上一步制备得到的DNA链与酶和核苷酸混合在10加仑容量的容器中，RNA聚合酶（RNA polymerase）会将DNA转录为mRNA。这一步骤被称为体外转录（IVT）。得到mRNA后，DNA以及其他物质将被滤除，mRNA被装进购物袋大小的塑料包装中，每袋含有约500万到1000万剂次的mRNA原料。经过经过质量控制和运输到达下一生产环节，这一阶段的生产耗时约4天，质量控制和运输耗时12天，共16天。 第三步：递送系统装载 第三阶段的流程目的是将mRNA包裹进脂质载体（LNP）中。脂质悬浮于酒精溶液中，与mRNA接触并将其包裹，两种物质通过相反电荷相吸引。之后，原液经过切向流过滤（TFF）滤除溶液中多余的脂质、酒精等杂质，并制成最终的mRNA疫苗溶液。此生产过程耗时约12天。辉瑞目前在一家位于密歇根的工厂进行这一阶段的生产，生产场地面积仅相当于一个能容纳一辆汽车的车库大小。场地内有100台混液装置工作，在30小时内制造了300万剂次的疫苗原液。此阶段是mRNA疫苗生产的最大瓶颈之一，其中一个重要原因是市场上提供脂质的厂商有限，因此辉瑞已开始自主研发制造脂质。但其中涉及的专利等问题仍旧为这一阶段的放大生产蒙上了一层阴影。
第四步：灌装检验 在上述三个生产阶段都完成后，mRNA疫苗原液已完成，只待灌装分发。辉瑞一管容器中包含6剂次的疫苗原液量。辉瑞位于密歇根州的工厂能够在2天内完成100万剂次的灌装。随后，经过2周的纯净度检测及其他安全性检测，疫苗便能销往世界各地。此过程共花费约19天。
以上所有生产灌装环节耗时约64天。
mRNA疫苗两大核心竞争力：序列结构、递送系统 以上我们分析了mRNA疫苗对于需求端相较于其他技术路径疫苗的优势与不足，可以确定的是，mRNA在需求端的吸引力正在不断上升。那么在供给端，决定mRNA疫苗竞争格局的要点与瓶颈集中在两大因素上：mRNA序列结构和疫苗递送系统。
mRNA****序列结构决定抗原蛋白结构、免疫原性及稳定性 疫苗产生的抗原蛋白的序列以及稳定性决定了其激活的特异免疫的精确性和活性。而抗原蛋白的序列和结构则由mRNA序列影响和控制。因此，mRNA序列决定了疫苗的质量，也是mRNA疫苗厂商的核心竞争力之一。
上文中提到生物学“中心法则”：DNA转录为mRNA转译为蛋白质。事实上，mRNA中只有部分片段会成为组成蛋白质的序列，其余部分则控制调节蛋白质的转译效率和结构。mRNA序列中，最终被转译成为蛋白质组成序列的部分被称为编码区域（translatedregion），编码区域前后分别有一个非转译区（untranslated region,UTR）。
编码区域决定了蛋白质中的氨基酸序列。编码区域中三个碱基为一组，称为密码子（codon）。密码子经转译成为特定的氨基酸，氨基酸串联后形成肽链，结构化后成为蛋白质。部分密码子组合会转译成同一种氨基酸（同义密码子Synonymouscodon），但在不同生物族群中，会存在对某一密码子组的偏好，此密码子组合的免疫原性较小，不易遭到酶类的攻击，而它的同义密码子则可能引起过敏反应并且导致质量下降。例如CAA、CAG均对应谷氨酰胺（Gln），但人类基因组中使用CAG更频繁，频率达到73%。因此CAA相较而言更有可能触发免疫反应。因此，mRNA疫苗需要选择最接近人源性的同义密码子，规避可能引起过敏反应的组合以保证安全性和转译质量。非转译区则调控mRNA和蛋白质的稳定性以及表达效率。
mRNA序列是疫苗研发中的重点，也是行业内竞争的核心。除了含有抗原蛋白编码外，序列其他部分也直接影响mRNA疫苗的质量。
编码前后的非转译区（UTR）负责调控转译以及蛋白表达，对mRNA的转译效率、半衰期、最高表达水平等数值有影响。转译效率可用来推断相同单位mRNA疫苗产生抗原的速度、半衰期用以推断mRNA能够产生抗原蛋白的时间、表达累计最高水平用以推断每单位mRNA在某一时刻能产生的抗原量的最高水平。同时，UTR中的GC水平、U水平均会影响mRNA的免疫原性，对疫苗的安全性和能否正常产生抗原造成影响。UTR需要在DNA质粒建立时包含在序列中，属于序列设计的一部分。
3’端多聚A尾（poly-A tail；A指腺苷，4种基础核苷酸的一种）位于mRNA尾部3’端，长度约100-250单位。多聚A尾能够提高mRNA的稳定性和转译效率。腺苷（A）能够降低核糖核酸酶（RNases）的效率，以此减缓mRNA的降解速度。多聚A尾可在建立DNA质粒时直接包含于编码中，也可在DNA转录为mRNA后通过聚合酶（poly-A polymerase，PAP）添加于mRNA尾部。
同时，位于mRNA最前端的5’帽结构对于降低mRNA免疫原性，增强稳定性和翻译效率有正面影响。5’帽结构是一个位于mRNA序列之前的反向7-甲基鸟苷（m7G）。在体外转录（IVT）过程中，mRNA5’端会含有三磷酸盐部分，具有很强的免疫原性。若不去除这一部分，当mRNA被递送进入人体细胞后，mRNA会在细胞质中引起IFN-1免疫反应，无法在人体内正常转译产生蛋白抗原。加帽过程可在DNA转录为mRNA的生产过程中或过程后进行，利用抗反向帽类似物（ARCA）将5’帽结构按正确方向固定在mRNA的5’端。但是此过程不能保证三磷酸盐完全被去除，所以仍旧存在引起细胞内免疫反应的风险，因此加帽工艺对疫苗的安全性有直接影响。
递送系统是目前产能扩张的瓶颈 LNP作为递送介质的工作原理已在上文阐述。作为mRNA疫苗的传递介质的一大难点是mRNA以内含体的形式进入细胞质后，需要打破内含体包膜，释放mRNA。目前LNP供应商较少，且其中专利纠纷因此成为mRNA新冠疫苗快速放量的一大掣肘。
目前辉瑞/BioNTech以及Moderna所使用的LNP专利都来源于一家名为Arbutus的加拿大生物公司。Arbutus将其部分LNP专利租借给另外两家公司Acuitas和Genevant，而这两家公司分别为Moderna和BioNTech的LNP专利来源。
Acuitas/Moderna Acuitas于2013年取得了来自Arbutus的LNP授权，而后Acuitas又将此授权进一步转租给Moderna公司。2016年，Arbutus与Acuitas针对这一再授权行为在加拿大法庭展开了一次长达2年的司法诉讼。2018年这场诉讼画上了句号，最终的诉讼结果是：“Acuitas转让给Moderna的4项非排他性疫苗授权是仅有的可以继续留存的合法授权，且此4项授权只能用于特定的病毒靶点。”然而，Moderna公司并不满意此次判决，公司接连发起3项针对Arbutus的专利诉讼（IPR）：
除Moderna外，另一大mRNA厂商CureVac在2016年也从Acuitas获得了LNP相关授权，目前暂未显示CureVac被卷入相关的诉讼中。根据ipwatchdog的报道，2020年7月CureVac的SEC F-1登记表中表明此授权协议仍旧有效，因此CureVac与Acuitas的协议可能并不涉及来自Arbutus的再许可。
Genevant/BioNTech Arbutus及其最大控股股东Roivant于2018年4月剥离了Genevant公司，同时Arbutus将非HBV的LNP技术专利授权给Genevant公司，授权中包含了Moderna败诉的‘069专利。作为回报，Arbutus获得Genevant公司40%股权（另60%股权属于Roivant公司）。2018年7月，BioNTech于Genevant公司签订了一份授权及共同开发协议。据称此协议可能包括了后续Moderna申诉的‘069专利。同时，Genevant和BioNTech公司共同承担专利保护权。
LNP专利成为mRNA疫苗行业商业权利的主要纷争来源 BioNTech和Moderna的新冠疫苗中的LNP技术专利全部来自Arbutus。Moderna在新冠疫苗中使用的LNP技术大概率不包含在Acuitas被许可再授权的4个项目中，因此后续是否会再次引起法律纠纷仍未可知。BioNTech从与Genevant合作中获得的LNP授权则会受到Moderna诉讼的影响。
在其他载体均有明显劣势的情况下，LNP是mRNA疫苗递送的最佳选择之一。因此，各厂商对LNP技术的掌握以及是否拥有相关专利成为了业内竞争中极其重要的一环。厂商若无相关专利，则在竞争中会处于被“卡脖子”的尴尬境地。因此，LNP技术专利决定了mRNA疫苗企业在业内竞争中的地位。
mRNA疫苗有望为肿瘤免疫疾病控制带来新曙光 mRNA疫苗属性契合肿瘤免疫疾病控制需求 肿瘤以及免疫疾病一直是人类健康面对的重大挑战，科学家不断地寻找能够减缓乃至根治肿瘤或免疫疾病的治疗方法。在治疗后，如何预防控制此类疾病的复发也是其中的重点课题之一。mRNA疫苗有可能给这个悬而未决的问题带来新解法。
mRNA疫苗能够激发针对细胞的T细胞免疫 mRNA疫苗除激活B细胞抗体免疫之外，还能够激活T细胞抗体。在杀伤肿瘤细胞方面，T细胞拥有更高的效率。mRNA疫苗通过自身细胞短暂持续产生外源蛋白，持续性地训练加强特异免疫。持续性训练能够使人体内的记忆免疫细胞（包括B记忆细胞和T记忆细胞）维持在相对较高的水平。由于记忆免疫细胞基数大，在遇到目标抗原时，抗体和杀手T细胞的扩增速度也会大大提升，能够更快速地反应。
mRNA疫苗能够更精准地靶向特异免疫目标 肿瘤或免疫疾病会分泌独有的特定的抗原标识物，称为肿瘤相关抗原（TAA），我们可以筛选出此类抗原进行测序、分析，将无毒害部分逆转译为对应的mRNA序列。将此mRNA制成疫苗，使自身细胞生产出抗原标识物，并以此激发对应的特异性免疫。由于mRNA疫苗中的编码可以进行编辑，可以准确地控制产生的抗原蛋白种类和序列，选择仅仅在肿瘤细胞中才会分泌的抗原蛋白标志物作为靶点，避免误伤其他正常细胞，使特异免疫精准地靶向肿瘤。
mRNA肿瘤疫苗研发情况 目前全球领先的三大mRNA疫苗企业分别为：Moderna、BioNTech、CureVac。
（1）Moderna
Moderna成立于2010年，总部位于美国马萨诸塞州剑桥市，位于美国两大生物技术热点地区之一，毗邻MIT、哈佛大学。公司使命为：将mRNA科学兑现，为患者创造新一代变革药物（Deliver on the promise of mRNA scienceto create a new generation of transformative medicines for patients.）。
技术平台助力序列研发，多平台全面支持科学家研发工作。 Moderna拥有从研究发现到早期开发的技术平台。研究平台中，SOFTWAREOF LIFE™ 使科学家能够将想法推进至开发阶段，为这一进程提供支持服务，其中包括能够快速大量提供mRNA的设备，让科学家能够进行大量实验。mRNA DesignStudio™利用算法为mRNA的序列设计赋能。此平台能够通过靶向蛋白反向模拟mRNA序列，并通过公司的生物信息算法进行自动优化。科学家也可通过手动编辑更改mRNA序列。通过积累大量的数据，mRNA Design Studio™能够不断升级进化mRNA设计算法，为之后的研发提供更大的帮助。
公司早期开发平台mRNA EARLYDEVELOPMENT ENGINE™能够提供例如工艺开发、GLP毒理研究、全球监管沟通、临床试验准备及运行的能力。平台将候选药物继续推进至GLP毒理、人类概念验证（PoC）阶段。目前Moderna在马萨诸塞州诺伍德有一家cGMP临床中心，占地面积约20万平方英尺，每年能进行超过100批次cGMP，能够进行GLP毒理研究以及临床I期、II期。同时，公司在诺伍德集中了生产所需的环节，包括原材料和活性药物成分（API）的生产、配方设计、灌装等能力。这一集群优势使研发工作能够快速推进。
研发管线包括预防性与治疗性疫苗，引领疫苗应用新时代的到来。 Moderna目前拥有24个疫苗研发项目，其中包括了预防性疫苗，例如新冠疫苗、扎卡病毒疫苗等，以及治疗性疫苗（主要为肿瘤疫苗）。
（2）BioNTech
BioNTech成立于2008年。公司致力于研发个人化的免疫治疗方案。公司产品涵盖了mRNA、细胞治疗、抗体、小分子免疫调节剂等。公司目前共有31个项目在研，13项进入临床阶段。
公司拥有多个技术平台，满足不同的患者和医疗需求。 公司FixVac平台主要靶向在肿瘤中普遍有表达的抗原，优化mRNA序列以及RNA与递送系统的结合。公司另一大平台iNeST则是针对患者个体的研发平台。通过直接采集的患者样本来确定肿瘤突变序列，并据此预测RNA靶点，最终为患者提供完全个人化的免疫治疗方案。除此之外，BioNTech还拥有许多其他平台支撑公司提供创新的肿瘤、免疫、传染疾病的解决方案。
公司在研管线集中于mRNA项目，同时抗体及小分子免疫调节剂已有项目进入临床。 BioNTech目前共有31项在研项目，13项已进入临床阶段，其中包含9项mRNA治疗、3项抗体治疗、1项小分子免疫调节剂。
（3）CureVac
CureVac成立于2000年，是全球第一家成功得到医用mRNA的公司。与Moderna相似，CureVac同时布局了预防型和治疗型疫苗，以及蛋白治疗。公司目前共有14个项目在研，4项进入临床阶段。
一站式mRNA治疗，全面布局药物发现至生产所有环节。 CureVac拥有693项专利，从药物发现至产品生产均可在公司内部完成。公司拥有一家位于德国的GMP工厂。同时公司研发了流动生产车间The RNA Printer®，可快速应对疫情爆发，能够紧急设置在医院提供个人化的mRNA药物。
加速推进新冠疫苗研发，以适应病毒变异。 CureVac于2021年6月16日公布了公司第一代mRNA新冠疫苗CVnCoV的临床IIb/III期数据。疫苗有效保护率仅为约47%，并未达到设定目标。疫苗安全性则达到了预定目标。本次临床试验数据已提交欧洲药物管理局（EMA），等待进一步分析审核。随后，公司于17日召开了说明会，对此次临床数据进行分析。分析认为造成第一代新冠疫苗CVnCoV保护率不理想的主要原因是病毒变异。公司对感染者所感染的新冠病毒进行了基因分析，发现其中有29种不同亚型的新冠病毒存在。在开展临床试验的10个国家中，欧洲地区病例91%属于Alpha型变异株，而拉丁美洲地区有多种变异株流行，而公司用作靶点的新冠病毒原型（野生型）仅有不足1%。因此，公司认为病毒不断变异对研发工作带来了不小的挑战。同时，公司也与GSK合作开始开发第二代新冠疫苗CV2CoV，新一代疫苗将使用全新的mRNA序列，并考虑多种病毒变异亚型。从目前的实验结果来看，二代新冠疫苗激活免疫的速度更快，同时抗体滴度更高。公司预测新一代疫苗将于2021年第三季度进入临床阶段。
另一方面，CureVac本次疫苗采用的储藏温度条件为5摄氏度，远远宽松于已上市的BNT162b2和mRNA1273。高温条件下，疫苗递送系统的脂质成分可能会发生变质、降解，本次不太理想的临床实验数据是否与此有关联是业内科学家们正在讨论的话题之一。
投资策略：国内mRNA疫苗暂时空白，关注拥有核心技术的企业 国内暂未有mRNA获批上市，这一市场目前仍处于空白状态。在第二轮新冠疫苗需求到来之际，国产mRNA疫苗的竞争将会打响。根据上文所提，mRNA疫苗的两大核心是序列设计和递送系统，因此，我们建议重点关注同时拥有这两大核心技术的企业。目前国内市场中，mRNA疫苗研发进展最快的是艾博生物与沃森生物、军科院共同研发的ARCoV，以及复星医药由BioNTech引进的BNT162b2。因此，我们推荐沃森生物以及取得了BioNTechmRNA新冠疫苗大中华区权利的复星医药。
国内已有8家研发型mRNA疫苗企业，目前均处于起步阶段。在认可mRNA疫苗潜力的前提下，建议留意各公司的研发及融资进展。我们建议关注斯微生物和丽凡达生物。同时，我们也建议关注在疫苗领域拥有丰富临床申报、生产制造、销售能力的企业，这些企业有望与研发企业开展紧密的合作，优势互补，并及时跟紧疫苗技术发展的潮流。
风险提示
研发进展不及预期、销售不及预期、监管政策收紧风险。
沃森生物 深耕疫苗行业，致力于打造中国第一款国产mRNA疫苗
支撑评级的要点 携手艾博生物打造第一款国产mRNA疫苗。5月11日，公司公告与苏州艾博生物签署关于新冠mRNA疫苗的合作协议。艾博生物具有mRNA疫苗设计的核心技术，其CEO英博先生曾供职于国际mRNA疫苗巨头Moderna。沃森生物则拥有临床注册、研究、产业化和营销方面的丰富经验。同日，墨西哥宣布将在5月底开展此疫苗的III期临床试验。
聚焦前沿技术，提前布局新一代核酸类药物。4月27日，上市公司与圣诺生物签署了抗病毒核酸干扰药物的合作协议。圣诺生物负责完成药物的临床申报所需的临床前研究，公司获得该药物在中国大陆及港澳台地区的独家权利。
13价肺炎疫苗开始贡献收入，国际化销售锦上添花。2021Q1，子公司13价肺炎疫苗获批签发164.3万瓶，达到2020年全年批签发量的36.8%。同时，子公司与摩洛哥MarocVax达成排他性协议。MarocVax保证在收到完整产品注册档案后18个月内获得上市许可。2021年，此疫苗于摩洛哥的销量约为200万剂。技术转移后，MarocVax将继续采购至少等同于200万剂的疫苗原液。
估值 我们预测2021-2023年公司可实现净利润13.62亿元、18.30亿元、21.64亿元，对应EPS 0.87元、1.17元、1.38元。
评级面临的主要风险 研发进展不及预期；上市审批速度不及预期；销售不及预期。
公司业绩简介 沃森生物成立于2001年，公司长期在疫苗领域深耕，拥有丰富且领先的产品管线，包括13价肺炎结合疫苗和HPV疫苗。公司2020年实现营业收入29.39亿元，同比增长162.13%；归母净利润10.03亿元，同比增长606.60%。2021年第一季度实现营业收入4.34亿元，同比增长286.45%；归母净利润3215.88万元，同比增长277.50%。
2021年第一季度，公司子公司玉溪沃森获批签发产品数量合计9,749,407剂，同比下滑10.14%。除百白破疫苗批签发量出现较明显下滑外，其余品种均实现了显著的同比增长，其中13价肺炎结合疫苗开始放量，同比增长1064.50%。
公司研发管线 根据公司2021年一季报，目前共有6条研发管线，其中1项进入申报生产阶段，其余5项处于临床研究阶段。其中2价HPV疫苗、9价HPV疫苗、mRNA新冠疫苗受到市场极高的关注。
携手艾博生物打造第一款国产mRNA疫苗。
5月11日，公司公告与苏州艾博生物签署合作协议，致力于开展新冠mRNA疫苗的临床前、临床研究并实施商业化生产。苏州艾博生物具有mRNA疫苗设计的核心技术，其CEO英博先生曾供职于国际mRNA疫苗巨头Moderna。沃森生物则拥有临床注册、研究、产业化和营销方面的丰富经验。
公司与艾博生物、军事科学研究院共同研发的mRNA新冠疫苗ARCoV是国内第一款获批临床的mRNA疫苗。目前，此款疫苗在国内进行临床II期实验。6月15日，在由BioBAY主办的核酸药物研发论坛上，英博透露ARCoV正在启动海外多中心III期临床试验，5月11日，墨西哥外交部长埃布拉德宣布将在墨西哥开展此疫苗的III期临床试验，预计志愿者6000人，实验将于5月31日开始。
ARCoV新冠mRNA疫苗的储藏条件为2-8摄氏度，相较于BNT162b2要求的-70摄氏度和mRNA1273的-20摄氏度更为宽松。不过宽松的储藏条件也相应地提高了对疫苗递送系统要求，由于脂质易在高温条件下发生变质、讲解，因此需要密切关注ARCoV的有效期以及疫苗保护率是否会因此受到影响。
聚焦前沿技术，提前布局新一代核酸类药物
4月27日，上市公司与圣诺生物医药技术(苏州)有限公司(简称“圣诺生物”)、Sirnaomics,Inc.(圣诺制药有限公司,简称“美国圣诺”)签署了抗病毒核酸干扰药物的合作协议。圣诺生物负责完成药物的临床申报所需的临床前研究，上市公司则获得该药物在中国大陆及港澳台地区的独家权利，包括临床开发、注册、生产制造和商业化销售的许可权。公司将根据协议向圣诺生物支付500万元预付款，3650万元临床前研发费用，以及药物在不同临床开发阶段的里程碑付款和产品销售分成。
核酸干扰（RNA interference，RNAi）类药物是新一代核酸药物，通过“沉默”靶基因或基因中的片段产生临床效果，在治疗肿瘤、免疫疾病、传染疾病、以及神经退行性疾病中有广阔的前景。RNAi中最重要的2种物质分别为miRNA和siRNA。在DNA转录产生mRNA后，这两种物质能够快速指引RNA分解酶对生成的mRNA进行降解，阻止其进一步转译为能够对生物活动产生影响的蛋白质，以此变相沉默特定的基因片段。
美国FDA于2018年和2019年11月相继批准了Alnylam两款RNAi药物的上市申请，适应症分别为急性肝卟啉症、遗传性转甲状腺素蛋白淀粉样变性引起的基因紊乱。
圣诺生物本次与沃森生物的合作项目为抗流感病毒的小干扰核酸药物STP702。STP702预定的给药途径为雾化吸入，目前该项目在中美均处于IND准备阶段。
13价肺炎疫苗开始贡献收入，国际化销售锦上添花。
2021年第一季度，控股子公司玉溪沃森的13价肺炎疫苗获批签发164.3万瓶，以达到2020年全年批签发量的36.8%。同时，子公司与摩洛哥MarocVax达成排他性协议。双方将先开展成品供应合作，同时进行部分技术转移。MarocVax保证在收到完整产品注册档案后18个月内获得上市许可。2021年，此疫苗于摩洛哥的销量约为200万剂。技术转移后，MarocVax将继续采购至少等同于200万剂的疫苗原液。我们预测公司的13价肺炎疫苗将在2021年继续放量，并成为公司的主要营收来源。
风险提示
研发不及预期：mRNA疫苗的序列设计和递送系统为前沿技术，可供参考的成功范例少，研发工作极其依赖公司研发团队的能力。因此，有研发不及预期的可能性。
上市审批速度不及预期：上市及审批受政策和疫情影响。若疫情控制较好，病毒变异并未造成现有疫苗明显的免疫逃逸，则审批速度有可能放缓。
销售不及预期：产品放量依赖市场需求，无论是对于新冠疫苗还是公司其他产品，需求的波动都有可能造成销售的起伏。同时，竞品或替代品的出现也有可能对销售造成冲击。
复星医药 全面布局创新，有望获国内mRNA疫苗第一签
支撑评级的要点
加速推进复必泰mRNA疫苗国内落地。**5月9日，公司公告子公司复星医药产业与BioNTech设立合资公司，以实现mRNA新冠疫苗产品的本地化生产及商业化。双方分别认缴合资公司注册资本的50%，BioNTech以技术和许可等无形资产方式出资。复星医药产业应提供产能可达10亿剂的生产设施。2021年1月，疫苗国内II期临床试验已完成所有受试者第二针的接种。在病毒变异以及疫苗有效期的双重推动下，新冠疫苗有望迎来第二轮需求。
国内首款CAR-T产品上市，为淋巴瘤患者带来新曙光。**2021年6月23日，NMPA批准了复星凯特的奕凯达的上市申请，用于治疗复发难治性大B细胞淋巴瘤。复兴凯特在针对中国患者的难治性侵袭性大B细胞淋巴瘤的实验中ORR达到79.2%，与Yescarta的临床和真实世界数据高度相似。2020年Yescarta全球销售额约6.07亿美元，同比增长33%。
公司布局多条创新药研发管线，为长期发展做好战略储备。**公司在创新药方面持续投入，研发费用率稳定在10%左右，逐步接近国际制药巨头水平。阿达木单抗、曲妥珠单抗、CAR-T细胞治疗等多个产品已获批上市，成为公司营收新的增长点。截至2020年末，公司在研创新药项目达56项，为未来长期发展做好战略储备。
估值
我们预测2021-2023年公司可实现净利润44.73亿元、53.37亿元、61.89亿元，对应EPS 1.75元、2.08元、2.41元。
评级面临的主要风险
研发不及预期，监管审批速度不及预期，疫情恶化风险。
公司业绩简介
复星医药广泛布局医药健康产业链，直接运营业务板块包括制药、医疗器械和诊断、医疗服务，并通过参股国药控股介入医药商业领域。2020年，复星医药实现营业收入303.07亿元，同比增长6.02%；归母净利润36.63亿元，同比增长10.27%。2021年第一季度，公司实现营业收入80.56亿元，同比增长37.00%；归母净利润8.47亿元，同比增长46.78%。
加速推进复必泰mRNA疫苗国内落地。
5月9日，公司公告子公司复星医药产业与BioNTech设立合资公司，以实现mRNA新冠疫苗产品的本地化生产及商业化。双方分别认缴合资公司注册资本的50%，BioNTech以技术和许可等无形资产方式出资。复星医药产业应提供产能可达10亿剂的生产设施。
根据《供货协议》，如以新冠疫苗成品供货，复星医药产业与BioNTech按65%、35%的比例分享年度销售毛利；如以大包装制剂供货，复星医药产业(或其关联公司)、BioNTech按60%、40%的比例分享年度销售毛利。BNT162b2 mRNA新冠疫苗在大中华区的商品名为复必泰。
2021年1月，疫苗国内II期临床试验已完成所有受试者第二针的接种。在病毒变异以及疫苗有效期的双重推动下，新冠疫苗有望迎来第二轮需求。
截至2021年6月30日，香港共已接种2,154,082剂复必泰疫苗。根据2020年12月11日香港政府发布的采购公告，香港政府计划采购750万剂复必泰。
复星医药2021年第一季度报告显示公司经营活动产生的现金流量净额达到约7.37亿元，同比增加92.62%，主要原因之一为收到中国香港及中国澳门政府mRNA新冠疫苗首付款以及支付相关采购支出与研发销售费用后的净贡献。
国内首款CAR-T产品上市，为淋巴瘤患者带来新曙光。
2021年6月23日，复星凯特阿基伦赛注射液（商品名：奕凯达）获NMPA批准上市，成为了国内第一款获批的CAR-T细胞产品。奕凯达由吉利德科学控股子公司Kite Pharma的Yescarta技术转移而来，国内获批适应症为二线及以上治疗后复发或难治性大B细胞淋巴瘤。复兴凯特在针对中国患者的难治性侵袭性大B细胞淋巴瘤的实验中ORR达到79.2%，其中完全缓解率（CR）达到51%，部分缓解率（PR）达到21%。与Yescarta的临床和真实世界数据高度相似。
2020年Yescarta全球销售额约6.07亿美元，同比增长33%。2021年第一季度，Yescarta销售额进一步上升至1.6亿美元。
公司前期研发投入进入收获期，新品成为营收增量主要动力。
阿达木单抗、曲妥珠单抗、CAR-T细胞治疗等多个产品已获批上市，成为公司营收新的增长点。
其中汉利康（利妥昔单抗注射液）于2019年获批上市，用于治疗非霍奇金淋巴瘤，并新获批适应症初治滤泡性淋巴瘤以及先前未经治疗或复发性/难治性慢性淋巴细胞白血病。2020年全年创造销售收入7.5亿元，已成为公司销售额最大的几个品种之一。
汉曲优（注射用曲妥珠单抗）于2020年8月在国内获批上市，用于治疗HER2阳性的转移性乳腺癌、HER2阳性的早期乳腺癌、HER2阳性的转移性胃腺癌或胃食管交界处腺癌。2020年7月，汉曲优获欧盟委员会（EC）批准上市。2020年全年贡献销售收入1.4亿元。
苏可欣（马来酸阿伐曲泊帕片）于2020年8月开始上市销售，用于治疗慢性肝病相关的血小板减少症。2020年实现销售收入1.4亿元，并于年底纳入国家医保目录。
公司布局多条创新药研发管线，为长期发展做好战略储备。
公司在创新药方面持续投入，研发费用率稳定在10%左右，逐步接近国际制药巨头水平。
公司2020年研发投入40.03亿元，研发费用27.95亿元。截至2020年末，公司在研创新药项目达56项，其中自研小分子创新药18项（临床阶段8项），自研生物创新药25项（临床阶段15项），许可引进创新药13项（临床阶段6项）。为未来长期发展做好战略储备。
风险提示
研发不及预期：公司参与大量创新药的研发。因此，有研发不及预期的可能性。
监管审批速度不及预期：上市及审批受政策和疫情影响。若疫情控制较好，病毒变异并未造成现有疫苗明显的免疫逃逸，则审批速度有可能放缓。
疫情恶化风险：若疫情持续恶化，病毒变异速度加快，则有可能造成疫苗有效率的下降。同时也对公司其他产品的销售造成影响。</content></entry><entry><title>APISIX的控制面</title><url>https://lizj3624.github.io/post/apisix-admin/</url><categories><category>apisix</category><category>nginx</category></categories><tags><tag>apisix</tag><tag>nginx</tag></tags><content type="html"> apisix的控制面主要是提供一套RESTful API接口对存储在etcd中的route、service、plugin、upstream等CURD操作。apisix有两套控制面：
apisix通过lua开发一套控制面API接口，这套代码主要在apisix/admin目录下。
另一个是通过golang的API接口，还包含一套javascript写的dashboard，这个项目也开源了，GitHub - apache/apisix-dashboard: Dashboard for Apache APISIX。
我们主要介绍一下apisix/admin这个控制面接口，对应的url path主要是/apisix/admin/*，我们看一个新增route的请求，熟悉一下API接口
curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/", "upstream_id": "00000000000000000122" }' init_worker 在http_init_worker函数中也会调用admin的init_worker函数require("apisix.admin.init").init_worker()，做一些初始化的工作。
初始化控制面接口的route信息
local uri_route = { { paths = [[/apisix/admin/*]], methods = {"GET", "PUT", "POST", "DELETE", "PATCH"}, handler = run, -- 控制面接口的回调函数 }, { paths = [[/apisix/admin/plugins/list]], methods = {"GET"}, handler = get_plugins_list, -- 查询插件的回调函数 }, { paths = reload_event, methods = {"PUT"}, handler = post_reload_plugins, -- 插件reload的回调函数 }, } 请求处理 我们主要看一下控制面接口的回调函数run
local resources = { --- 注册了处理route、service、plugin、upstream等的模块信息 routes = require("apisix.admin.routes"), services = require("apisix.admin.services"), upstreams = require("apisix.admin.upstreams"), consumers = require("apisix.admin.consumers"), schema = require("apisix.admin.schema"), ssl = require("apisix.admin.ssl"), plugins = require("apisix.admin.plugins"), proto = require("apisix.admin.proto"), global_rules = require("apisix.admin.global_rules"), stream_routes = require("apisix.admin.stream_routes"), plugin_metadata = require("apisix.admin.plugin_metadata"), plugin_configs = require("apisix.admin.plugin_config"), } local function run() local api_ctx = {} core.ctx.set_vars_meta(api_ctx) ngx.ctx.api_ctx = api_ctx -- token校验 local ok, err = check_token(api_ctx) if not ok then core.log.warn("failed to check token: ", err) core.response.exit(401, {error_msg = "failed to check token"}) end local uri_segs = core.utils.split_uri(ngx.var.uri) core.log.info("uri: ", core.json.delay_encode(uri_segs)) -- /apisix/admin/schema/route local seg_res, seg_id = uri_segs[4], uri_segs[5] local seg_sub_path = core.table.concat(uri_segs, "/", 6) if seg_res == "schema" and seg_id == "plugins" then -- /apisix/admin/schema/plugins/limit-count seg_res, seg_id = uri_segs[5], uri_segs[6] seg_sub_path = core.table.concat(uri_segs, "/", 7) end if seg_res == "stream_routes" then local local_conf = core.config.local_conf() if not local_conf.apisix.stream_proxy then core.log.warn("stream mode is disabled, can not add any stream ", "routes") core.response.exit(400, {error_msg = "stream mode is disabled, " .. "can not add stream routes"}) end end -- resources是注册了处理route、service、plugin、upstream等的模块信息 local resource = resources[seg_res] if not resource then core.response.exit(404, {error_msg = "not found"}) end local method = str_lower(get_method()) if not resource[method] then core.response.exit(404, {error_msg = "not found"}) end local req_body, err = core.request.get_body(MAX_REQ_BODY) if err then core.log.error("failed to read request body: ", err) core.response.exit(400, {error_msg = "invalid request body: " .. err}) end if req_body then local data, err = core.json.decode(req_body) if err then core.log.error("invalid request body: ", req_body, " err: ", err) core.response.exit(400, {error_msg = "invalid request body: " .. err, req_body = req_body}) end req_body = data end local uri_args = ngx.req.get_uri_args() or {} if uri_args.ttl then if not tonumber(uri_args.ttl) then core.response.exit(400, {error_msg = "invalid argument ttl: " .. "should be a number"}) end end -- 根据PUT/POST/PATHCE，调用相应的处理函数 local code, data = resource[method](seg_id, req_body, seg_sub_path, uri_args) if code then data = strip_etcd_resp(data) core.response.exit(code, data) end end 比如我们前面介绍的新增route的请求curl "http://127.0.0.1:9080/apisix/admin/routes" -X POST -d '{json data}'，根据url中route可以从查找resources到引用require("apisix.admin.routes")模块，根据method方法POST(resource[method])可以调用routes模块的post处理函数，我们就以route为例，跟进看一下route模块的路由信息的操作。
控制面对路由信息的操作主要在在apisix/admin/routes.lua中
-- 更新数据的校验 local function check_conf(id, conf, need_id) ... end -- route的put函数 function _M.put(id, conf, sub_path, args) end -- route的get函数 function _M.get(id) end -- route的post函数 function _M.post(id, conf, sub_path, args) local id, err = check_conf(id, conf, false) --检查更新请求数据是否合法 if not id then return 400, err end local key = "/routes" -- 存储到etcd的key utils.inject_timestamp(conf) -- 调用etcd的push方法，将更新数据存储到etcd中 local res, err = core.etcd.push(key, conf, args.ttl) if not res then core.log.error("failed to post route[", key, "] to etcd: ", err) return 503, {error_msg = err} end return res.status, res.body end -- route的delete函数 function _M.delete(id) end -- route的patch函数 function _M.patch(id, conf, sub_path, args) end routes模块实现了路由信息的PUT/GET/POST/DELETE/PATCH方法，这些方法都是对etcd的操作，etcd的实现操作放在apisix/core/etcd.lua中。其他service/plugin/upstream的实现跟着比较类似，这里就不在详解了。
apisix的控制面主要是通过REST API接口对存储在etcd中的route、service、plugin、upstream等CURD操作。</content></entry><entry><title>APISIX的route匹配机制</title><url>https://lizj3624.github.io/post/apisix-etcd/</url><categories><category>apisix</category><category>etcd</category></categories><tags><tag>apisix</tag><tag>etcd</tag></tags><content type="html"> apisix通过etcd作为后端存储，存储了route、service、plugin、upstream等信息，我们看一下如何通过etcd查找路由等信息，如果路由有变化时时如何通知更新的。 apisix也是支持yaml文件存储的，我们主要介绍etcd作为存储。
apisix与etcd交互是通过resty-lua-etcd，这个也是apisix自己开发并开源的组件。apisix的etcd核心代码都在config_etc.lua。
启动阶段start 调用etcd.init()根据配置初始化etcd，创建etcd的client，测试验证是否ok。
local function start(env, ...) ... init(env) init_etcd(env, args) ---调用etcd.init() util.execute_cmd(env.openresty_args) end -- config_etcd.lua function _M.init() local local_conf, err = config_local.local_conf() if not local_conf then return nil, err end if table.try_read_attr(local_conf, "apisix", "disable_sync_configuration_during_start") then return true end local etcd_cli, err = get_etcd() if not etcd_cli then return nil, "failed to start a etcd instance: " .. err end local etcd_conf = local_conf.etcd local prefix = etcd_conf.prefix local res, err = readdir(etcd_cli, prefix, create_formatter(prefix)) if not res then return nil, err end return true end init_worker阶段 在这个阶段调用各个组件模块的init_woker，从etcd中获取router、service、plugin、upstream等信息，我看一下
-- init.lua中http_init_worker在init_worker阶段调用 function _M.http_init_worker() ... require("apisix.balancer").init_worker() load_balancer = require("apisix.balancer") require("apisix.admin.init").init_worker() require("apisix.timers").init_worker() require("apisix.debug").init_worker() ... plugin.init_worker() router.http_init_worker() --route的init_worker函数 require("apisix.http.service").init_worker() --- service的init_worker函数 plugin_config.init_worker() require("apisix.consumer").init_worker() apisix_upstream.init_worker() -- upstream的init_worker ... end 着重看一下route的init_worker 函数
function _M.http_init_worker() local conf = core.config.local_conf() local router_http_name = "radixtree_uri" local router_ssl_name = "radixtree_sni" if conf and conf.apisix and conf.apisix.router then router_http_name = conf.apisix.router.http or router_http_name router_ssl_name = conf.apisix.router.ssl or router_ssl_name end -- router_http_name引用相应的路由模块apisix/http/router local router_http = require("apisix.http.router." .. router_http_name) --绑定路由模块的init_worker函数和routes函数，init_worker不存在时就apisix/http/route.lua中的init_worker attach_http_router_common_methods(router_http) --调用模块的init_worker函数，一般都是apisix/http/route.lua中的init_worker函数 router_http.init_worker(filter) _M.router_http = router_http local router_ssl = require("apisix.ssl.router." .. router_ssl_name) router_ssl.init_worker() _M.router_ssl = router_ssl _M.api = require("apisix.api_router") local global_rules, err = core.config.new("/global_rules", { automatic = true, item_schema = core.schema.global_rule, checker = plugin_checker, }) if not global_rules then error("failed to create etcd instance for fetching /global_rules : " .. err) end _M.global_rules = global_rules end 我们在跟进router_http.init_worker(filter)这个就是调用的apisix/http/route.lua中的init_worker函数，并将从etcd获取的路由信息存储在http_router.user_routes中，以便access阶段进行路由匹配。
function _M.init_worker(filter) local user_routes, err = core.config.new("/routes", { automatic = true, item_schema = core.schema.route, checker = check_route, filter = filter, }) if not user_routes then error("failed to create etcd instance for fetching /routes : " .. err) end return user_routes end 这里core.config.new对应是apisix/core/config_etcd.lua的new函数，因为core.config设置的配置中心etcd，这是获取route的信息因此key是routes，获取到信息存储到user_routes变量中，有变更时就更新这个变量，再次根据etcd的new函数。
function _M.new(key, opts) ... local obj = setmetatable({ etcd_cli = nil, key = key and prefix .. key, automatic = automatic, item_schema = item_schema, checker = checker, sync_times = 0, running = true, conf_version = 0, ---设置当前版本函数 values = nil, need_reload = true, routes_hash = nil, prev_index = 0, last_err = nil, last_err_time = nil, resync_delay = resync_delay, health_check_timeout = health_check_timeout, timeout = timeout, single_item = single_item, filter = filter_fun, }, mt) if automatic then if not key then return nil, "missing `key` argument" end if loaded_configuration[key] then local res = loaded_configuration[key] loaded_configuration[key] = nil -- tried to load log.notice("use loaded configuration ", key) local dir_res, headers = res.body, res.headers load_full_data(obj, dir_res, headers) end --- 定时函数，定时检查配置是否有变更，变更时就更新 ngx_timer_at(0, _automatic_fetch, obj) else local etcd_cli, err = get_etcd() if not etcd_cli then return nil, "failed to start a etcd instance: " .. err end obj.etcd_cli = etcd_cli end if key then created_obj[key] = obj end return obj end etcd的这个new定义对象obj，将每次通过定时处理函数是_automatic_fetch从etcd中获取的放到这个对象的values，并更新conf_version的版本号，我们跟进这个定时函数
local function _automatic_fetch(premature, self) if premature then return end if not (health_check.conf and health_check.conf.shm_name) then local _, err = health_check.init({ shm_name = health_check_shm_name, fail_timeout = self.health_check_timeout, max_fails = 3, retry = true, }) if err then log.warn("fail to create health_check: " .. err) end end local i = 0 while not exiting() and self.running and i &lt;= 32 do i = i + 1 local ok, err = xpcall(function() if not self.etcd_cli then local etcd_cli, err = get_etcd() -- 获取etcd客户端 if not etcd_cli then error("failed to create etcd instance for key [" .. self.key .. "]: " .. (err or "unknown")) end self.etcd_cli = etcd_cli end local ok, err = sync_data(self) -- 从etcd中get数据 if err then if string.find(err, err_etcd_unhealthy_all) then local reconnected = false while err and not reconnected and i &lt;= 32 do local backoff_duration, backoff_factor, backoff_step = 1, 2, 6 for _ = 1, backoff_step do i = i + 1 ngx_sleep(backoff_duration) _, err = sync_data(self) if not err or not string.find(err, err_etcd_unhealthy_all) then log.warn("reconnected to etcd") reconnected = true break end backoff_duration = backoff_duration * backoff_factor log.error("no healthy etcd endpoint available, next retry after " .. backoff_duration .. "s") end end elseif err ~= "timeout" and err ~= "Key not found" and self.last_err ~= err then log.error("failed to fetch data from etcd: ", err, ", ", tostring(self)) end if err ~= self.last_err then self.last_err = err self.last_err_time = ngx_time() else if ngx_time() - self.last_err_time >= 30 then self.last_err = nil end end -- etcd watch timeout is an expected error, so there is no need for resync_delay if err ~= "timeout" then ngx_sleep(self.resync_delay + rand() * 0.5 * self.resync_delay) end elseif not ok then -- no error. reentry the sync with different state ngx_sleep(0.05) end end, debug.traceback) if not ok then log.error("failed to fetch data from etcd: ", err, ", ", tostring(self)) ngx_sleep(self.resync_delay + rand() * 0.5 * self.resync_delay) break end end if not exiting() and self.running then ngx_timer_at(0, _automatic_fetch, self) --再次设置定时器 end end init_worker阶段etcd最重要的功能就是定时回调函数，定时同步etcd中的数据放到user_routes。到这里init_worker介绍完了。
access阶段 这个阶段主要匹配路由和挑选server。
function _M.http_access_phase() local ngx_ctx = ngx.ctx ... -- 匹配路由 router.router_http.match(api_ctx) ... -- 挑选server local server, err = load_balancer.pick_server(route, api_ctx) if not server then core.log.error("failed to pick server: ", err) return core.response.exit(502) end ... end 匹配路由 apisix为了提高查找性能，基于基数树写一套路由查找的插件GitHub - api7/lua-resty-radixtree: Adaptive Radix Trees implemented in Lua / LuaJIT，match函数主要调用apisix/radixtree_uri.lua at master · apache/apisix · GitHub中的match，这个可以根据config_default.ymal配置修改用那种路由查找模块，有三个路由查找radixtree_uri.lua、radixtree_host_uri.lua、radixtree_uri_with_parameter.lua，我们先来看一下这个match函数
function _M.match(api_ctx) local user_routes = _M.user_routes --从etcd获取的路由数据 local _, service_version = get_services() --service版本 --user_routes的数据有变更时重新创建radixtree的路由查找树 if not cached_router_version or cached_router_version ~= user_routes.conf_version or not cached_service_version or cached_service_version ~= service_version then uri_router = base_router.create_radixtree_uri_router(user_routes.values, uri_routes, false) cached_router_version = user_routes.conf_version cached_service_version = service_version end if not uri_router then core.log.error("failed to fetch valid `uri` router: ") return true end --真正路由匹配 return base_router.match_uri(uri_router, match_opts, api_ctx) end `` match函数有两个重要的函数create_radixtree_uri_router和base_router.match_uri，前者主要在从etcd中route信息的user_routes版本有变更时，将route信息user_routes.values重建radixtree的路由查找树，后者是将请求匹配radixtree的路由查找树，查合适的路由信息。
挑选server 挑选server主要是load_balancer.pick_server这个函数主要是调用的apisix/balancer.lua中的pick_server函数
local function pick_server(route, ctx) ... local server_picker = ctx.server_picker if not server_picker then -- 根据负载均衡类型选取合适的lru缓存 server_picker = lrucache_server_picker(key, version, create_server_picker, up_conf, checker) end if not server_picker then return nil, "failed to fetch server picker" end local server, err = server_picker.get(ctx) --合适balancer的get方法 if not server then err = err or "no valid upstream node" return nil, "failed to find valid upstream server, " .. err end ctx.balancer_server = server ... end 这里有两个重要的函数lrucache_server_picker和server_picker.get函数，前者创建balancer的lru缓存，lru的new函数是lrucache.lua的new_lru_fun函数，通过create_obj_fun创建缓存对象，在缓存击穿后为了保证只有一个worker进程取etcd获取数据，使用了resty.lock锁。
local function new_lru_fun(opts) local item_count, item_ttl if opts and opts.type == 'plugin' then item_count = opts.count or PLUGIN_ITEMS_COUNT item_ttl = opts.ttl or PLUGIN_TTL else item_count = opts and opts.count or GLOBAL_ITEMS_COUNT item_ttl = opts and opts.ttl or GLOBAL_TTL end local item_release = opts and opts.release local invalid_stale = opts and opts.invalid_stale local serial_creating = opts and opts.serial_creating local lru_obj = lru_new(item_count) return function (key, version, create_obj_fun, ...) if not serial_creating or not can_yield_phases[get_phase()] then local cache_obj = fetch_valid_cache(lru_obj, invalid_stale, item_ttl, item_release, key, version) if cache_obj then return cache_obj.val end local obj, err = create_obj_fun(...) --回调函数就是create_server_picker if obj ~= nil then lru_obj:set(key, {val = obj, ver = version}, item_ttl) end return obj, err end local cache_obj = fetch_valid_cache(lru_obj, invalid_stale, item_ttl, item_release, key, version) if cache_obj then return cache_obj.val end local lock, err = resty_lock:new(lock_shdict_name) if not lock then return nil, "failed to create lock: " .. err end local key_s = tostring(key) log.info("try to lock with key ", key_s) local elapsed, err = lock:lock(key_s) if not elapsed then return nil, "failed to acquire the lock: " .. err end cache_obj = fetch_valid_cache(lru_obj, invalid_stale, item_ttl, nil, key, version) if cache_obj then lock:unlock() log.info("unlock with key ", key_s) return cache_obj.val end local obj, err = create_obj_fun(...) if obj ~= nil then lru_obj:set(key, {val = obj, ver = version}, item_ttl) end lock:unlock() log.info("unlock with key ", key_s) return obj, err end end create_obj_fun的回调函数是create_server_picker
local function create_server_picker(upstream, checker) --upstream是从etcd中获取数据，ctx.upstream_conf local picker = pickers[upstream.type] if not picker then -- 根据不同负载均衡算法挑选合适负载均衡模块，upstream.type是负载算法类型 pickers[upstream.type] = require("apisix.balancer." .. upstream.type) picker = pickers[upstream.type] end if picker then local nodes = upstream.nodes local addr_to_domain = {} for _, node in ipairs(nodes) do if node.domain then local addr = node.host .. ":" .. node.port addr_to_domain[addr] = node.domain end end local up_nodes = fetch_health_nodes(upstream, checker) if #up_nodes._priority_index > 1 then core.log.info("upstream nodes: ", core.json.delay_encode(up_nodes)) local server_picker = priority_balancer.new(up_nodes, upstream, picker) server_picker.addr_to_domain = addr_to_domain return server_picker end core.log.info("upstream nodes: ", core.json.delay_encode(up_nodes[up_nodes._priority_index[1]])) -- 调用balancer的new方法 local server_picker = picker.new(up_nodes[up_nodes._priority_index[1]], upstream) server_picker.addr_to_domain = addr_to_domain return server_picker end return nil, "invalid balancer type: " .. upstream.type, 0 end pickers变量存放负载均衡算法的模块，apisix支持的负载算法roundrobin、chash、least_conn，这些实现代码模块都在apisix/balancer目录，picker.new是balancer对象的new方法。我们看一下roundrobin的balancer
function _M.new(up_nodes, upstream) --new方法 local safe_limit = 0 for _, weight in pairs(up_nodes) do -- the weight can be zero safe_limit = safe_limit + weight + 1 end local picker = roundrobin:new(up_nodes) local nodes_count = nkeys(up_nodes) return { upstream = upstream, get = function (ctx) --get方法 if ctx.balancer_tried_servers and ctx.balancer_tried_servers_count == nodes_count then return nil, "all upstream servers tried" end local server, err for i = 1, safe_limit do server, err = picker:find() if not server then return nil, err end if ctx.balancer_tried_servers then if not ctx.balancer_tried_servers[server] then break end else break end end return server end, after_balance = function (ctx, before_retry) --after_balance方法 if not before_retry then if ctx.balancer_tried_servers then core.tablepool.release("balancer_tried_servers", ctx.balancer_tried_servers) ctx.balancer_tried_servers = nil end return nil end if not ctx.balancer_tried_servers then ctx.balancer_tried_servers = core.tablepool.fetch("balancer_tried_servers", 0, 2) end ctx.balancer_tried_servers[ctx.balancer_server] = true ctx.balancer_tried_servers_count = (ctx.balancer_tried_servers_count or 0) + 1 end, before_retry_next_priority = function (ctx) -- before_retry_next_priority方法 if ctx.balancer_tried_servers then core.tablepool.release("balancer_tried_servers", ctx.balancer_tried_servers) ctx.balancer_tried_servers = nil end ctx.balancer_tried_servers_count = 0 end, } end 前面的server_picker.get就是调用这里的get方法。apisix中的upstream server放到lru的缓存中，所有的worker共享这个缓存，缓存击穿后通过resty.lock保证只有一个worker去etcd中获取数据。
到这里apisix从etcd获取数据，有变更时更新缓存数据的流程介绍完了。</content></entry><entry><title>2021年中国云服务市场规模及格局</title><url>https://lizj3624.github.io/post/cloud-cn-2021/</url><categories><category>云计算市场</category></categories><tags><tag>云计算市场</tag></tags><content type="html"> 3月21日，Canalys 发布2021年中国云计算市场报告显示，中国的云基础设施市场规模已达274亿美元。由阿里云、华为云、腾讯云和百度智能云组成的“中国四朵云”占据80%的中国云计算市场，稳居主导地位。 阿里云在2021年引领云基础设施服务市场，占总支出的37%。阿里巴巴在2021年的市场份额略有下降，主要是受政策监管和互联网客户增长放缓的影响。但是在主要客户的长期承诺和传统行业业务扩张的推动下，它仍然增长了30%。
华为云在2021年达到18%的市场份额，每年增长67%。快速增长拉大了华为云与腾讯云的差距，稳居市场第二。
第三大提供商腾讯云占16%的市场份额，增长了55%。腾讯云2021年整体增长平稳，多板块多元化增长。
第四大供应商百度AI云占9%的市场份额，增长55%。由于其业务主要集中在在线营销和人工智能上，百度在去年受到政府法规的影响小于腾讯和阿里巴巴。
Canalys研究分析师布莱克·默里表示，“企业在数字化转型方面的投资仍在继续，这为云厂商创造了巨大机会。Canalys预计中国云计算市场规模将在2026年达到847亿美元，2021-2026年的复合增长率(CAGR)有望维持在25%。 看一下国内云计算公司的营收数据
华为云 3月28日，华为公布2021年年度报告。华为公司副董事长、CFO孟晚舟介绍说，华为云2021年营收201亿人民币，同比增长34%，在全球IaaS市场排名第五。华为云的亮眼表现成为了华为2021年财报的一大亮点。
腾讯云 3月23日，腾讯发布2021年业绩报告。财报显示尽管腾讯盈利增长有所放缓，但To B业务在2021年保持稳健增长，成为主要业务中的重要增长板块。 2021年Q4 To B业务超越游戏成为腾讯最大收入来源，其中金融科技及企业服务板块营收达480亿元。财报中并没有直接披露云服务的财务数据，我们可以大体推算一下， 2019年披露云服务年收入170亿，根据百度云增速60%和阿里云增速20%，腾讯云增速应该在两者之间，给复合增长率45%~50%，可以推算出2021年腾讯云的收入350亿~380亿，我们取平均数365亿。
百度智能云 3月1日，百度发布2021 Q4及全年财报显示，百度智能云四季度营收52亿元，同比增长60%，2021年实现全年总营收151亿元，同比增长64%。
阿里云 2月24日，阿里巴巴最新的2022财年第三季度财报显示，截至2021年12月31日的三个月里，阿里云收入264.31亿元，抵销跨分部交易（即服务阿里集团内部）后收入为195.39亿元，同比增长20%。 再结合2021年前三个季度的财报，可以统计出阿里云2021年总收入为792.5亿元。
简单预测未来三年云计算收入 2021 2022 2023 2024 年复合增长率 阿里云 792.50 951.00 1141.20 1369.44 20% 腾讯云 365.00 474.50 616.85 616.85 30% 百度智联云 151.00 211.40 295.96 414.34 40% 华为云 201.00 281.40 393.96 772.16 40% Canalys预计2021-2026年的复合增长率(CAGR)有望维持在25%，我们根据规模和一些监管政策，给阿里云年复合增长率20%，腾讯云30%，百度智联云和华为云为40%，单位：亿元
引用 Canalys：2021年中国云服务市场规模达到274亿美元 同比增长45%
科技云报道：“内卷”的云厂商财报：稳中有变，行业优势被拉平
腾讯云255亿元，高歌猛进，位列2020云综合排名第五
腾讯发布2021年财报：To B成最大收入来源 加大全链路自研</content></entry><entry><title>2021年全国在线零售以及三大电商GMV分析</title><url>https://lizj3624.github.io/post/gmv/</url><categories><category>财报</category><category>京东</category></categories><tags><tag>京东</tag><tag>财报</tag></tags><content type="html"> 2021年在线零售 2022.1.17号国家统计局公布2021年社会消费品零售总额。
2021年，社会消费品零售总额440823亿元，比上年增长12.5%，两年平均增速为3.9%。 其中，除汽车以外的消费品零售额397037亿元，增长12.9%。扣除价格因素，2021年社会消费品零售总额比上年实际增长10.7%。
2021年，全国网上零售额130884亿元，比上年增长14.1%。其中，实物商品网上零售额108042亿元，增长12.0%，占社会消费品零售总额的比重为24.5%； 在实物商品网上零售额中，吃类、穿类和用类商品分别增长17.8%、8.3%和12.5%。
三大电商平台GMV 阿里GMV 2022.2.24美股盘前，阿里巴巴公布截至2021年四季度（2022财年Q3）的财务业绩。营收同比增长10%，净利润同比降低25%，财报中没有公布GMV数据，我们可以 推测一下，去年5.13号阿里巴巴集团公布2021财年（2020年4月-2021年3月），当时财报显示GMV达到8.119万亿元，但是后面的两个季度营收增速降级，估计拖累GMV， 甚至GMV都是负增长，有机构推测阿里现在的GMV在全国在线零售总额占比都不到50%，我们就打个9折，推测(2021自然年)GMV=8.119万亿 * 0.9 = 7.3071万亿。
京东GMV 2022.3.10号京东发布2021Q4及全年财报，没有具体说GMV数据，但是说到GMV同比增长26.2%，翻了翻2020年的年报GMV 26125亿元，2021年GMV 26125亿元 * 1.262 = 3.29万亿
拼多多GMV 2022.3.21号财报中显示全年GMV：2.441万亿，同比增长46%。
总结 拼多多的GMV增长最快(46%)，占比16%，估计明年超越占25%的京东，阿里丢掉份额估计大部分让拼多多抢去了。
引用 2021年社会消费品零售总额增长12.5%-国家统计局 阿里年度GMV新增1万亿，今年将重点支持中小商家 自营坚挺，POP放缓，京东重回盈亏线 三大平台的财报数据</content></entry><entry><title>Crowdstrike 2022财年Q4及全年财报</title><url>https://lizj3624.github.io/post/crowdstrike-q4/</url><categories><category>财报</category><category>crowdstrike</category></categories><tags><tag>crowdstrike</tag><tag>财报</tag></tags><content type="html"> 2022财年Q4财务亮点 自然年2021Q4
收入$4.31亿，同比$2.649亿，增长63%；其中订阅收入$4.054亿，同期$2.447亿。
ARR(Annual Recurring Revenue)增加YoY 65%，截止2022.1.31到$17.3亿，同期$2.169亿。
订阅毛利(gross margin) GAAP毛利76%，同期78%，Non-GAAP毛利79%，同期80%
GAAP下运营亏损$2350w，同期$1580w，Non-GAAP盈利$8040w，同期盈利$3440w
GAAP下净亏损$4200w，同期$1900w，每股净亏损$0.18，同期$0.09；Non-GAAP净盈利$7040w，同期盈利$3160w，每股盈利$0.3，同期$0.13
运营产生净现金流$1.597亿，同期$1.145亿，自由现金流$1.273亿，同期$9740w
截止到2022.1.31现金及等价物$20亿
2022财年全年财务亮点 总收入$14.5亿，同期$8.744亿，增长66%；其中订阅收入$13.6亿，同期$8.047%，增长69%。
订阅毛利(gross margin) GAAP毛利76%，同期77%，Non-GAAP毛利79%，同期79%
GAAP下运营亏损$1.425亿，同期$9250w，Non-GAAP盈利$1.962亿，同期盈利$6240w
GAAP下净亏损$2.348亿，同期$9260w，每股净亏损$1.03，同期$0.43；Non-GAAP净盈利$1.607亿，同期盈利$6260w，每股盈利$0.67，同期$0.27
运营产生净现金流$5.748亿，同期$3.566亿，自由现金流$4.418亿，同期$2.929亿
最近运营亮点 截止到2022.1.31订阅用户16325，净增1638，YoY 65%
截止到2022.1.31订阅4个及以上的用户增长69%，订阅5个及以上的用户增长57%，订阅6个及以上的用户增长34%
发布了Falcon XDR module模块，增强了在端点检查和响应的领导地位
推出 Falcon Identity Threat Protection Complete，扩展 Falcon Complete 托管服务以包括Falcon Identity Threat Protection 模块，它将身份威胁预防和IT策略结合在一起执法，专家管理、监测和补救
推出macOS和Linux平台的零信任评估，与多家零信任厂商集成
选择托管安全服务的领导者Deloitte，作为为其 Managed Extended 的关键组件提供支持
再次被IDC评为现代端点安全收入的领导者，被Frost &amp; Sullivan 评为 2021 年亚太地区年度端点安全公司
获得独立测试机构SE Labs颁发的新AAA 奖，达到100%的攻击检测评级在最新的高级安全测试中，并连续第十次获得AV-Comparatives批准的商业安全产品奖
在2021年《财富》未来50强榜单中排名第一，该榜单表彰领先的上市公司通过对公司潜力和市场的评估，公司最适合长期增长，实现增长的能力。
2023财年Q1展望 总收入$4.589亿~$4.654亿
Non-GAAP运营收入$6170w~$6640w
Non-GAAP净收入$5200w~$5670w
Non-GAAP每股盈利$0.22~$0.24
2023财年全年展望 总收入$21.331亿~$21.632亿
Non-GAAP运营收入$2.892亿~$3.118亿
Non-GAAP净收入$2.511亿~$2.736亿
Non-GAAP每股盈利$1.03~$1.13</content></entry><entry><title>Linux的几种常用的锁介绍</title><url>https://lizj3624.github.io/post/linux-lock/</url><categories><category>linux</category><category>锁机制</category></categories><tags><tag>linux</tag><tag>锁机制</tag></tags><content type="html"> 最近公司项目因为一个自旋锁的原因，导致性能下降，换了轻量级的锁性能改善不好，在Linux下有各种锁比如互斥锁(mutex)、自旋锁(spin)、读写锁、文件锁、悲观锁、乐观锁，有时都分不清楚用法以及使用场景，这篇从[小林coding]摘录的介绍锁的文章讲解比较透彻，再次引用一下。
高并发的场景下，如果选对了合适的锁，则会大大提高系统的性能，否则性能会降低。
所以，知道各种锁的开销，以及应用场景是很有必要的。
接下来，就谈一谈常见的这几种锁：
正文 多线程访问共享资源的时候，避免不了资源竞争而导致数据错乱的问题，所以我们通常为了解决这一问题，都会在访问共享资源之前加锁。
最常用的就是互斥锁，当然还有很多种不同的锁，比如自旋锁、读写锁、乐观锁等，不同种类的锁自然适用于不同的场景。
如果选择了错误的锁，那么在一些高并发的场景下，可能会降低系统的性能，这样用户体验就会非常差了。
所以，为了选择合适的锁，我们不仅需要清楚知道加锁的成本开销有多大，还需要分析业务场景中访问的共享资源的方式，再来还要考虑并发访问共享资源时的冲突概率。
对症下药，才能减少锁对高并发性能的影响。
那接下来，针对不同的应用场景，谈一谈「互斥锁、自旋锁、读写锁、乐观锁、悲观锁」的选择和使用。
互斥锁与自旋锁：谁更轻松自如？ 最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。
加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。
当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：
互斥锁加锁失败后，线程会释放CPU ，给其他线程； 自旋锁加锁失败后，线程会忙等待，直到它拿到锁； 互斥锁是一种「独占锁」，比如当线程A加锁成功后，此时互斥锁已经被线程A独占了，只要线程A没有释放手中的锁，线程B加锁就会失败，于是就会释放CPU让给其他线程，既然线程B释放掉了CPU，自然线程B加锁的代码就会被阻塞。
对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：
所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。
那这个开销成本是什么呢？会有两次线程上下文切换的成本：
当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行； 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。
上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。
所以，如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。
自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。
一般加锁的过程，包含两个步骤：
第一步，查看锁的状态，如果锁是空闲的，则执行第二步； 第二步，将锁设置为当前线程持有； CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。
使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。
自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。
自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。
自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。
它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。
读写锁：读和写还有优先级区分？ 读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。
所以，读写锁适用于能明确区分读操作和写操作的场景。
读写锁的工作原理是：
当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。 所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。
知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。
另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。
读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图：
而写优先锁是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取读锁。如下图：
读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。
写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。
既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。
公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。
互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。
乐观锁与悲观锁：做事的心态有何不同？ 前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。
悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。
那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。
乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。
可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现乐观锁全程并没有加锁，所以它也叫无锁编程。
这里举一个场景例子：在线文档。
我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。
那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。
怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交改动，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。
服务端要怎么验证是否冲突了呢？通常方案如下：
由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号； 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。 实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。
乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。
总结 开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。
如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。
如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。
互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。
另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。
相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。
不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。
引用 面试官：你说说互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景 - 小林coding - 博客园</content></entry><entry><title>2022财年Zscaler的Q2财报</title><url>https://lizj3624.github.io/post/zscaler-q2/</url><categories><category>财报</category><category>zscaler</category></categories><tags><tag>zscaler</tag><tag>财报</tag></tags><content type="html"> 2022财年Q2对应自然年2021Q4
2022财年Q2(2021Q4)财务亮点 收入$2.556亿，YoY 63% 运营收入(亏损) GAAP亏损$0.839亿，占比33%，同期$0.539亿，占比34%，Non-GAAP收入$0.223亿 占9%，同期$0.148亿 占比9% 净收入(亏损) GAAP净亏损$1.004亿，同期盈利$0.675亿，Non-GAAP净收入$0.192亿，同期盈利$0.14亿 每股净收入(亏损) GAAP净亏损$0.71，同期盈利$0.5。Non-GAAP下盈利$0.13，同期$0.1 现金流，运营现金流$0.483亿，占比19%，同期$0.304亿，占比19%，自由现金流$0.294亿，占比12%，同期$0.18亿，占比11% 截止到2022.1.31号递延收入$7.599亿，YoY 70% 截止到2022.1.31号现金及等价物$16.212亿，同期$1.187亿 2022财年Q3(2022Q1)展望 总收入$2.7亿~$2.72亿 Non-GAAP运营收入$0.19亿~$0.2亿 Non-GAAP每股净收入$0.1~$0.11 2022财年全年展望 总收入$10.45亿~10.5亿 计算出的账单为$13.65亿美~$13.7亿 Non-GAAP下运营收入$0.95亿~$0.98亿 Non-GAAP每股净收入$0.54~$0.56</content></entry><entry><title>Digital Ocean 2021q4</title><url>https://lizj3624.github.io/post/digital-ocean-2021q4/</url><categories><category>digitalocean</category><category>财报</category></categories><tags><tag>digitalocean</tag><tag>财报</tag></tags><content type="html"> 2021Q4财务亮点 收入$1.197亿，YoY 37% ARR截止到年底$4.9亿，YoY 37% 毛利(Gross profit) $0.753亿，毛利率63%，经调整毛利$0.974亿，毛利率81% 运营亏损$0.101亿，operating margin (%8)；Non-GAAP运营收入$0.141亿，operating margin 12% 经调整的EBITDA $0.378亿，EBITDA margin 32% 每股净亏损$0.11，Non-GAAP每股收入$0.1 截止到2021.12.31现金及现金等价物$17亿 2021Q4运营亮点 NDR 116%，同期105% ARPU $65.87，同比增加29% 总客户60.9w，每月付费$50的客户9.9w，这个群体占总收入的83%，比去年同期增长24%，2020年第四季度，NDR为117%。 通过2026年到期的0%可转换优先票据筹集15亿美元，提供资金以帮助为扩张努力提供资金。 来做微软的产品专家Hired Gabe Monroy作为CPO加盟 2021财年财务亮点 全年收入$4.286亿，YoY 35% 毛利$2.58亿，毛利率60%，经调整毛利$3.411亿，毛利率80% 运营亏损$0.112亿，operating margin (3%)；Non-GAAP下运营收入$0.504亿，non-GAAP operating margin 12% 经调整的EBITDA $1.363亿，EBITDA margin 32% 每股净亏损$0.21，摊薄后的Non-GAAP下每股净收益为$0.34 2021财年运营亮点 NDR 113%，同期103% ARPU $59.96，同比增长25% 收购serverless提供商Nimbella，将公司的能力扩展到快速增长的功能即服务 (FaaS) 市场。 与 MongoDB, Inc. 合作推出了DigitalOcean Managed MongoDB，这是一种完全托管的数据库即服务 (DBaaS) 产品。 2022Q1预测 总收入$1.26亿~$1.265亿之间 Non-GAAP operating margin 12%~13% Non-GAAP 每股收益$0.1~0.12之间 完全稀释的加权平均流通股约为1.28亿股。 2022全年预测 总收入$5.64亿~$5.68亿之间 Non-GAAP operating margin 13%~15% 自由现金流占收入8%~10% 收入增长对比
研发费用增长对比</content></entry><entry><title>Nginx的锁机制</title><url>https://lizj3624.github.io/post/nginx-lock/</url><categories><category>nginx</category><category>源码</category></categories><tags><tag>nginx</tag><tag>源码</tag></tags><content type="html"> 我们项目中nginx的dyups模块在大量更新时，有性能瓶颈，经排查发现时用的自旋锁导致性能瓶颈，dyups使用ngx_shmtx_lock和ngx_shmtx_trylock两种锁， 用户通过参数可以设置选择修改，发现ngx_shmtx_lock性能较差，其中ngx_shmtx_trylock这个锁每次执行的时候只是去抢一下锁，当没有抢到则立即返回失败。 ngx_shmtx_lock锁相当于一个自旋锁（splinlock）当进程执行到此处的时候会是一个死循环的去进行抢锁，当然中间加了一些自己的限制机制， 当抢一次失败的时候会增加下一次去抢所的时间间隔，而且抢了很多次后还是抢不到锁的时候就会先让出cpu一会 此处调用ngx_sched_yield让其他的程序先执行－－－找一个优先级等于或是高于当前程序的去执行，相比之下ngx_shmtx_trylock的性能高多了。 这两个锁都是使用了cpu级别的原子操作，不会发生上下文的切换。 在此研究一下nginx的锁机制，这是从CSDN摘录的文件。
nginx使用共享内存来进行进程间通信，那么就需要一把锁来确保进程通信的正确，在nginx中通过判断操作系统是否支持相应的锁来进行选定锁的类型，分为:
原子锁
信号量互斥锁
文件锁(互斥锁)
自旋锁(多处理器时使用)
ngx_shmtx.h
typedef struct { ngx_atomic_t lock; #if (NGX_HAVE_POSIX_SEM) //定义使用信号量 ngx_atomic_t wait; #endif } ngx_shmtx_sh_t; typedef struct { #if (NGX_HAVE_ATOMIC_OPS) //原子锁 ngx_atomic_t *lock; #if (NGX_HAVE_POSIX_SEM) //信号量互斥锁 ngx_atomic_t *wait; ngx_uint_t semaphore; sem_t sem; #endif #else //文件锁 ngx_fd_t fd; u_char *name; #endif ngx_uint_t spin; //多处理器时才会使用,即ngx_ncpu>1 } ngx_shmtx_t; ngx_shmtx.c
ngx_int_t ngx_shmtx_create( ngx_shmtx_t *mtx, ngx_shmtx_sh_t *addr, u_char *name) { mtx->lock = &amp;addr->lock; //获取位于共享内存中的lock区 if (mtx->spin == (ngx_uint_t) -1) { //判断是否支持信号量互斥锁 return NGX_OK; } mtx->spin = 2048; #if (NGX_HAVE_POSIX_SEM) mtx->wait = &amp;addr->wait; /** *信号量相关的头文件 *#include &lt;semaphore.h> *int sem_init(sem_t *sem,int pshared,unsigned int value); *当pshared为0代表该信号量用于多线程间的同步 *大于0表示用于多个相关进程间的同步 *value为初始化sem的值 **/ if (sem_init(&amp;mtx->sem, 1, 0) == -1) { ngx_log_error(NGX_LOG_ALERT, ngx_cycle->log, ngx_errno, "sem_init() failed"); } else { mtx->semaphore = 1; } #endif return NGX_OK; } void ngx_shmtx_destroy(ngx_shmtx_t *mtx) { #if (NGX_HAVE_POSIX_SEM) //当支持信号量时才能生效 if (mtx->semaphore) { //mtx->semaphore初始化成功时为1 if (sem_destroy(&amp;mtx->sem) == -1) { //清理信号量 ngx_log_error(NGX_LOG_ALERT, ngx_cycle->log, ngx_errno, "sem_destroy() failed"); } } #endif } void ngx_shmtx_lock(ngx_shmtx_t *mtx) { ... for ( ;; ) { //是否持有锁 if (*mtx->lock == 0 &amp;&amp; ngx_atomic_cmp_set(mtx->lock, 0, ngx_pid)) { return; } //有多个处理器时启用自旋锁 if (ngx_ncpu > 1) { for (n = 1; n &lt; mtx->spin; n &lt;&lt;= 1) { for (i = 0; i &lt; n; i++) { /*ngx_cpu_pause是汇编代码 __asm__ ("pause")的拓展*/ ngx_cpu_pause(); } if (*mtx->lock == 0 &amp;&amp; ngx_atomic_cmp_set(mtx->lock, 0, ngx_pid)) { return; } } } #if (NGX_HAVE_POSIX_SEM) if (mtx->semaphore) { //具有原子操作的__sync_fetch_and_add(mtx->wait, 1) (void) ngx_atomic_fetch_add(mtx->wait, 1); if (*mtx->lock == 0 &amp;&amp; ngx_atomic_cmp_set(mtx->lock, 0, ngx_pid)) { //获得锁后共享内存wait减一 (void) ngx_atomic_fetch_add(mtx->wait, -1); return; } ... while (sem_wait(&amp;mtx->sem) == -1) { ngx_err_t err; err = ngx_errno; /**若err=NGX_EINTR *此时的信号量等待被打断而不是出错 *向log写入信息后继续等待 */ if (err != NGX_EINTR) { ... } } ... continue; } #endif //程序挂起一段时间，让出处理器，当使用信号量时无效 ngx_sched_yield(); } } 如果没有使用信号量就和之前的自旋锁没有什么区别。 如果使用了信号量，并且自旋锁一轮过来(spin消耗完全)都没有加锁成功，则会尝试最后一次加锁，如果加锁失败则使用信号量进行休眠等待唤醒。 void ngx_shmtx_unlock(ngx_shmtx_t *mtx) { if (mtx->spin != (ngx_uint_t) -1) { //判断该进程是否能够进入休眠状态 ... } //将lock置为0，释放了锁 if (ngx_atomic_cmp_set(mtx->lock, ngx_pid, 0)) { ngx_shmtx_wakeup(mtx); } } ngx_uint_t ngx_shmtx_force_unlock(ngx_shmtx_t *mtx, ngx_pid_t pid) { //强迫进程释放锁 ... if (ngx_atomic_cmp_set(mtx->lock, pid, 0)) { ngx_shmtx_wakeup(mtx); return 1; } return 0; } static void ngx_shmtx_wakeup(ngx_shmtx_t *mtx) { #if (NGX_HAVE_POSIX_SEM) ngx_atomic_uint_t wait; if (!mtx->semaphore) { //判断是否使用了信号量 return; } for ( ;; ) { wait = *mtx->wait; //无进程在等待直接返回 if ((ngx_atomic_int_t) wait &lt;= 0) { return; } //通过原子操作减少当前等待的进程数 if (ngx_atomic_cmp_set(mtx->wait, wait, wait - 1)) { break; } } ... if (sem_post(&amp;mtx->sem) == -1) { //释放了信号量锁 ... } #endif } 到此可以看出nginx如何实现高效的原子互斥锁， 即通过信号量使得进程去获得一把锁，当一个进程使用sem_post释放了锁， 另一个进程sem_wait得到了锁，若是处于sem当前值等于0时，则进程进入睡眠状态等待唤醒。
nginx实现的另一种锁，文件锁，即不支持原子锁时，通过文件锁保证进程通信的准确。
ngx_int_t ngx_shmtx_create(ngx_shmtx_t *mtx, ngx_shmtx_sh_t *addr, u_char *name) { if (mtx->name) { //判断mtx->name已经初始化 if (ngx_strcmp(name, mtx->name) == 0) { mtx->name = name; return NGX_OK; } //如果已经存在打开的文件则关闭 ngx_shmtx_destroy(mtx); } //打开文件名为name的文件 mtx->fd = ngx_open_file(name, NGX_FILE_RDWR, NGX_FILE_CREATE_OR_OPEN, NGX_FILE_DEFAULT_ACCESS); if (mtx->fd == NGX_INVALID_FILE) { ... } if (ngx_delete_file(name) == NGX_FILE_ERROR) { /*ngx_delete_file为ulink *由于并不需要真实文件，只需要文件fd在内核中存在即可 */ ... } mtx->name = name; return NGX_OK; } void ngx_shmtx_destroy(ngx_shmtx_t *mtx) { if (ngx_close_file(mtx->fd) == NGX_FILE_ERROR) { //ngx_close_file()即为close() ... } } ngx_uint_t ngx_shmtx_trylock(ngx_shmtx_t *mtx) { ngx_err_t err; //文件上锁，此时文件锁并不会使阻塞进程 err = ngx_trylock_fd(mtx->fd); ... #if __osf__ /* Tru64 UNIX */ if (err == NGX_EACCES) { return 0; } #endif ... return 0; } void ngx_shmtx_lock(ngx_shmtx_t *mtx) { ngx_err_t err; err = ngx_lock_fd(mtx->fd); if (err == 0) { return; } ... } ngx_shmtx_lock与ngx_shmtx_trylock区别为ngx_shmtx_lock在上锁时， 即fcntl(fd, F_SETLKW, &amp;fl)中cmd的字段为F_SETLKW，将会在不能获取锁时阻塞进程，而ngx_shmtx_trylock中的字段为F_SETLK并不会阻塞进程。
void ngx_shmtx_unlock(ngx_shmtx_t *mtx) { ... //释放锁将fcntl中cmd字段置为UNLCK即可 err = ngx_unlock_fd(mtx->fd); if (err == 0) { return; } ... } //强制释放锁 ngx_uint_t ngx_shmtx_force_unlock(ngx_shmtx_t *mtx, ngx_pid_t pid) { return 0; } nginx实现的锁有个共同点即是在其他进程始终不放弃锁时，一段时间后将会强制获得该锁。 有关信号量的内容可以通过搜索Linux信号量。
引用
nginx之nginx_shmtx(锁机制)
nginx锁(spinlock,ngx_shmtx_t)</content></entry><entry><title>京东2021Q4以及全年财报</title><url>https://lizj3624.github.io/post/jd-q4/</url><categories><category>财报</category><category>京东</category></categories><tags><tag>京东</tag><tag>财报</tag></tags><content type="html"> 2021Q4以及全年财务亮点 2021年Q4净营收为2759亿元人民币（约合433美元），同比增长23.0%。归属于普通股股东的净亏损为52亿元（约合8亿美元），而上年同期净利润为243亿元。 基于非美国通用会计准则，归属于普通股股东的净利润为36亿元（约合6亿美元），而上年同期净利润为24亿元。
2021全年净营收为9516亿元（约合1493美元），较2020年增长27.6%。归属于普通股股东的净亏损为36亿元（约合6亿美元），而2020年净利润为494亿元。 基于非美国通用会计准则，归属于普通股股东的净利润为172亿元（约合27亿美元），而2020年净利润为168亿元。
2021Q4财务数据 净营收为2759亿元（约合433美元），同比增长23.0%。其中，净产品营收同比增长22.1%，净服务营收同比增长28.3%。
营收成本为2388亿元（约合375亿美元），与上年同期的1932亿元相比增长23.6%。
履约成本为163亿元（约合26亿美元），与上年同期的148亿元相比增长10.7%。
营销成本为134亿元（约合21亿美元），与上年同期的104亿元相比增长28.2%。
研发开支为41亿元（约合6亿美元），而上年同期为45亿元。
总务与行政开支为37亿元（约合6亿美元），与上年同期的20亿元相比增长89.0%。
运营亏损3.920亿元（约合6150万美元），而上年同期运营利润5.949亿元。
基于非美国通用会计准则，运营利润28亿元（约合4亿美元），而上年同期为12亿元。
基于非美国通用会计准则，EBITDA（息税折旧及摊销前利润）为42亿元（约合7亿美元），而上年同期EBITDA为27亿元。
其他非运营亏损为2200万元（350万美元），而2020年同期其他非运营利润为220亿元。
净利润/亏损 归属于普通股股东的净亏损为52亿元（约合8亿美元），而上年同期净利润为243亿元。
基于非美国通用会计准则，归属于普通股股东的净利润为36亿元（约合6亿美元），而上年同期净利润为24亿元。
每股美国存托股（ADS）摊薄亏损3.33元（约合0.52美元），而上年同期每股ADS摊薄收益15.18元。
基于非美国通用会计准则，每股ADS摊薄收益为2.21元（约合0.35美元），而上年同期每股ADS摊薄收益为1.49元。
现金流 截至2021年12月31日，京城持有的现金、现金等价物、受限现金和短期投资总额为1913亿元（约合300亿美元），而截至2020年12月31日为1511亿元。
第四季度，用于投资活动的净现金为188亿元（约合29亿美元），主要包括短期投资的增加和用于资本支出的现金。
2021年第四季度，用于融资活动的净现金为34亿元（约合5亿美元），主要包括偿还短期债务。
2021年全年财务数据 净营收为9516亿元（约合1493美元），较2020年增长27.6%。其中净产品营收同比增长25.1%，净服务营收同比增长44.7%。
营收成本为8225亿元（约合1291亿美元），与2020年的6367亿元相比增长29.2%。
履约成本为591亿元（约合93亿美元），与2020年的487亿元相比增长21.3%。
营销成本为387亿元（约合61亿美元），与2020年的272亿元相比增长42.7% 。
研发开支为163亿元（约合26亿美元），而2020年为161亿元。
总务与行政开支为116亿元（约合18亿美元），而2020年为64亿元。
运营利润41亿元（约合6亿美元），而2020年运营利润123亿元。
基于非美国通用会计准则，运营利润134亿元（约合21亿美元），而2020年运营利润为153亿元。
净利润 归属于普通股股东的净亏损为36亿元（约合6亿美元），而2020年净利润为494亿元。
基于非美国通用会计准则，归属于普通股股东的净利润为172亿元（约合27亿美元），而2020年净利润为168亿元。
每股美国存托股（ADS）摊薄亏损2.29元（约合0.36美元），而2020年每股ADS摊薄收益31.68元。
基于非美国通用会计准则，2020年每股美国存托股（ADS）摊薄收益10.72元（约合1.69美元），而2020年每股ADS摊薄收益10.56元。
2021年全年，用于投资活动的净现金为742亿元（约合117亿美元），融资活动提供的净现金为195亿元（约合31亿美元）。
2021年，京东活跃用户数为5.697亿，与2020年的为4.719亿相比增长20.7%。</content></entry><entry><title>美国国债收益率</title><url>https://lizj3624.github.io/post/us-bonds/</url><categories><category>宏观经济</category><category>美债收益率</category></categories><tags><tag>宏观经济</tag><tag>美债收益率</tag></tags><content type="html"> 2022.4.2号，美债又崩了，2/10年期收益率再度倒挂，2/30年期2007年以来首次倒挂，很多机构发出美国经济衰退的风险预警， 再此学习一些美债收益率以及美债收益率倒挂的原因以及可能导致影响。
作为市场上公认的“全球资产定价之锚”，10年期美债收益率的一举一动，往往牵动着股市、汇市乃至商品市场投资者的目光。 不过，如今在华尔街，投行交易员聚焦的，可不光光只有基准10年期美债收益率的表现，他们还在密切追踪着一件事：美债收益率曲线会不会倒挂！
美债收益率曲线是什么 美国财政部通过发行各种形式的债券为联邦政府的预算债务提供资金。 当前规模已经高达23万亿美元的美国公债市场包括:
1月至1年期的短期国库券(T-Bills) 2年至10年期的中期国债(T-Notes) 20年期和30年期的长期国债(T-Bonds) 而美债收益率曲线便描绘了所有各周期国库券和国债的收益率。投资者通过观察其形状， 不仅可以一目了然地知悉当前各周期收益率的所处的水平，甚至可以借此来推断市场对美国经济增长和货币政策的预期。
美债收益率曲线应该是怎样的 在正常情况下，美债收益率曲线理应是一条从左至右（从短期到长期）向上倾斜的曲线，如下面这张我们所截的一年前的美债收益率曲线图： 这是因为投资者若持有较长期债券，便需要承担通胀上升将降低预期回报的风险，理应得到更多的补偿。这意味着10年期美债收益率通常会高于两年期美债收益率， 因为它的存续期更长。美债收益率与美债价格呈反向变动。
与此同时，这条曲线趋陡通常意味着人们预期经济活动将走强，通胀将上升，利率将上升。曲线趋平则可能意味着相反的情况: 投资者即便预计短期内会加息，并却已对经济增长前景失去了信心。
为何收益率曲线如今趋平了 美国中短期国债收益率今年一直在迅速上升，反映出人们对美联储将加息的预期，而较长期美债收益率的升势则明显相对缓和，因市场担心政策收紧可能损及经济。 一组行情对比可以直观地体现出这一点：追踪短期利率预期的两年期美债收益率已从去年年底的0.73%升至1.94%，涨幅达到166%。基准10年期美债收益率则仅仅从1.5%升至2.19%左右，涨幅为46%。 其结果是，美债收益率曲线总体呈现扁平化趋势。
曲线若倒挂意味着什么 虽然加息可能是对抗通胀的武器，但其也可能通过提高从抵押贷款到汽车贷款的所有贷款成本从而导致经济增长放缓。
根据旧金山联储在2018年发布的一份报告，自1955年以来，2年期和10年期美债收益率曲线在每次衰退之前都会出现倒挂， 经济衰退大致发生在倒挂出现的6-24个月之后。在这段漫长的岁月长河里，美债收益率只发出过一次错误的倒挂信号。
最为神奇的是，上一次2年期和10年期美债收益率曲线反转发生在2019年。而次年，美国经济便陷入了衰退——由新冠疫情大流行所引起的。
当前美债收益率曲线存在哪些倒挂 截止到2022.4.5号，2/10年期收益率再度倒挂，2/30年期2007年以来首次倒挂，5/10年期收益率在2020.3首次出现倒挂.
曲线倒挂对现实世界意味着什么 除了可能会对经济前景发出指引信号外，美债收益率曲线的形态还会对消费者和企业产生影响。
当短期利率上升时，美国国内银行往往会提高一系列消费和商业贷款的基准利率，包括小型企业贷款和信用卡利息，从而导致消费者的借贷成本压力上升，抵押贷款利率往往也会水涨船高。
这意味着当收益率曲线变陡时，银行能够以较低的利率借钱，并以较高的利率放贷。相反，当曲线趋平时，他们会发现利润受到挤压，这可能会阻碍放贷。
引用 一文读懂：美债收益率曲线倒挂究竟意味着什么？为何眼下必须关注？ 美债又崩了，2/10年期收益率再度倒挂，2/30年期2007年以来首次倒挂</content></entry><entry><title>APISIX源码分析-请求处理流程</title><url>https://lizj3624.github.io/post/apisix-request-processing/</url><categories><category>apisix</category><category>nginx</category></categories><tags><tag>apisix</tag><tag>nginx</tag></tags><content type="html"> APISIX的请求处理流程跟Nginx处理请求的各个阶段是一致的，只是APISIX在各个阶段嵌入自己详细处理请求的逻辑。
init_worker阶段 init_worker阶段主要是在Nginx的worker初始化阶段，虽然不参与请求的处理，但是这个节点做了很多准备工作，针对APISIX来说这阶段从etcd获取 route、server、plugin、upstream信息，并缓存在每个worker中，这个节点主要函数http_init_worker。
init_worker_by_lua_block { apisix.http_init_worker() } 看一下这个函数主要处理逻辑，这个函数主要在init.lua源文件中
function _M.http_init_worker() ... -- worker事件，如果路由、上游等信息变更通知，这个机制是跟kong一致 local we = require("resty.worker.events") local ok, err = we.configure({shm = "worker-events", interval = 0.1}) if not ok then error("failed to init worker event: " .. err) end -- 服务发现 local discovery = require("apisix.discovery.init").discovery if discovery and discovery.init_worker then discovery.init_worker() end -- upstream负载均衡器的init_worker require("apisix.balancer").init_worker() load_balancer = require("apisix.balancer") require("apisix.admin.init").init_worker() require("apisix.timers").init_worker() require("apisix.debug").init_worker() -- 插件init_worker初始化 plugin.init_worker() -- http路由的init_worker初始化 router.http_init_worker() require("apisix.http.service").init_worker() plugin_config.init_worker() require("apisix.consumer").init_worker() ... -- upstream的init_worker初始化 apisix_upstream.init_worker() require("apisix.plugins.ext-plugin.init").init_worker() ... end 这些init_worker函数主要是从配置中跟key前缀拉取数据，并缓存在worker中，看一下七层HTTP路由函数router.http_init_worker()
function _M.http_init_worker() local conf = core.config.local_conf() local router_http_name = "radixtree_uri" local router_ssl_name = "radixtree_sni" -- 路由匹配支持三种模式，radixtree_uri, radixtree_host_uri，radixtree_uri_with_paramter，都是基于基数树。 -- 从配置config-default.yaml获取路由匹配模式. if conf and conf.apisix and conf.apisix.router then router_http_name = conf.apisix.router.http or router_http_name router_ssl_name = conf.apisix.router.ssl or router_ssl_name end -- 根据路由匹配模式获取引用的处理模块，相应的模块主要在apisix/http/route模块下 local router_http = require("apisix.http.router." .. router_http_name) attach_http_router_common_methods(router_http) -- 主要调用时apisix/http/route.lua中init_worker函数 router_http.init_worker(filter) _M.router_http = router_http -- 处理ssl的路由 local router_ssl = require("apisix.ssl.router." .. router_ssl_name) router_ssl.init_worker() _M.router_ssl = router_ssl _M.api = require("apisix.api_router") local global_rules, err = core.config.new("/global_rules", { automatic = true, item_schema = core.schema.global_rule, checker = plugin_checker, }) if not global_rules then error("failed to create etcd instance for fetching /global_rules : " .. err) end _M.global_rules = global_rules end 我们在跟进看一下route.lua的init_worker函数
function _M.init_worker(filter) local user_routes, err = core.config.new("/routes", { automatic = true, item_schema = core.schema.route, checker = check_route, filter = filter, }) if not user_routes then error("failed to create etcd instance for fetching /routes : " .. err) end return user_routes end 这里的core.config.new是调用的配置中心config_etcd.lua的new函数。
-- core.lua -- 根据配置config_default.yaml的config_center选择配置中心，默认是etcd local config_center = local_conf.apisix and local_conf.apisix.config_center or "etcd" log.info("use config_center: ", config_center) -- config就是选择配置中心的处理模块，在core/config_*.lua local config = require("apisix.core.config_" .. config_center) config.type = config_center 在先看一下core/config_etcd.lua的new函数
function _M.new(key, opts) local local_conf, err = config_local.local_conf() if not local_conf then return nil, err end local etcd_conf = local_conf.etcd local prefix = etcd_conf.prefix local resync_delay = etcd_conf.resync_delay if not resync_delay or resync_delay &lt; 0 then resync_delay = 5 end local health_check_timeout = etcd_conf.health_check_timeout if not health_check_timeout or health_check_timeout &lt; 0 then health_check_timeout = 10 end local automatic = opts and opts.automatic local item_schema = opts and opts.item_schema local filter_fun = opts and opts.filter local timeout = opts and opts.timeout local single_item = opts and opts.single_item local checker = opts and opts.checker local obj = setmetatable({ etcd_cli = nil, key = key and prefix .. key, automatic = automatic, item_schema = item_schema, checker = checker, sync_times = 0, running = true, conf_version = 0, values = nil, need_reload = true, routes_hash = nil, prev_index = 0, last_err = nil, last_err_time = nil, resync_delay = resync_delay, health_check_timeout = health_check_timeout, timeout = timeout, single_item = single_item, filter = filter_fun, }, mt) if automatic then if not key then return nil, "missing `key` argument" end if loaded_configuration[key] then local res = loaded_configuration[key] loaded_configuration[key] = nil -- tried to load log.notice("use loaded configuration ", key) local dir_res, headers = res.body, res.headers load_full_data(obj, dir_res, headers) end -- 设置定时器的回调函数，定期从etcd更新数据 ngx_timer_at(0, _automatic_fetch, obj) else local etcd_cli, err = get_etcd() if not etcd_cli then return nil, "failed to start a etcd instance: " .. err end obj.etcd_cli = etcd_cli end if key then created_obj[key] = obj end return obj end SSL握手阶段 这个阶段设置的是http_ssl_phase函数，校验证书，支持动态更新证书和私钥
function _M.http_ssl_phase() local ngx_ctx = ngx.ctx local api_ctx = ngx_ctx.api_ctx if api_ctx == nil then api_ctx = core.tablepool.fetch("api_ctx", 0, 32) ngx_ctx.api_ctx = api_ctx end local ok, err = router.router_ssl.match_and_set(api_ctx) if not ok then if err then core.log.error("failed to fetch ssl config: ", err) end ngx_exit(-1) end end -- apisix/ssl/route/radixtree_sni.lua function _M.match_and_set(api_ctx) -- redixtree route不存在时或者版本有变更时，重建 -- sni sni, err = apisix_ssl.server_name() -- 查找路由 local ok = radixtree_router:dispatch(sni_rev, nil, api_ctx) -- 更加sni设置证书和私钥 ok, err = set_pem_ssl_key(sni, matched_ssl.value.cert, matched_ssl.value.key) ... end access阶段 这个阶段设置是http_access_phase，这个函数是APISIX处理请求的核心函数入口，这里匹配路由，处理插件，查找上游(upstream)，根据balancer挑选合适的上游server。
function _M.http_access_phase() -- 通过ngx.ctx在请求各阶段传递数据 local ngx_ctx = ngx.ctx -- api_ctx是apisix请求上下文 local api_ctx = core.tablepool.fetch("api_ctx", 0, 32) ngx_ctx.api_ctx = api_ctx -- 将ngx.var设置到api_ctx core.ctx.set_vars_meta(api_ctx) -- 路由匹配，apisix/http/route/radixtree_uri.lua的match函数，然后再调用apisix/http/route.lua的match_uri函数 router.router_http.match(api_ctx) -- 根据匹配的路由查找插件、service、upstream local upstream = get_upstream_by_id(up_id) -- 挑选upstream的server local server, err = load_balancer.pick_server(route, api_ctx) ... end 路由匹配主要是lua-resty-radixtree，这是支流科技开源的基数树的实现，这个公司也是apisix的主要维护公司，是一家开源的商业公司。
根据balancer挑选server主要是调用balancer.lua的pick_server函数
local function pick_server(route, ctx) ... -- 获取缓存数据 local server_picker = ctx.server_picker if not server_picker then server_picker = lrucache_server_picker(key, version, create_server_picker, up_conf, checker) end if not server_picker then return nil, "failed to fetch server picker" end -- 根据负载算法获取一个合适的upstream server, apisix/balancer/*.lua是apisix支持的负载算法的实现 local server, err = server_picker.get(ctx) if not server then err = err or "no valid upstream node" return nil, "failed to find valid upstream server, " .. err end ctx.balancer_server = server ... end _M.pick_server = pick_server 看一下server_picker.get函数如何根据负载算法挑选server的。优先看一下如果创建一个server_picker对象，这个实现主要在create_server_picker函数中
-- balancer.lua local function create_server_picker(upstream, checker) local picker = pickers[upstream.type] if not picker then -- 根据upstream.type类型也就是负载算法(roundrobin\chash\ewma\least_conn)选择合适的负载算法模块(apisix/balancer/*.lua) pickers[upstream.type] = require("apisix.balancer." .. upstream.type) picker = pickers[upstream.type] end ... -- 调用相应负载算法模块的new方法 local server_picker = picker.new(up_nodes[up_nodes._priority_index[1]], upstream) ... end 然后在看一下具体一个负载算法的实现，那就以roundrobin为例。
local roundrobin = require("resty.roundrobin") function _M.new(up_nodes, upstream) local safe_limit = 0 for _, weight in pairs(up_nodes) do -- the weight can be zero safe_limit = safe_limit + weight + 1 end local picker = roundrobin:new(up_nodes) local nodes_count = nkeys(up_nodes) return { upstream = upstream, get = function (ctx) --- get方法 if ctx.balancer_tried_servers and ctx.balancer_tried_servers_count == nodes_count then return nil, "all upstream servers tried" end local server, err for i = 1, safe_limit do server, err = picker:find() if not server then return nil, err end if ctx.balancer_tried_servers then if not ctx.balancer_tried_servers[server] then break end else break end end return server end, after_balance = function (ctx, before_retry) --after_balance方法 if not before_retry then if ctx.balancer_tried_servers then core.tablepool.release("balancer_tried_servers", ctx.balancer_tried_servers) ctx.balancer_tried_servers = nil end return nil end if not ctx.balancer_tried_servers then ctx.balancer_tried_servers = core.tablepool.fetch("balancer_tried_servers", 0, 2) end ctx.balancer_tried_servers[ctx.balancer_server] = true ctx.balancer_tried_servers_count = (ctx.balancer_tried_servers_count or 0) + 1 end, before_retry_next_priority = function (ctx) --方法 if ctx.balancer_tried_servers then core.tablepool.release("balancer_tried_servers", ctx.balancer_tried_servers) ctx.balancer_tried_servers = nil end ctx.balancer_tried_servers_count = 0 end, } end 这个负载算法主要在apisix/balancer/roundrobin.lua下实现的，依赖了OpenResty的roundrobin， get方法就是前面pick_server函数中picker_server.get，这时已经选择合适的上游server。
balancer阶段 这个阶段设置http_balancer_phase，这个阶段对应OpenResty的balancer_by_lua。这里主要将挑选的server调用OpenResty的balancer.set_current_peer设置当前需要转发的server，同时设置 超时以及重试次数等参数。
header_filter阶段 设置函数http_header_filter_phase这里主要是设置响应头
body_filter节点 设置函数http_body_filter_phase
log阶段 设置函数http_log_phase
这就是一个HTTP请求处理流程，APISIX也是在stream，stream处理流程跟HTTP类型。
引用 apisix源码分析
APISIX源码分析——路由匹配
kong的事件和缓存
OpenResty的balancer</content></entry><entry><title>怎样选择成长股-费雪读书笔记</title><url>https://lizj3624.github.io/post/fisher-common-stocks-and-uncommon-profits-reading/</url><categories><category>费雪</category><category>投资</category></categories><tags><tag>费雪</tag><tag>投资</tag></tags><content type="html"> 投资想赚大钱，必须有耐性；股票市场本质上具有欺骗投资人的特性。
&ldquo;闲聊"有妙处，买一家公司的股票前要充分的进行调研，通过跟公司相关的供应商，竞争对手，同行业， 公司员工(也包含离职或被辞退)，公司高管等的"闲聊&rdquo;，获取公司的各个渠道的信息，构成了对这家公司认知的全貌。
寻找优良普通股的15个要点:
(1) 这家公司的产品或服务有没有充分的市场潜力，至少几年内营业额能否大幅成长？优良的公司大致有两类：幸运且能干和能干所以幸运，这两个都必须要有能干的管理层。 (2) 为了进一步提高总体销售水平，发现新的产品增长点，管理层是不是决心继续开发新产品或新工艺？这一点考察管理层是否有一种为提高销售水平的积极主动开发新市场或新工艺。 (3) 和公司的规模相比，这家公司的研究发展努力，有多大的效果？这个考察公司研发能力，在研发的投入，是否有有一支能干的研发团队(专业的科研人员和协调组织的人员)，研发的产品是否有市场等，优良的公司都比较重视研发能力。 (4) 这家公司有没有高人一等的销售组织？ (5) 这家公司的利润率高不高？这里并不是利润率越高越好，要看利润是否一直可以持续，利润率降低是要看降低的真正原因；利润率低也不是不能投资，要看行业属性，比如好市多(Costco)，京东等。 (6) 这家公司做了什么事，以维持或改善利润率？ (7) 这家公司的劳资和人事关系是不是很好？优良的公司劳资和人事关系都比较和谐，员工工作的积极性就比较高，对公司发展是利好，和谐的关系是一个良性循环。 (8) 这家公司的高级主管关系很好吗？上下一条心，其利断金。但是随着公司人员规模扩大，管理起来比较棘手了；有人的地方就有江湖，有江湖就有争斗。 (9) 公司管理阶层的深度够吗？管理阶层的人品。 (10) 这家公司的成本分析和会计记录做得如何？不能做假账，有诚实。 (11) 是不是在所处领域有独到之处？它可以为投资者提供重要线索，以了解此公司相对于竞争者，是不是很突出？ (12) 这家公司有没有短期或长期的盈余展望？ (13) 在可预见的将来，这家公司是否会大量发行股票，获取足够的资金，以利公司发展，现有持股人的利益是否因预期中的成长而大幅受损？ (14) 管理层是不是只向投资人报喜不报忧？诸事顺畅时口沫横飞，有问题或叫人失望的事情发生时，则三缄其口? (15) 这家公司管理层的城市正直态度是否毋容置疑？ 费雪老先生通过自己几十年的总结优良成长股15个要点，还是很全面的，从产品，市场，研发，人力，管理层等方面考察一家公司。但是我们不能教条主义，要活学活用。
要买什么，买有安全边际的成长股，要用闲散的资金投资，不要借钱，控制风险。
何时买进
费雪认为想获得高额的股票报酬，买入股票的时机也是很重要的，他不赞同预测股价上涨或下跌，他认为这是不可预测。 费雪认为买入的公司是能干管理层管理的公司，买入时机应该是这家公司的盈余即将大幅改善，但是盈余增加的展望还没有推升该公司的股票价格。他列举了 推出新产品的美国氰氨公司，复杂的工厂运转的食品机械化工公司。
费雪列出五项影响股价的力量：经济状况、利率趋势、政府对投资和私人企业的整体态度、通货膨胀的趋势、新发明和新技术的影响，他认为最后一项是最强的一股力量。
选择优良的公司，在好消息情况但是还没有提升股价时买入，在一些坏消息的情况下，导致股价快速下戳时买入，这些消息需要投资者辨别一下，买入时要分仓分批买入，股价下跌时分仓买入，降低买入的成本。 现在美国通胀持续升高，美元加息等对美股的科技成长股影响比较大，回调很严重。
何时卖出以及何时不要卖出
费雪总结出三条卖出的原则:
买入股票后发现判断错误，并且这个错误愈发明显，这时候就应该果断清仓。这时候需要坦诚面对自己，放下情绪化和自己自尊心，勇敢承认错误，快速清仓，不要抱幻想，比如等待反弹再买卖出。 公司的经营状况发生了变化，比如管理层能力下降、公司所在的市场成长潜力耗尽等。公司经营状况变化需要投资者辨别。 发现更好的投资机会，也就是调仓。这个需要投资者辨别新机会，有可能判断错误，这时调仓要分批卖出，分批买入。 费雪还讨论一种情况是一支股票在短时间内上涨过快，应该卖出的情况，他认为无法判断股票是否上涨过快，他的观点是选择优质成长股，并报牢，卖出时机永远不会到来。 费雪还讨论两种损失重大的操作：
由于担心大盘可能如何而延后买入值得投资的股票，长期来看是损失惨重的做法。 投资者不应该因为忧虑空头市场来袭，而抛售出色的股票，他说理论上应该是在跌完后再买回，但是这就说明可以知道什么时候低估，但是这个预测不太可能，这种跌后再买回可能性不大，要么是空头市场没有出现，股价一路上涨； 要么是空头来临，股票价格持续下降，下跌到当初买的价格，普通人一般担心还会下跌，没有及时买回来，错过好机会。 费雪讨论的短时间上涨过快是否卖出的情况，应该跟他所处的环境有关系，美国二战后经济持续增长，成长股持续，因此他认为卖出机会永远不会来。这两年新冠疫情，促使了一些科技股尤其是美股科技成长股股价暴增3~4倍， 但是随着高通胀持续飙升，美元加息的情况下，科技股回调很严重，大部分比高点下降50%，甚至下降75%以上，那再疯狂暴增时，应该卖出一部分增长过快的股票，在回调时，可以再以低价买回来， 这样买入更多股数，为了可能带来更多收益，这只是我自己的一些看法。
投资的五不原则
不买处于创业阶段的公司
不要因为一支好股票在"店头市场"交易，就弃之不顾 &ldquo;店头市场"柜台市场又称“店头市场”是在证券交易所之外的某一固定场所，供未上市的证券或不足以成交批量的证券进行交易的市场。该市场因买卖双方多通过电话、电报协商完成交易，故又称之为电话市场。 柜台市场是一个广泛而又复杂的市场，其证券交易量远远超过证券交易所交易量。
不要因为你喜欢某公司年报的“格调”，就去买该公司的股票 不要光看财报，要实地考察
不要以为一公司的本益比高，便表示未来的盈余成长已大致反映在价格上 现在财务数据只能改变过去和现在，不能改变未来
不要锱铢必较 对于好公司，在购买时，不要锱铢必较股价
投资人“另五不”原则
不要过度强调分散投资 费雪认为投资要分散在不同行业，不同类型公司，自己可以搞懂的公司，费雪将投资的公司分为A/B/C三类，A是根基稳固的大型成长股(道氏、杜邦、IBM)，B类是有不错的管理团队，年营业额在1500w~1亿美元 年轻的成功性公司，C类是经营成功，获利可观的小型公司，这些公司成功很快但是有可能血本无归，投资C类公司时“千万不要把赔不起的钱拿去投资”。
不要担心在战争阴影笼罩下买进股票 局部战争可能导致股票出现黄金坑，需要鉴别的抄底
不要忘了你的吉尔伯特和沙利文 两人是讽刺喜剧作家，费雪的意思是不要被股票过去的数据记录所影响，特别是注意不要以为买入那些过往股价没有上涨的股票就是安全的方法。影响股价的主要因素是未来而不是过去。
买进真正优秀的成长股时，除了考虑价格，不要忘了时机因素。
不要随波逐流 股市中需要独立思考
如何找到成长股 费雪认为要在股市中获得高额的回报，自己必须努力勤奋，实地调研考察，再加上一定的能力、判断力和观察力；自己不做研究，从一下研究机构拿到一些研报，不可能选择高回报的股票。 &ldquo;在股票市场，强健的神经系统比聪明的头脑还重要&rdquo;，莎士比亚说"凡人经历狂风巨浪才有财富&rdquo;
保守型投资人夜夜安枕
1）第一要素：生产、行销、研究、财务
生产成本低 强大的行销组织 杰出的研究和技术努力 财务能力 2）人的因素 公司是有一群能干的管理层管理。
公司必须认识到它置身的世界变化的速度越来越快 公司必须持续不断努力，让每个阶层的员工成长 管理层必须已身作则，遵守公司成长所需的戒律 3）若干企业的投资特征 &ldquo;这家公司能做什么事，其他公司没办法做得那么好&rdquo;，这个应该是巴菲特所说的"护城河"
4）保守型投资的价格 安全边际，在低于价值时的价格购买，这得需要会估值，费雪三次讨论这个要素，说明这个很重要
投资哲学
对投资要有浓厚的兴趣 失败中成长 从经验中学习 独立思路，不要人云亦云 要有耐心，三年守则 把少数事情做好，能力圈 在市场下跌是，对选择优质的股票，抱死不放 费雪投资总结
买进的公司，应有按部就班的计划，以使盈余长期大幅成长，而且内在的特质很难让新加入分享那么高的成长 集中全力购买那些失宠的公司，被市场低估的公司 报牢股票知道公司的性质从根本发生改变或公司成长到某个地步后，成长率不会再高于整体水平 淡化股利的影响 学会承受失败，从失败中学习成长 真正出色的公司很少，不能持股太多，10或者12支股票 不盲从当时金融圈的主流意见，增加更多的知识，应用更好的判断力，彻底评估特定的情境，并有勇气坚持自己的判断 必须努力工作，勤奋不懈，诚信正直</content></entry><entry><title>APISIX源码-启动过程</title><url>https://lizj3624.github.io/post/apisix-start/</url><categories><category>apisix</category><category>nginx</category></categories><tags><tag>apisix</tag><tag>nginx</tag></tags><content type="html"> apisix启动命令 APISIX安装之后，开始启动APISIX，APISIX写一套启动命令工具。 执行apisix help可以查看命令详细信息:
$ apisix help /usr/local/openresty/luajit/bin/luajit /usr/local/apisix/apisix/cli/apisix.lua help Usage: apisix [action] &lt;argument> help: show this message, then exit init: initialize the local nginx.conf init_etcd: initialize the data of etcd start: start the apisix server stop: stop the apisix server quit: stop the apisix server gracefully restart: restart the apisix server reload: reload the apisix server version: print the version of apisix 启动源码简析 启动流程 如果OpenResty版本不是1.19，就通过lua启动apisix.lua
源码分析 $ tree -L 2 . ├── apisix │ ├── admin │ ├── api_router.lua │ ├── balancer │ ├── balancer.lua │ ├── cli │ ├── constants.lua │ ├── consumer.lua │ ├── control │ ├── core │ ├── core.lua │ ├── debug.lua │ ├── discovery │ ├── error_handling.lua │ ├── http │ ├── init.lua │ ├── patch.lua │ ├── plugin_config.lua │ ├── plugin.lua │ ├── plugins │ ├── router.lua │ ├── schema_def.lua │ ├── script.lua │ ├── ssl │ ├── ssl.lua │ ├── stream │ ├── timers.lua │ ├── upstream.lua │ ├── utils │ └── wasm.lua ├── bin │ └── apisix ├── CHANGELOG.md ├── CODE_OF_CONDUCT.md ├── CODE_STYLE.md ├── conf │ ├── apisix.yaml │ ├── cert │ ├── config-default.yaml │ ├── config.yaml │ ├── debug.yaml │ ├── mime.types │ └── nginx.conf ├── CONTRIBUTING.md ├── deps │ ├── lib │ └── share ├── LICENSE ├── MAINTAIN.md ├── Makefile ├── NOTICE ├── powered-by.md ├── README.md └── rockspec ├── apisix-2.12.1-0.rockspec └── apisix-master-0.rockspec apisix源码bin/apisix是命令入口，是一个shell脚本，通过lua或luajit启动apisix编写的启动lua脚本，这些lua脚步主要在apisix/cli目录下。 apisix.lua中引用的lua包路径，解析参数，执行相应命令参数的回调函数，启动apisix。命令行中每个参数对应一个回调函数，这些函数在ops.lua中。
... local action = { help = help, version = version, init = init, init_etcd = etcd.init, start = start, stop = stop, quit = quit, restart = restart, reload = reload, test = test, } function _M.execute(env, arg) local cmd_action = arg[1] if not cmd_action then return help() end if not action[cmd_action] then stderr:write("invalid argument: ", cmd_action, "\n") return help() end action[cmd_action](env, arg[2]) end ... 我看一下start函数
local function start(env, ...) ... -- 创建日志目录 local cmd_logs = "mkdir -p " .. env.apisix_home .. "/logs" util.execute_cmd(cmd_logs) -- 检查是否已经启动 -- 解析命令行参数 local parser = argparse() -- 解析用户自定义配置参数 -- 初始化 init(env) -- 初始化etcd init_etcd(env, args) -- 执行启动OpenResty命令 util.execute_cmd(env.openresty_args) end 这个启动函数中最重要的是init(env)初始化函数，这里初始化了apisix启动所有的配置信息，根据配置参数以及模板生成nginx.conf配置。
local function init(env) -- 判断root path， apisix不推荐在root下启动apisix -- 检查 ulimit，建议将ulimit设置大一些 -- 解析conf/*.yaml的配置 local yaml_conf, err = file.read_yaml_conf(env.apisix_home) if not yaml_conf then util.die("failed to read local yaml config of apisix: ", err, "\n") end -- 校验解析yaml是否正确，因为需要根据yaml配置信息，生成nginx.conf，这个配置很重要，因此apisix在这里进行大量的校验 -- 校验成功后，生成nginx.conf配置 local conf_render = template.compile(ngx_tpl) local ngxconf = conf_render(sys_conf) local ok, err = util.write_file(env.apisix_home .. "/conf/nginx.conf", ngxconf) if not ok then util.die("failed to update nginx.conf: ", err, "\n") end end apisix的生成nginx.conf的模板，nginx.conf不能手工修改，应该它 每次启动时会重新生成，apisix也是支持自定义配置的，自定义配置。 看一下渲染生成的nginx.conf配置，我这个没有设置4层(stream)的配置，apisix也是支持4层转发的。
# Configuration File - Nginx Server Configs # This is a read-only file, do not try to modify it. master_process on; worker_processes auto; worker_cpu_affinity auto; # main configuration snippet starts # main configuration snippet ends error_log logs/error.log warn; pid logs/nginx.pid; worker_rlimit_nofile 20480; events { accept_mutex off; worker_connections 10620; } worker_rlimit_core 16G; worker_shutdown_timeout 240s; env APISIX_PROFILE; env PATH; # for searching external plugin runner's binary http { # put extra_lua_path in front of the builtin path # so user can override the source code lua_package_path "$prefix/deps/share/lua/5.1/?.lua;$prefix/deps/share/lua/5.1/?/init.lua;/usr/local/apisix/?.lua;/usr/local/apisix/?/init.lua;;/usr/local/apisix/?.lua;./?.lua;/usr/local/openresty/luajit/share/luajit-2.1.0-beta3/?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua;/usr/local/openresty/luajit/share/lua/5.1/?.lua;/usr/local/openresty/luajit/share/lua/5.1/?/init.lua;"; lua_package_cpath "$prefix/deps/lib64/lua/5.1/?.so;$prefix/deps/lib/lua/5.1/?.so;;./?.so;/usr/local/lib/lua/5.1/?.so;/usr/local/openresty/luajit/lib/lua/5.1/?.so;/usr/local/lib/lua/5.1/loadall.so;"; lua_max_pending_timers 16384; lua_max_running_timers 4096; lua_shared_dict internal-status 10m; lua_shared_dict plugin-limit-req 10m; lua_shared_dict plugin-limit-count 10m; lua_shared_dict prometheus-metrics 10m; lua_shared_dict plugin-limit-conn 10m; lua_shared_dict upstream-healthcheck 10m; lua_shared_dict worker-events 10m; lua_shared_dict lrucache-lock 10m; lua_shared_dict balancer-ewma 10m; lua_shared_dict balancer-ewma-locks 10m; lua_shared_dict balancer-ewma-last-touched-at 10m; lua_shared_dict plugin-limit-count-redis-cluster-slot-lock 1m; lua_shared_dict tracing_buffer 10m; # plugin: skywalking lua_shared_dict plugin-api-breaker 10m; lua_shared_dict etcd-cluster-health-check 10m; # etcd health check # for openid-connect and authz-keycloak plugin lua_shared_dict discovery 1m; # cache for discovery metadata documents # for openid-connect plugin lua_shared_dict jwks 1m; # cache for JWKs lua_shared_dict introspection 10m; # cache for JWT verification results # for authz-keycloak lua_shared_dict access-tokens 1m; # cache for service account access tokens # for ext-plugin lua_shared_dict ext-plugin 1m; # cache for ext-plugin # for custom shared dict # for proxy cache proxy_cache_path /tmp/disk_cache_one levels=1:2 keys_zone=disk_cache_one:50m inactive=1d max_size=1G use_temp_path=off; lua_shared_dict memory_cache 50m; # for proxy cache map $upstream_cache_zone $upstream_cache_zone_info { disk_cache_one /tmp/disk_cache_one,1:2; } lua_ssl_verify_depth 5; ssl_session_timeout 86400; underscores_in_headers on; lua_socket_log_errors off; resolver 10.2.255.200 ipv6=on; resolver_timeout 5; lua_http10_buffering off; lua_regex_match_limit 100000; lua_regex_cache_max_entries 8192; log_format main escape=default '$remote_addr - $remote_user [$time_local] $http_host "$request" $status $body_bytes_sent $request_time "$http_referer" "$http_user_agent" $upstream_addr $upstream_status $upstream_response_time "$upstream_scheme://$upstream_host$upstream_uri"'; uninitialized_variable_warn off; access_log logs/access.log main buffer=16384 flush=3; open_file_cache max=1000 inactive=60; client_max_body_size 0; keepalive_timeout 60s; client_header_timeout 60s; client_body_timeout 60s; send_timeout 10s; variables_hash_max_size 2048; server_tokens off; include mime.types; charset utf-8; # error_page error_page 500 @50x.html; real_ip_header X-Real-IP; real_ip_recursive off; set_real_ip_from 127.0.0.1; set_real_ip_from unix:; # http configuration snippet starts # http configuration snippet ends upstream apisix_backend { server 0.0.0.1; keepalive 320; keepalive_requests 1000; keepalive_timeout 60s; # we put the static configuration above so that we can override it in the Lua code balancer_by_lua_block { apisix.http_balancer_phase() } } apisix_delay_client_max_body_check on; apisix_mirror_on_demand on; init_by_lua_block { require "resty.core" apisix = require("apisix") local dns_resolver = { "10.2.255.200", } local args = { dns_resolver = dns_resolver, } apisix.http_init(args) } init_worker_by_lua_block { apisix.http_init_worker() } exit_worker_by_lua_block { apisix.http_exit_worker() } server { listen 127.0.0.1:9090; access_log off; location / { content_by_lua_block { apisix.http_control() } } location @50x.html { set $from_error_page 'true'; content_by_lua_block { require("apisix.error_handling").handle_500() } } } server { listen 127.0.0.1:9091; access_log off; location / { content_by_lua_block { local prometheus = require("apisix.plugins.prometheus") prometheus.export_metrics() } } location = /apisix/nginx_status { allow 127.0.0.0/24; deny all; stub_status; } } server { listen 0.0.0.0:9080 default_server reuseport; listen [::]:9080 default_server reuseport; listen 0.0.0.0:9443 ssl default_server http2 reuseport; listen [::]:9443 ssl default_server http2 reuseport; server_name _; ssl_certificate cert/ssl_PLACE_HOLDER.crt; ssl_certificate_key cert/ssl_PLACE_HOLDER.key; ssl_session_cache shared:SSL:20m; ssl_session_timeout 10m; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384; ssl_prefer_server_ciphers on; ssl_session_tickets off; # http server configuration snippet starts # http server configuration snippet ends location = /apisix/nginx_status { allow 127.0.0.0/24; deny all; access_log off; stub_status; } location /apisix/admin { set $upstream_scheme 'http'; set $upstream_host $http_host; set $upstream_uri ''; allow 127.0.0.0/24; deny all; content_by_lua_block { apisix.http_admin() } } ssl_certificate_by_lua_block { apisix.http_ssl_phase() } proxy_ssl_name $upstream_host; proxy_ssl_server_name on; location / { set $upstream_mirror_host ''; set $upstream_upgrade ''; set $upstream_connection ''; set $upstream_scheme 'http'; set $upstream_host $http_host; set $upstream_uri ''; set $ctx_ref ''; set $from_error_page ''; # http server location configuration snippet starts # http server location configuration snippet ends access_by_lua_block { apisix.http_access_phase() } proxy_http_version 1.1; proxy_set_header Host $upstream_host; proxy_set_header Upgrade $upstream_upgrade; proxy_set_header Connection $upstream_connection; proxy_set_header X-Real-IP $remote_addr; proxy_pass_header Date; ### the following x-forwarded-* headers is to send to upstream server set $var_x_forwarded_for $remote_addr; set $var_x_forwarded_proto $scheme; set $var_x_forwarded_host $host; set $var_x_forwarded_port $server_port; if ($http_x_forwarded_for != "") { set $var_x_forwarded_for "${http_x_forwarded_for}, ${realip_remote_addr}"; } if ($http_x_forwarded_host != "") { set $var_x_forwarded_host $http_x_forwarded_host; } if ($http_x_forwarded_port != "") { set $var_x_forwarded_port $http_x_forwarded_port; } proxy_set_header X-Forwarded-For $var_x_forwarded_for; proxy_set_header X-Forwarded-Proto $var_x_forwarded_proto; proxy_set_header X-Forwarded-Host $var_x_forwarded_host; proxy_set_header X-Forwarded-Port $var_x_forwarded_port; ### the following configuration is to cache response content from upstream server set $upstream_cache_zone off; set $upstream_cache_key ''; set $upstream_cache_bypass ''; set $upstream_no_cache ''; proxy_cache $upstream_cache_zone; proxy_cache_valid any 10s; proxy_cache_min_uses 1; proxy_cache_methods GET HEAD POST; proxy_cache_lock_timeout 5s; proxy_cache_use_stale off; proxy_cache_key $upstream_cache_key; proxy_no_cache $upstream_no_cache; proxy_cache_bypass $upstream_cache_bypass; proxy_pass $upstream_scheme://apisix_backend$upstream_uri; mirror /proxy_mirror; header_filter_by_lua_block { apisix.http_header_filter_phase() } body_filter_by_lua_block { apisix.http_body_filter_phase() } log_by_lua_block { apisix.http_log_phase() } } location @grpc_pass { access_by_lua_block { apisix.grpc_access_phase() } grpc_set_header Content-Type application/grpc; grpc_socket_keepalive on; grpc_pass $upstream_scheme://apisix_backend; header_filter_by_lua_block { apisix.http_header_filter_phase() } body_filter_by_lua_block { apisix.http_body_filter_phase() } log_by_lua_block { apisix.http_log_phase() } } location = /proxy_mirror { internal; proxy_http_version 1.1; proxy_set_header Host $upstream_host; proxy_pass $upstream_mirror_host$request_uri; } location @50x.html { set $from_error_page 'true'; content_by_lua_block { require("apisix.error_handling").handle_500() } header_filter_by_lua_block { apisix.http_header_filter_phase() } log_by_lua_block { apisix.http_log_phase() } } } # http end configuration snippet starts # http end configuration snippet ends } 根据模板生成的nginx.conf监听的9080和9443端口，IP则是0.0.0.0和[::]这是特殊IP，允许所有IP的请求进入
/apisix/admin的location主要是处理控制面的接口。
在OpenResty的init阶段嵌入apisix.http_init(args)
init_by_lua_block { require "resty.core" apisix = require("apisix") local dns_resolver = { "10.2.255.200", } local args = { dns_resolver = dns_resolver, } apisix.http_init(args) } 在init_worker阶段嵌入apisix.http_init_worker()
在exit_worker阶段嵌入apisix.http_exit_worker()
在ssl_handshake阶段嵌入apisix.http_ssl_phase()
在access阶段嵌入apisix.http_access_phase()，apisix没有设置rewrite阶段，匹配路由，挑选server
在content阶段，设置上游server，apisix主要通过apisix.http_balancer_phase()实现的。
upstream apisix_backend { server 0.0.0.1; keepalive 320; keepalive_requests 1000; keepalive_timeout 60s; # we put the static configuration above so that we can override it in the Lua code balancer_by_lua_block { apisix.http_balancer_phase() } } 在header_filter阶段嵌入apisix.http_header_filter_phase()
在body_filter阶段嵌入apisix.http_body_filter_phase()
在log阶段嵌入apisix.http_log_phase()
到这里apisix启动流程介绍完了，启动过程主要是初始化数据以及etcd，生成nginx.conf配置，apisix大部分的代码逻辑都嵌入到OpenResty处理请求的各个阶段， 后面再分析一个请求在apisix的处理过程、etcd数据同步过程和apisix的控制面。
引用 APISIX源码分析</content></entry><entry><title>腾讯2021Q4以及全年财报</title><url>https://lizj3624.github.io/post/tencent-2021q4-fy/</url><categories><category>腾讯</category><category>财报</category></categories><tags><tag>腾讯</tag><tag>财报</tag></tags><content type="html"> Q4财报 总收入同比增长8%，Non-GAAP下股东盈利同比下降25%。
总收入为人民币1441.88亿元(226.15亿美元)，同比增长8%。
Non-GAAP财务
经营盈利为人民币331.51亿元(52.00亿美元)，同比下降13%；经营利润率由去年同期的28%下降到23%。 期内盈利为人民币257.58亿元(40.40 亿美元)，同比下降25%；净利润率由去年同期的26%下降到18%。 每股基本盈利为人民币2.609元，每股摊薄盈利为人民币2.547元。 核心业务营收和盈利都在下降
GAAP财务 经营盈利为人民币1097.23亿元(172.10亿美元)，同比增长72%; 经营利润率由去年同期的48%上升至76%。 期内盈利为人民币957.05亿元(150.11亿美元)，同比增长61%; 净利润率由去年同期的44%上升至66%。 期内本公司权益持有人应占盈利为人民币949.58亿元(148.94亿美元)，同比增长60%。 每股基本盈利为人民币9.957元。每股摊薄盈利为人民币9.788元。 期末总现金为人民币2812.86亿元(441.18亿美元)。
收入明细
增值服务收入719亿，同比增长7%；其中本土游戏收入296亿，同比增长1%，国际游戏收入132亿，同比增长34%，社交网络收入291亿，同比增长4%. 网络广告收入215亿，同比下降13%，其中社交广告183亿，同比下降10%，媒体广告32亿，同比下降25%。 金融科技及企业服务收入480亿，同比增长25%。 Q4腾讯游戏业务个位数增长，网络广告下降13%，金融科技及企业服务(主要是腾讯云)表现亮眼，25%的增长。
全年财报 总收入: 同比增长8%，Non-GAAP下股东盈利同比增长1%。
总收入为人民币5601.18亿元(878.52亿美元)，同比增长16%。
Non-GAAP下核心业务表现
经营盈利为人民币1595.39亿元(250.23亿美元)，增长7%; 经营利润率由去年的31%下降至28%。 年度盈利为人民币1279.19亿元(200.64 亿美元)，增长1%; 净利润率由去年的26%下降至23%。 年度本公司权益持有人应占盈利为人民币1237.88亿元(194.16亿美元)，增长1%。 每股基本盈利为人民币12.992元，每股摊薄盈利为人民币12.698 元。 GAAP下表现 经营盈利为人民币2716.20亿元(426.02亿美元)，增长47%; 经营利润率由去年的38%上升至48%。 年度盈利为人民币2278.10亿元(357.31 亿美元)，增长42%; 净利润率由去年的33%上升至41%。 年度本公司权益持有人应占盈利为人民币2248.22亿元(352.62亿美元)，增长41%。 每股基本盈利为人民币23.597元。每股摊薄盈利为人民币23.164元。</content></entry><entry><title>美团2021Q4及全年财报</title><url>https://lizj3624.github.io/post/meituan-2021q4-fy/</url><categories><category>拼多多</category><category>美团</category></categories><tags><tag>美团</tag><tag>财报</tag></tags><content type="html"> 2021Q4财报 Q4营收495.23亿，同比增长30.6%；经营亏损50.05亿，同比增加75.5%；期内亏损53.39亿，同比增长137.9%。经调整的EBITDA 亏20.09亿，同比增加241.1%；经调整亏损净额39.35亿，同比增加174%。
营收明细
单位：亿人民币)
餐饮外卖营收261.26亿，同比增长21.3%，成本243.91亿，同比增长18.1%，盈利17.35亿，同步增长96.7%，在疫情和政策收紧的情况下，外卖同比大涨，难得可贵。
到店、酒店以旅游营收87.22亿，同比增长22.2%，成本48.25亿，同比增长11.9%，盈利38.97亿，同比增长38.1%。这块占营收17%，但是盈利的主要来源。
新业务营收146.74亿，同比增长58.7%，成本248.79亿，同步增长63.2%，亏损102.05亿。
在美团营收中餐饮外卖收入占比53%，是营收的大头；到店、酒店及旅游收入占比17%，是盈利的大头；前两个业务已经实现的盈利；新业务收入占比30%，目前亏损大头，拉低美团的盈利，导致亏损。美团新业务包含美团优选，美团闪购，美团买菜业务。
2021全年财报 全年营收1791.27亿，同比增长56%；经营亏损231.27亿，同期盈利43.3亿；年内亏损235.36亿，同期盈利47.07亿；经调整EBITDA亏损96.94亿，同期盈利47.37亿；经调整亏损155.71亿，同期盈利31.2亿。
全年营收明细
单位：亿人民币
全年中餐饮外卖营收963.11亿，同比增长45.3%；成本901.37亿，同步增长42.1%，盈利61.74亿，同比增长117.9%；
到店、酒店以旅游营收325.3亿，同比增长53.1%；成本184.37亿，同比增长41%；盈利140.93亿，同比增长72.3%。
新业务及其他营收502.85亿，同比增长84.4%；成本886.79亿，同步增长132.6%；亏损383.83亿，同比增长253.7%。
全年由于新业务的投入导致亏损。
2021年运营数据 年交易用户数：6.905亿，同步增长35.2%；年活动商家880w，同步增长29.2%；每交易用户平均每年交易数35.8，同比增长27.2%。
Q4餐饮外卖金额1886.206亿，同步增长20.7%；Q4餐饮外卖交易笔数39.106亿，同步增长17.4%；国内酒店间夜量1.153亿，同比下滑3.7%。
全年餐饮外卖金额7020.574亿，同步增长43.6%；Q4餐饮外卖交易笔数143.676亿，同步增长41.6%；国内酒店间夜量4.769亿，同比增长34.5%。
三大业务运营明细
餐饮外卖Q4交易金额1886.206亿，同步增长20.7%；日均订单4250w，同比增长17.4%，经营利润率由4.1%提升至6.6%。全年利润率由4.3%增至6.4%，8月份单日峰值5000w。
到店、酒店以旅游全年盈利141，年利润率由38.5%提升至43.3%。
新业务全年营收同比增加84.4%，亏损383.8亿，同比亏损扩大36.6%；美团优选搭建次日提货的三级仓配物流体系，现已覆盖30个省份的大部分社区和农村；美团闪送12月单日峰值630w，鲜花、超时以及便利店保持高速势头，1月份开启24小时送药服务，零售的终局是"万物到家"；美团买菜完成了四个一线的覆盖。</content></entry><entry><title>费雪《怎样选择成长股》精华版</title><url>https://lizj3624.github.io/post/fisher-common-stocks-and-uncommon-profits/</url><categories><category>费雪</category><category>投资</category></categories><tags><tag>费雪</tag><tag>投资</tag></tags><content type="html"> 中概股从去年2月份一直下跌，2022.3月份美元加息以及俄乌冲突，还有不及预期的中概股财报等诱因下， 从3.2号开始中概股暴跌，持续到14号，短短两周京东跌幅达44%，阿里跌幅达27%，拼多多达53%， 让支持中概股的人很恐慌(本人持有京东美股)，这时候向我这样的普通个人投资者应该怎么办？ 我选的股票是错了吗？带着这些疑问正在看费雪《怎样选择成长股》，碰巧在雪球看到雪友 写的‘费雪《怎样选择成长股》精华版’，感觉总结非常不错，在自己小站里记录一下，以便自己经常翻阅。 原文
1、投资最重要的原则 费雪通过研究自己和他人的长期投资记录后认为，投资想赚大钱，必须有耐性。换句话说，预测股价会达到什么水准，往往比预测多久才会达到那种水准容易。而另一件重要的事就是股票市场本质上具有欺骗投资人的特性，跟随其他每个人当时在做的事去做，或者自己内心不可抗拒的呐喊去做，事后往往证明是错的。
2、投资赚钱的逻辑 费雪认为，买股票的最终目的是为了利润。因此，投资者应该回顾一下股票市场史，看看人们累计财富的方法。费雪指出：有一种人，即便在早年，找到真正杰出的公司，抱牢它们的股票，度过市场的波动起伏，不为所动，也远比买低卖高的做法赚得多。因此，大部分投资人终其一生，依靠有限的几支股票，长时间的持有，就为自己或子女奠下成为巨富的基础。这些机会不见得必须在大恐慌底部的某一天买股票。这些公司股价年复一年都能让人赚到很高的利润，投资者需要的能力是能区辩提供绝佳投资机会的少数公司。
3、股票长期投资收益优于债券 费雪指出，在1946年-1956年的10年间，全球货币贬值情况非常严重，其中美元贬值了29%，每年的贬值率是3.4%。即便在利率较高的1957年，投资者购买公债长期看都仍是亏损的。通货膨胀大幅攀升源于总体信用扩增，而此事又是政府庞大的赤字使得信用体系的货币供给大增造成的。因此，正常经济周期下，企业营运保持不错，股票表现优于债券。如果是经济严重衰退，债券表现也许短期优于股票，但接下来政府大幅制造赤字的行动，必将导致债券投资真正的购买力再度大跌。经济萧条几乎肯定会制造另一次通货膨胀的急升，这样的情况下，股票的吸引力又会超过债券。所以，综合长期来看，股票投资仍是最佳的选择。
4、&ldquo;幸运且能干"和"能干所以幸运&rdquo; 费雪认为分析一家成长型企业，不应拿某一年的经营业绩进行评价，因为即使最出色的成长型公司，也不能期望每年的营业额都高于前一年。因此应以好几年为单位判断公司营业额有无成长。而这些优秀的成长企业有两个特征：&ldquo;幸运且能干"和"能干所以幸运&rdquo;。两者都要求管理层很能干。个人理解，后者类型的企业更令人心仪：即处在不利的行业竞争发展格局之中，但仍能保持出色的竞争优势，并转化为超越行业的业绩增长。
5、利润率和边际公司 费雪认为利润率是分析公司的好指标，而边际公司就是利润率低下的公司。投资者不应该只考虑经济景气下的利润率，因为经济向好时，边际公司利润率的成长幅度远高于成本较低的公司，后者的利润率也在提升，但幅度并不会太大。因此，年景好时，体质疲弱的公司盈余成长率往往高于同行中体质强健者，但也必须记住，一旦年景不好，边际公司的盈余也会急剧下降。
费雪的这些观点在现代看来，似乎不足以反映真实现状。例如零售业的利润率（净利润率）是非常低的，但很多优秀的零售企业却往往是绝佳的投资对象。利润率低于对手，但却保持强大竞争力的企业，能够通过薄利多销或提供优质低价的产品争取消费者。
6、管理层是否报喜不报忧 费雪认为，即使是经营管理最好的公司，有时也会出乎意外碰到困难。最成功的企业，也无法避免这种叫人失望的事情。坦诚面对，加上良好的判断力，会知道它们只是最后成功的代价之一，这往往是公司强势的迹象，而非弱势的特征。
而管理层面对这些事情的态度，是投资人十分宝贵的线索。那种遇到好事侃侃而谈，遇到难题则三缄其口的公司领导层，投资者应该回避。
7、选择大公司还是成长型小企业 费雪认为，相对于大公司，规模较小的公司股价更容易上涨。因为市值规模小，盈余的增长会更快的反应到股价当中，因此十年内可以上涨数十倍。但费雪提醒投资者：投资这样的小型成长股，技巧娴熟的人都难免偶尔犯错。而要是投资这样的普通股犯错，丢出去的每一块钱可能就消失了。因此，投资者应该选择那种历史悠久、根基较稳固的成长型股票。
而年轻高风险公司由于自身不断发展成熟，可能进步到机构投资者开始购买的地步，投资者这个时候倒可以投资这样的公司。这种公司未来增值的潜力不似以往那么大了，但仍能取得较好的回报。
8、买进成长股的时机 费雪并不主张投资者一定要在市场崩溃后寻找买入时机，他认为在1929年股市崩溃后的两年内有勇气买入并持有几支股票的投资者收益率固然可观，但在50年代以合理的价格买入成长股的投资者也获得了惊人的回报。
他坚决反对投资者去预测所谓经济景气高点和低点，以作为买入或卖出的根据。他辛辣讽刺说，如果投资者有耐心查询下每年在商业周刊上刊登的经济学家对未来的预测就会发现，他们成功的概率极低。经济学家们花费在经济预测上的时间如果拿去思考如何提升生产力可能对人类的贡献更大。
几乎所有投资大师，都对依赖经济景气预测作为投资判断的观点嗤之以鼻。彼得林奇说：美国有6万名经济学家，却没有一个人预测到1987年的股市灾难。巴菲特也说华尔街的经济学家都睡大觉，可能是投资者的好消息。
这一点应该是可以验证的，在2007年中国经济景气高点时，几乎没有经济学家对未来抱有悲观观点，狂热乐观的倒是太多。
费雪主张投资者应选择在非常能干的管理层领导下的公司，他们偶尔也会遭遇到始料不及的问题，之后才能否极泰来。投资者应该知晓这些问题都属于暂时性质，不会永远存在。如果这些问题引发股价重挫，但可望在几个月内解决问题，而不是拖上好几年，那么此时买入股票可能相当安全。
但这并不代表投资者完全不理会经济萧条带来的问题。但诸如1929年那样的投机极度炙热导致的股价崩盘和后续经济大萧条外，投资者并不应该对股价的大幅下跌感到惊慌失措。当确定某家公司值得投资，放手去投资就是，因为推测产生的恐惧或者希望不应该令投资者却步。
9、卖出以及何时卖出 费雪认为，卖出股票的三个理由：①、当初买进行为犯下错误，某特定公司的实际状况显著不如原先设想那么美好。在某种程度上，要看投资者能否坦诚面对自己。②、当成长股成长潜力消耗殆尽，股票与持有原则严重脱节时，就应该卖出。③、有更加前景远大的成长股可以选择。
费雪认为投资者不应该因为空头市场的担忧而卖出股票（恐惧熊市的到来）。他认为这样做无异于要求投资者知道空头市场何时出现，以及何时结束（在空头市场底部买回股票）。但通常情况是投资者卖出后，空头市场并未出现，市场继续上扬。等到空头市场真的来临时，却从来没有见过比卖出价格更低的位置买回相同股票的投资者。通常的情况是，股价并没有跌回卖出价，但投资者仍苦苦等待，或者股价真的一路下挫跌过卖出价，他们却又忧虑别的事情而不敢买回。
费雪提醒： 投资者不应该因为手上的股票涨幅过大就卖出股票。因为，&ldquo;涨幅过大&rdquo;、&ldquo;估值过高&rdquo;，都是非常模糊的概念。没有证据表明多高的估值或者涨幅才是最高。
他进而推论出这个观点： 如果当初买进普通股时，事情做得很正确，则卖出时机是——几乎永远不会到来。
当然，阅读费雪的此书，必须考虑到所处的美国50年代，正是美国国力蒸蒸日上成为全球霸主的时期。美国股市经过长期的萎靡（1932年-1947年）正好处于恢复上升周期，百业兴旺。而今的美国已经大不如昔了。例如如果你上市就买入花旗银行，并长期持有至今，收益率非常可怜，远远低于通货膨胀。尽管花旗银行长期被认为是美国繁荣的标志，是全球银行业的冠军。
10、投资者的"五不原则" 原则一：不买处于创业阶段的公司。
费雪认为创业阶段的公司，投资者只能看到它的运作蓝图，并猜测它可能出现什么问题或可能拥有什么优点，这事做起来困难的多，做出错误结论的几率也高出很多。投资者应该坚守原则，绝不买进创业阶段的公司，不管它看起来多有魅力。而老公司里面多的是绝佳投资机会。
原则二：不要因为一支好股票在"店头市场"交易就弃之不顾。
原则三：不要因为你喜欢某公司年报的"格调"就去买该公司股票。
原则四：不要以为一公司的本益比高，便表示未来的盈余成长已大致反映在价格上。
费雪认为，真正优秀的成长企业能不断开发新的盈利来源，而且所处行业具有相近的成长动力，那5-10年后的本益比肯定高于一般普通股票。这种股票的本益比(PE)反映未来的程度，往往远低于许多投资者所相信的。
当然，费雪和格雷厄姆相比，在逻辑和推理上是显得不足的，费雪更加相信自己选择优秀成长企业的能力，而格雷厄姆怀疑任何人具有对未来预测的能力，并且对任何高出平均水平的价格敬而远之。两者各有侧重，只有后面巴菲特集两者长处于一体后，才取得了两人所远不能及的惊人成就。但归根到底，巴菲特是以格雷厄姆安全边际理论为根基的，费雪的成长股长期投资理论开阔了他的眼界（还有查理芒格的协助）。
原则五：不要锱铢必较。（彼得.林奇也提过这个教训）
费雪是指投资者不必为了中意股票的些许价格差异而错过了投资时机。
11、投资者的"另五不原则" 原则一：不要过度强调分散投资
费雪认为，投资者如果过分强调分散投资，那么将可能对手中持有的大量股票无暇顾及，最终效果反而不好。费雪将公司类型分为三类，A类公司是历史悠久、根基稳固的大公司，B类公司是刚刚步入成熟的公司，c类则是中小型公司，如果经营成功则获利丰厚，但一旦失败则血本无归。投资者应该在ABC三类公司中进行分散投资，并且注意不要在同一行业类过度集中。而投资者对于C类公司，必须注意千万不要把赔不起的钱拿去投资。另一个极端就是过分集中，但投资者必须警惕，任何人都可能犯错，而且有可能一蹶不振。因此，分散的原则就是投资者对自己的投资清单的公司，具有时刻把握的能力。
原则二：不要担心在战争阴影笼罩下买进股票
费雪认为，20世纪发生了10次大的战争，每一次都是在战争正式爆发前股市下跌，但一旦战争爆发，则股市开始走稳，战争结束后即开始狂飙。究其原因，就是战争使得政府巨额开支，从而摊薄了货币的购买力，也就是导致通货膨胀。因此，在战争爆发后持有现金是最不明智的做法。正确的做法是在战争爆发前小心的逐步购买，战争爆发后马上加快购买速度。而如果战争导致本国失败，那本国的货币也将变得一文不值，而投资者不管是持有股票，还是抱有现金，结果都一样。
原则三：不要忘了你的吉尔伯托和沙利文（两人是讽刺喜剧作家，费雪的意思是不要被股票过去的数据记录所影响，特别是注意不要以为买入那些过往股价没有上涨的股票就是安全的方法。影响股价的主要因素是未来而不是过去）
原则四：买进真正优秀的成长股时，除了考虑价格，不要忘了时机因素。
费雪认为，很多投资者期待在某个价位买入成长股股票，但时机较难掌握。因此，有一种投资路径可以参考：就是不在特定的价格购买，而是在特定的时期买进。
这就是所谓"定投"的投资策略，而个人认为，在经过认真谨慎分析后的估值安全区间以下，是可以进行定期定额投资的。特别是在一些比较极端萧条的时期。
原则五：不要随波逐流
费雪认为金融圈在不同的时间，对相同事实的评估方式大异其趣的现象，绝不限于整体股市，也存在于某些特定行业和这些行业中的个别公司。金融圈的喜恶不断变动，原因往往出在时移势转，相同的事实却有不一样的解读方式。
他举例1950年的制药股普遍认为和工业化学一样，卓越的研究成果带来无止尽的成长潜力，加上生活水准稳定提高，因此制药股本益比和最好的化学工业股一样高。但后来不久，某家制药商以前销售很好的产品出了问题，金融圈马上闻风色变，重新评估该行业，并且只愿意给予较低的本益比水平。但到了1958年，经济不景气下，制药股的业绩表现出色，金融圈马上又重新充满了憧憬，从而大幅提升了本益比。
费雪认为，聪明的投资者如能独立思考，在绝大部分人的意见偏向另一边时，提出自己的正确答案，将获益匪浅。初出茅庐的投资者应该首先练习的最简单方法，就是千万不要随波逐流，人云亦云。
12、费雪谈耐心和自律精神 费雪认为，知道投资的准则和了解常犯的错误，并不能帮助那些没有什么耐心和自律精神的人。他说：&ldquo;我认识一位能力非常强的投资专家，几年前告诉我：在股票市场，强健的神经系统比聪明的头脑还重要。&rdquo;
莎士比亚可能无意中总结了投资成功的历程： &ldquo;凡人经历狂风巨浪才有财富。&rdquo;
13、寻找具有"竞争壁垒"的企业 费雪指出，投资者应该寻找那些成本同比行业更低，但利润率却高于同行的企业。这些公司并不只依靠技术开发和规模经济两个层面。还要依靠，首先是公司必须在其提供的产品（或服务）品质和可靠性上建立起声誉。客户更换公司，节省的成本并不太多，但找到不知名供应商的风险更大。其次，公司必须有某种产品（或服务），提供给许多小客户，而不只是卖给少数大客户。以至于它的竞争对手，必须去争取众多的客户，才有可能取代这家公司的地位。
这样的企业，具有高于平均水平的利润率，或投资回报率。但不必——实际上不应该高出业界平均水平好几倍。实际上利润或回报率太高，反而可能成为危险之源，引来众多竞争对手一争长短。
也就是说，公司具有特殊的性质，具有某些内在经济因素，使得高于平均水平的利润率并不是短期现象。投资者可以问问自己：这家公司能做些什么事，而其他公司却没办法做得那么好？
费雪这些观点，无疑是与巴菲特口中所说的特许经营权（或林奇口中的利基）相一致的。巴菲特投资的企业，大多维持了较高的股东权益回报率，且长达几十年的时间保持住了这样高效的回报。他投资的企业ROE最低也超过15%。例如可口可乐曾维持50%的ROE水平。
费雪的观点提炼出来就是： 具有竞争壁垒的公司能以低于业界水平的价格供给（或服务）广大普通客户，广大客户信赖公司和公司产品服务，他们更换公司产品的代价更高，意愿更低。低成本和高效率运作保证了公司长时间能维持略高出业界水平的利润率。
个人认为费雪和认识和巴菲特的实践是一致的，巴菲特选择的企业，其产品和服务都是面向普通百姓的，与他们的生活息息相关。长期的品牌塑造和公众对其产品服务的信赖，使得更换显得概率极低。他们的产品并不是高高在上的，而是较低价格出售，满足普通公众日常的生活需要。例如食品饮料：箭牌口香糖、可口可乐饮料、宝洁的洗发水、吉列的剃须刀、盖克的汽车保险、富国银行的零售服务、甚至于中石油的加油业务。巴菲特几乎很少投资那种客户集中化的企业。
以前曾思考过例如中兴通讯、大族激光等企业，都是很优秀的制造业或科技企业。但他们的特点都是客户比较集中，这给分析带来很大的困难：例如中兴通讯如果拿不到联通的设备提供合同，那就是灾难性的后果。而他们的竞争对手，如果拿下某一个大的客户合同，都会给予其沉重的打击。这让长期投资者的判断充满了不确定性。
14、市盈率的主观性与投资的机会选择 费雪认为，市盈率是金融圈最容易主观判断的指标，他认为，任何个别普通股相对于整体股市，价格大幅的波动，都是因为金融圈对那支股票的评价发生了变化。我理解应该不是绝对，但的确很多时候，公司经营并没有太大波动，股价的大幅波动只是大家的看法或者情绪发生了变化。格雷厄姆谈及这一点时说过，市场先生有时候喜怒无常，投资者应该善用这一点，而不是被其利用。
费雪认为，有三种情况，第一种是市场不看好公司，因此市盈率（本益比）较低。投资者应该谨慎审视，寻找公司前景与市场看法错位的投资机会，他认为这也许是绝佳的投资机会。第二种是市场暂时比较看好公司，而该公司前景的确很美好，那么投资者应该继续持有高估的股票，容忍后面短暂的大幅下挫。第三种是市场非常看好公司，而公司前景却与市场普遍看法相左。投资者应该极度警惕这样的情况。
费雪认为，投资者在分析企业前景和选择投资时机时，应该认真分析市场当前对于该公司的看法。观察这样的看法是否比公司实际基本面有利或者不利。这样才能确定属于前面三种情况哪一种。
费雪另一层含义是：如果市场非常不看好该公司，而投资者有确切证据和研究分析指出公司未来基本面情况比市场悲观的观点更好，那此时就是绝佳的投资成长股的机会。实际上，格雷厄姆口中的"安全边际"，也只能在此时得到充分的验证：市场普遍看好时，难以寻找到所谓的"安全边际"。而巴菲特长期持有股票的另一层含义是：美国仅仅只有在1974-1976年才拥有极其便宜的估值：大约6倍市盈率水平。（上一次要退到1947年，那个时候巴菲特还没有开始投资生涯）难怪巴菲特，在1974年撰稿说：这是投资者唯一能以格雷厄姆式的价格，买到费雪般的优秀股票。按照纽伯格的观点，美国股市自1974年开始-1997年（实际上到了2000年）走了长达23年的长期牛市，而之前，在1937年开始的恢复性牛市一直持续到了1973年，中间夹杂熊市，但规模都很小。1974年的大熊市，指数下跌不到50%，但主要是道琼斯指数覆盖较低。当时主要蓝筹股普遍从最高点下跌了7成。
15、费雪谈"锚定定理" 费雪描述了类似今天所谓的"锚定定理"。即： 市场总是容易将一个长时期维持的股价认为是那支股票的"真实价值"，并且根深蒂固，习以为常。一旦跌破或者突破该价位，市场各类投资人就会蜂拥而出。而这样的力量，是投资领域最危险也是最微妙的。连最老练的投资者都必须时时防范。
市场的观点有时候会错的离谱，但几乎绝大多数人都陷入其中无法自拔。例如1927年市场开始的对新纪元的强烈憧憬，连续多年（实际上长达10年的经济繁荣期）美国大部分企业盈利不断上升，经济萧条早已成为记忆中的遥远历史（1910年曾发生过）。有怀疑意见的投资者，都在后面不断攀升的涨幅中消失匿迹。最终事实证明市场荒谬憧憬的时候，已经是两年之后了。
而到了1946-1949年时，市场正好转了个面。大部分美国公司盈利强劲增长，股票市盈率降到前所未有的低位。但当时的市场人士普遍认为，这些盈利增长都是暂时的现象，而随之到来的经济大萧条，必将摧毁这些盈利。等到市场最终看不到大萧条的发生后，美国历史上最久的牛市才逐步展开（持续了20年）。而1972-1974年的市场，和当年一样，又在空头市场笼罩下（费雪写此文的时间——1974年，也是该书后续修订版本），股票市盈率出现了和1946-1949年那样的极低水平，这是这个世纪以来，美国股市仅有的两次记录。费雪不仅惊奇：市场这样的评价合理吗？
回头看费雪，当真是目光如炬。1946-1949年巴菲特并没有遇到，但在1974年这个美国股市估值水平达到历史最低水平时，费雪和巴菲特几乎发出了同样的声音。我们后来看，可以理解巴菲特在1974年高呼的：我回来了。以及他当时想踢着踢踏舞上班时的愉悦心情。
但在当时的1974年-1980年，投资者有一万个理由看空股市：首先是第一次和第二次石油危机，特别是1979的伊朗事件导致的第二次石油危机重创美国，1978年三大汽车公司巨亏10亿美元（看起来很眼熟），房地产开工不足，年度建房到1981年仅有1972年的一半不到。钢铁行业处境艰难。1971年首次成为债务国。这段时间美国财长被换了6位。股市指数跌了49%，大多数绩优股跌了60%-70%。中东战争不断，美国等西方国家和伊朗等阿拉伯国家严重对峙。美国利率不断攀升：到1980年美国银行优惠利率居然达到20%！（美国人说的是耶稣诞生以来最高的利率——当然，也有一些人投资当时的美国国债发了大财）1977年美国通胀率达到9%，美元几年贬值了25%，失业率上升到8%。我现在也想不到任何在利率高达16%的时代，投资股票还有什么太大意义：华尔街有统计数据历史的投资大师们，超过20年投资真实记录的大师中，仅有两位大师的年均复合增长率超过21%！一位是巴菲特，一位是巴菲特的老师格雷厄姆（20年年复利达到21%）。另外，成长股投资大师麦克.普莱斯在21年中取得20.4%的成绩。约翰.聂夫也非常厉害，在31年中年均投资复利达到13.7%（这个成绩仍远远低于巴菲特的超级记录）。当你买进即便13%的美国长期国债，实际上就已经超越了美国历史上投资总成绩排名第三的投资大师。香港的著名分析师和投资者林森池，就是依靠这个东西赚到了大钱。
实践证明了，股市总是会回归到平均值水平，不管经济看起来多么美好，或者是多么糟糕。这也许解释了为什么经济学家投资普遍比较失败的原因。
16、投资哲学的起源和形成 费雪认为，没有一种投资哲学能在一天或一年发展完全，除非抄袭别人的方法。其中，一部分可能来自所谓合乎逻辑的推理，一部分来自观察别人的成败。但大部分来自比较痛苦的方法：就是从自己的错误中学习。其中，当费雪第一次进入华尔街的时候，几乎就犯下了巨大的错误：他在1929年经不起诱惑，买入了一些他认为较为合理的股票。尽管1929年6月费雪就曾经发表过预测市场将在6个月内面临巨大下跌风险的警示报告。（也充分说明：投资知易行难的道理，说着容易，但实践更难一百倍，口头或笔头的投资大师很多）。
17、费雪谈逆向投资 费雪认为，光有反向意见还不够，背离一般投资思想潮流时，你必须非常肯定你自己是对的。有时候背离潮流投资者也会输的很惨。但如果有强烈迹象，显示自己转对方向时，往往获得庞大的利润。
18、费雪谈耐心和绩效 费雪指出，买进某样东西时，不要以一个月或一年期作为评估成果，必须容许有三年时间。但每一个原则也都有例外的时候，这就是说，投资者既要坚守某些原则，但又不能失去其灵活性，这需要对自己真诚坦然。
19、费雪谈长期持有 费雪认为，只要认定公司未来仍能成长，并值得投资，那么就不应该在多头获利的市场卖出股票。他说：我宁可抱牢这些股票不放，因为增值潜力雄厚的公司很难找，如能了解和运用良好的基本原则，相信真正出色的公司和平凡的公司一定会有差异，而且准确度可能高达90%。
相反，预测股票未来6个月的表现，则困难的多。股票短期走势和短期的经济环境、行业情况、公司短期业绩，还有华尔街对公司的看法，以及众多投资者心理变化等等有关。这样的分析预测成功概率不可能超过60%，这还是很乐观的预计。
因此，短期价格波动本质上难以捉摸，不可预测，因此抢进抢出的游戏，不可能像长期抱牢正确股票那样，一再获得长期利润。（这个观点一般不会被中国众多交易者认同）
20、费雪的八大核心投资哲学 1、买进的公司，应该是那种有竞争壁垒（特许经营权）的公司。
2、集中全力买进那些失宠的公司：也就是说，由于整体市况或当时市场误判一家公司的真正价值，使得股价远低于真正价值时，则应该断然买进。
3、抱牢股票，直到：a、公司性质发生根本变化；b、公司成长到不再能够高于整体经济。除了两个因素外，除非有非常确凿的证据，否则绝不轻易卖出。
4、投资者对股利不应持有太高的兴趣，那些发放股利比例最高的公司中，难以找到理想的投资对象。
5、要明白，投资者犯下错误是不可避免的成本。重要的是尽快承认错误，并了解和从中吸取教训。要养成好的投资习惯，不要只是为了实现获利就获利了结。
6、真正出色的公司，数量相当少，往往也难以以低廉价格买到。因此，在某些特殊的时期，当有利的价格出现时，应充分掌握时机，资金集中在最有利的机会上。买入那些创业或小型公司，必须小心的进行分散化投资。花费数年时间，慢慢集中投资在少数几家公司上。
7、对持有的股票要进行卓越的管理：基本要素是不盲从当时金融圈的主流意见，也不会只是为了反其道而行，便排斥当时主流的观点。相反，投资者应该拥有更多的知识，应用更好的判断力，彻底判定当时情形，并有勇气，在你的判断结果告诉你，你是对的时候，学会坚持。
8、投资和人类其他大部分工作一样，想要成功，必须努力工作、勤奋不懈、诚实正直。
最终，费雪认为，投资也难免需要些运气，但长期而言，好运和坏运会相互抵消掉。想要持续成功，必须依靠技能和继续运用良好的原则。相信，未来主要属于那些能够自律且肯付出心血的人</content></entry><entry><title>拼多多2021Q4及全年财报</title><url>https://lizj3624.github.io/post/pdd-2021q4/</url><categories><category>拼多多</category><category>财报</category></categories><tags><tag>拼多多</tag><tag>财报</tag></tags><content type="html"> 3.21号拼多多发布2021年Q4以及全年财报，简单看一下财报数据，帮助理解拼多多这家公司，单位：人民币
Q4财报 亮点 全年GMV：2.441万亿，同比增长46%。 Q4总收入：272.309亿，同比增长3%。 月活用户：7.334亿，同比增长2%。 年活动买家：8.687亿，同比增长10%。 单用户年度消费额：2810，同比增长33%。 Q4财务数据 Q4总收入：272.309亿，同比增长3% 广告收入: 224.25亿, 同比增长19%。 交易佣金收入：47.242亿, 同比增长108%。 商品销售收入：0.817亿, 同比减少98%。 拼多多的商品销售只是对用户需求的补充，不是拼多多的重点，这块比重会慢慢减少。
收入成本：65.155亿，同比减少43%。
运营支出：138.084亿，同比减少23%，其中市场营销费：113.658亿，同比减少23%。
减少补贴，营销费大幅度下降
运营利润：69.07亿，归属股东的净利润：66.195亿。Non-GAAP下：84.444亿。 Q4的收入、月活都是个位增长，通过降低营销费实现净利润。
全年财报 全年收入：939.499亿，同比增长58%。 广告收入：725.634亿，同比增长51%。 交易佣金收入：141.404亿，同比增长144%。 商品销售收入：72.461亿，同比增长26%。 收入成本：317.181亿，同比增长65%。
运营支出：553.353亿，同比增长10%，其中研发支出同比增长30%。
减少营销费用，研发还在持续投入
运营利润：68.968亿，Non-GAAP下：116.715亿, 归属股东的净利润：77.687亿，Non-GAAP下：138.295亿。</content></entry><entry><title>APISIX的Plugin介绍</title><url>https://lizj3624.github.io/post/apisix-plugin/</url><categories><category>apisix</category><category>cloudnative</category></categories><tags><tag>apisix</tag><tag>plugin</tag><tag>cloudnative</tag></tags><content type="html"> 插件机制 APISIX通过插件(Plugin)机制来丰富其功能，目前通过lua实现了8大类插件，还通过sidecar模式支持多语言插件。
Plugin配置可直接绑定在Route上，也可以被绑定在Service或Consumer上。 而对于同一个插件的配置，只能有一份是有效的，配置选择优先级总是Consumer > Route > Service。
一个插件在一次请求中只会执行一次，即使被同时绑定到多个不同对象中（比如Route或Service）。 插件运行先后顺序是根据插件自身的优先级(priority)来决定的。
插件热加载 APISIX的插件是热加载的，不管你是新增、删除还是修改插件，都不需要重启服务。
只需要通过admin API发送一个HTTP请求即可：
curl http://127.0.0.1:9080/apisix/admin/plugins/reload -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X PUT 路由加入插件 路由(route)接口中加入plugins关键字后支持插件，limit-count、prometheus都是引用的插件名称。
curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/mypath03/plugin", "plugins": { "limit-count": { "count": 2, "time_window": 60, "rejected_code": 503, "key": "remote_addr" }, "prometheus": {} }, "upstream_id": "00000000000000000122" }' 多语言的外部插件 APISIX通过Sidecar的方式加载和运行多语言开发的插件。这里的Sidecar就是Plugin Runner，多语言开发的插件叫做External Plugin。 如果APISIX中配置了一个Plugin Runner，APISIX将以子进程的方式运行该Plugin Runner。 该子进程与APISIX进程从属相同用户。当重启或者重新加载APISIX时，该Plugin Runner也将被重启。 请求将触发从APISIX到Plugin Runner的RPC调用。 目前支持go、python、java、javascript语言开发插件。 Lua插件开发 如果社区的插件不能满足需求，APISIX也支持自助开发插件。Lua插件规范
引用 apisix plugin
apisix plugin列表
apisix 外部插件
apisix lua插件开发
apisix admin API</content></entry><entry><title>APISIX快速入门</title><url>https://lizj3624.github.io/post/apisix-quick-start/</url><categories><category>apisix</category><category>nginx</category></categories><tags><tag>apisix</tag><tag>nginx</tag></tags><content type="html"> 前面介绍过APISIX，github开源社区比较活跃的云原生API网关， 自己根据官方的快速入门指南学习使用APISIX。
安装部署 安装部署APISIX APISIX支持rpm、docker image、helm chart、source release package安装部署，我开始开始用源码安装但是一直没有 成功，为了先开始学习，用rpm包安装的，以后再慢慢研究源码安装过程。再此提醒一下APISIX暂时不支持CentOS8，这个我 在社区提交issue，后续可能会改进。 在此我简单写一下步骤，详细安装步骤可以参考官方步骤
## apisix yum源, 会安装依赖的OpenResty(apisix-base-1.19.9.1.3-0.el7.x86_64) sudo yum-config-manager --add-repo https://repos.apiseven.com/packages/centos/apache-apisix.repo sudo yum info -y apisix sudo yum --showduplicates list apisix sudo yum install apisix 安装部署etcd apisix的数据存储在etcd中，启动apisix前需要安装etcd并启动。目前最新版本1.12版本只支持etcdv3版本。
## 安装 ETCD_VERSION='3.4.13' wget https://github.com/etcd-io/etcd/releases/download/v${ETCD_VERSION}/etcd-v${ETCD_VERSION}-linux-amd64.tar.gz tar -xvf etcd-v${ETCD_VERSION}-linux-amd64.tar.gz &amp;&amp; \ cd etcd-v${ETCD_VERSION}-linux-amd64 &amp;&amp; \ sudo cp -a etcd etcdctl /usr/bin/ ## 启动, etcd要支持数据持久化 ETCD_HOME=`pwd` sudo nohup etcd --data-dir $ETCD_HOME/data.etcd --wal-dir $ETCD_HOME/wal --snapshot-count 100000 > $ETCD_HOME/etcd.log 2>&amp;1 &amp; 启动apisix # initialize NGINX config file and etcd apisix init # generate `nginx.conf` from `config.yaml` and test it apisix test # start Apache APISIX server apisix start upstream的增删改查 详细可以查看upstream admin API
增加upstream curl "http://127.0.0.1:9080/apisix/admin/upstreams" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "type": "roundrobin", "nodes": { "127.0.0.1:8080": 1, "127.0.0.1:8880": 1, "127.0.0.1:8881": 1 }, "retries": 2, "checks": { "active": { "timeout": 5, "http_path": "/healthcheck", "host": "test.my.com", "healthy": { "interval": 2, "successes": 1 }, "unhealthy": { "interval": 1, "http_failures": 2 }, "req_headers": ["User-Agent: curl/7.29.0"] }, "passive": { "healthy": { "http_statuses": [200, 201, 302, 304], "successes": 3 }, "unhealthy": { "http_statuses": [500, 503, 504], "http_failures": 3, "tcp_failures": 3 } } } }' 添加成功后，返回数据中包含upstream_id(00000000000000000122)，以后可以通过这个id去关联route或service
{ "action":"create", "node":{ "key":"\/apisix\/upstreams\/00000000000000000122", "value":{ "retries":2, "nodes":{ "127.0.0.1:8881":1, "127.0.0.1:8080":1, "127.0.0.1:8880":1 }, "hash_on":"vars", "id":"00000000000000000122", "scheme":"http", "checks":{ "passive":{ "healthy":{ "http_statuses":[ 200, 201, 302, 304 ], "successes":3 }, "unhealthy":{ "http_statuses":[ 500, 503, 504 ], "tcp_failures":3, "timeouts":7, "http_failures":3 }, "type":"http" }, "active":{ "healthy":{ "http_statuses":[ 200, 302 ], "interval":2, "successes":1 }, "timeout":5, "req_headers":[ "User-Agent: curl\/7.29.0" ], "unhealthy":{ "http_failures":2, "tcp_failures":2, "timeouts":3, "interval":1, "http_statuses":[ 429, 404, 500, 501, 502, 503, 504, 505 ] }, "host":"test.my.com", "concurrency":10, "http_path":"\/healthcheck", "https_verify_certificate":true, "type":"http" } }, "pass_host":"pass", "update_time":1647059500, "type":"roundrobin", "create_time":1647059500 } } } 这个upstream还支持主动/被动健康检查，apisix健康检查只有有请求转发到这个upstream时才启动。 有admin API请求时，必须每次都得加token(&lsquo;X-API-KEY: edd1c9f034335f136f87ad84b625c8f1&rsquo;)，不然API校验不通过。
修改upstream # 修改时，可以通过PUT方法 curl "http://127.0.0.1:9080/apisix/admin/upstreams/1" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X PUT -d ' { "type": "roundrobin", "nodes": { "httpbin.org:80": 1 } }' 查询 curl http://127.0.0.1:9080/apisix/admin/upstreams/00000000000000000122 -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' 返回数据
{ "node":{ "key":"\/apisix\/upstreams\/00000000000000000122", "value":{ "retries":2, "nodes":{ "127.0.0.1:8881":1, "127.0.0.1:8080":1, "127.0.0.1:8880":1 }, "hash_on":"vars", "create_time":1647059500, "type":"roundrobin", "pass_host":"pass", "checks":{ "passive":{ "healthy":{ "http_statuses":[ 200, 201, 302, 304 ], "successes":3 }, "unhealthy":{ "http_statuses":[ 500, 503, 504 ], "tcp_failures":3, "timeouts":7, "http_failures":3 }, "type":"http" }, "active":{ "healthy":{ "http_statuses":[ 200, 302 ], "successes":1, "interval":2 }, "timeout":5, "req_headers":[ "User-Agent: curl\/7.29.0" ], "unhealthy":{ "http_failures":2, "tcp_failures":2, "timeouts":3, "interval":1, "http_statuses":[ 429, 404, 500, 501, 502, 503, 504, 505 ] }, "host":"test.my.com", "concurrency":10, "http_path":"\/healthcheck", "https_verify_certificate":true, "type":"http" } }, "update_time":1647059500, "scheme":"http", "id":"00000000000000000122" } }, "action":"get", "count":1 } route的增删改查 route admin API
新增route curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/", "upstream_id": "00000000000000000122" }' 返回数据中也是包含route_id，00000000000000000212
{ "action":"create", "node":{ "key":"\/apisix\/routes\/00000000000000000212", "value":{ "methods":[ "GET" ], "upstream_id":"00000000000000000122", "uri":"\/", "host":"test.my.com", "id":"00000000000000000212", "status":1, "update_time":1647064681, "priority":0, "create_time":1647064681 } } } route的规则是GET方法、host，uri
upstream_id就是上面创建upstream的id，这样命中这个route的请求就会转发到这个upstream上，route也是直接添加upstream， 但是route跟upstream是1:N得关系，为了重复添加重复的upstream，推荐用upstream_id的方式与route绑定；route也是支持service的， 如果service和(upstream或upstream_id)并存时，upstream优先。
修改route curl "http://127.0.0.1:9080/apisix/admin/routes/00000000000000000212" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X PUT -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/mypath", "upstream_id": "00000000000000000122" }' 删除route curl http://127.0.0.1:9080/apisix/admin/routes/00000000000000000212 -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X DELETE 测试验证 curl http://127.0.0.1:9080/ -H "Host: test.my.com" Service增删改查 Service是一组upstream和plugin的组合，plugin可选。
创建Service curl http://127.0.0.1:9080/apisix/admin/services -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X POST -i -d '{"upstream_id": "00000000000000000122"}' ## 返回数据 { "action":"create", "node":{ "key":"\/apisix\/services\/00000000000000000292", "value":{ "id":"00000000000000000292", "update_time":1647069365, "upstream_id":"00000000000000000122", "create_time":1647069365 } } } upstream_id就是前面，创建的upstream，这个Service没有关联plugin
Service绑定Route上 curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d ' { "methods": ["GET"], "host": "test.my.com", "uri": "/mypath01/*", "service_id": "00000000000000000292" }' ## 返回数据 { "action":"create", "node":{ "key":"\/apisix\/routes\/00000000000000000308", "value":{ "service_id":"00000000000000000292", "methods":[ "GET" ], "uri":"\/mypath01\/*", "host":"test.my.com", "id":"00000000000000000308", "status":1, "update_time":1647070197, "priority":0, "create_time":1647070197 } } } 将上面创建的Service绑定一个rout上
删除Service curl "http://127.0.0.1:9080/apisix/admin/routes/00000000000000000292" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X DELETE 测试验证route curl http://127.0.0.1:9080/mypath01/json -H "Host: test.my.com" Consumer增删改查 curl http://127.0.0.1:9080/apisix/admin/consumers -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X PUT -d '{ "username": "test", "plugins": { "key-auth": { "key": "auth-one-test" }, "limit-count": { "count": 2, "time_window": 60, "rejected_code": 503, "key": "remote_addr" } } }' ## 返回数据 { "action":"set", "node":{ "key":"\/apisix\/consumers\/test", "value":{ "username":"test", "update_time":1647070804, "plugins":{ "limit-count":{ "count":2, "key":"remote_addr", "time_window":60, "show_limit_quota_header":true, "key_type":"var", "policy":"local", "rejected_code":503, "allow_degradation":false }, "key-auth":{ "key":"auth-one-test" } }, "create_time":1647070804 } } } 创建route支持consumer curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/mypath04/consumer", "plugins": { "key-auth": {} }, "upstream_id": "00000000000000000122" }' upstream_id也是上面创建的upstream
删除consumer curl "http://127.0.0.1:9080/apisix/admin/consumers/test" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X DELETE 测试验证请求 curl http://127.0.0.1:9080/mypath04/consumer -H "Host: test.my.com" -H 'apikey: auth-one-test' 配置Plugin 在route创建Plugin plugin可以在Consumer、Service，Route配置，同一个Plugin在一个请求中只执行一次，如果配置相同的Plugin，优先顺序： Consumer、Route，Service。
curl "http://127.0.0.1:9080/apisix/admin/routes" -H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X POST -d '{ "methods": ["GET"], "host": "test.my.com", "uri": "/mypath03/plugin", "plugins": { "limit-count": { "count": 2, "time_window": 60, "rejected_code": 503, "key": "remote_addr" }, "prometheus": {} }, "upstream_id": "00000000000000000122" }' plugin绑定在route上
测试验证 curl http://127.0.0.1:9080/mypath03/plugin -H "Host: test.my.com" 引用 APISIX架构
APISIX admin API
APISIX快速入门指南</content></entry><entry><title>区块链技术快速入门</title><url>https://lizj3624.github.io/post/learn-block-chain/</url><categories><category>区块链</category><category>blockchain</category></categories><tags><tag>区块链</tag><tag>blockchain</tag></tags><content type="html"> 知乎一网友写快速学习区块链技术的文章，从读书学习构建区块链技术体系，然后去实践，我感觉非常不错，再次收藏一下。 对格式、文章结构、部分引用url略有改动，原文
2019年从互联网后端开发工程师转型为区块链工程师。一个月时间系统学习区块链技术，参与到链研发工作当中。下面来谈谈自己的学习心得，希望能够帮助到你。
关于「如何高效的自学一项新技能」，我通常分为两步走：
搜集高质量学习材料和工具。 应用合适的学习方法。 区块链经过18、19年的火热发展后，网络上大家都能轻易的找到各种各样的高质量学习资料。此外，本问题的大部分答案都是围绕「学习什么」，因此，下文我将重点介绍「如何学习」的方法论。
一、泛读通读，建立框架，「不求甚解」 尽管区块链和其他的计算机技术没有本质上的区别，但有一个很重要的差异是，区块链技术涉及的技术面非常广。事实上，当我们把中本聪的区块链技术拆解后可发现，区块链技术是由20世纪提出的一些老技术和知识的组合而成的，换句话说，区块链的创新在于老技术的组合创新，正正体现了区块链技术的系统之美。也正是如此，区块链技术涉及知识面非常广，其中包括：分布式系统、拜占庭问题、密码学、数据结构、P2P网络等技术，以及博弈论、经济学等思想。
如果你一开始就针对某一方面孤立学习，不但无法系统化的学习，并且容易迷失在繁多复杂的新概念当中。因此，我建议的方法：以泛读通读的方式，先建立知识框架，对区块链有个大致的认识。
区块链是伴随比特币而产生的，因此要搞明白区块链，首先需要了解比特币：
普林斯顿大学课程 Bitcoin and Cryptocurrency Technologies 《精通比特币》 比特币白皮书 除此之外，对区块链技术的演变也要有一定的了解。作为区块链2.0的代表的以太坊是同样值得学习：
以太坊白皮书 以太坊开发入门指南 精通以太坊（中文版） 《区块链技术指南》 记住！你不需要一字一句全部读完，遇到不懂的概念和知识点记录下来和忽略。在这个过程中，配合搜索引擎，你需要不断的去思考和回答以下几个问题：
区块链、比特币和以太坊是什么？它们的工作原理大概是如何的？比特币和以太坊的区别？ 它们具备什么性质？包含哪些关键的技术点？ 区块链的发明目的是解决什么问题？除此以外，还能解决什么问题？ 区块链具备什么优缺点？ 完成这一步后，你已经对区块链和比特币有一个相对宏观、整体的认识，并初步建立了一个属于你自己的知识框架，此框架在后面的学习中会起到重要的作用。 也许你会觉得你建立的框架并不正确和完整，但不要紧，随着你的认识加深，不断的修正和完善框架。学习本身就是一个螺旋式上升的过程。
二、从外到内，逐一突破 建立知识框架之后，下一步你需要做的就是丰富和完善它。对于第一步中遗留的那些「似懂非懂」的概念和知识点，便可以在这个环节中逐一突破。
简单来说，你要做的便是：主动学习——快速定位你存在疑惑的概念和知识点，用一切办法来攻克它。
在这个阶段中， 除了回顾上面推荐的材料以外， 你需要广泛的搜索，不局限任何的形式。高质量的搜索结果依赖于准确的问题定义， 因此在查询过程中也逐渐帮助定义清楚你的疑惑。此外推荐两个关于区块链技术的中文社区：
深入浅出区块链 比特币布道者 当你在攻克某一个知识点和概念的过程中，你一定会遇到其他新的知识点，此时你便可以顺藤摸瓜，把相关的知识一并学习吸收。 值得注意的是，在这个过程中需要把握好知识扩展的度，避免过度分散注意力，重点还是关注原来的疑惑本身，以目标为导向。至于如何把握，我的建议是：
判断新遇到的概念是否直接影响到你理解原来的概念？若是，务必一切办法攻克它； 新概念在整个框架（知识体系）中是否占有很重要的地位？还是说只是某个知识点延伸出来的小分支？ 比如：在你了解P2P网络时遇到新概念分布式哈希表（DHT），此概念只不过是P2P网络中用于定位特定节点或数据的一个技术手段，显然可暂时不需要深入了解； 要理解新知识点的要求是否远超过当前的知识储备？若是，你也可以暂且先放一放，如：EVM原理。 重点关注的范围还是围绕区块链的工作原理相关的概念为主，如：1）如何处理交易和记账；2）如何产生区块及达成共识；如何验证和储存状态等过程中的重要概念。此外，不必过分追求技术的实现细节。
而关于如何判断是否真正理解透彻，我建议使用「费曼方法， 尝试用自己的方式，用通熟易懂的语言描述清楚。当解决完成相关的概念后，把它们重新放在框架里，不断修正和完善框架。
完成这一步后，我相信你已经对区块链及两个应用的大部分重要概念都理解通透了，基本概念如：
去中心化 共识机制 工作量证明PoW、PoS 非对称加密 硬（软）分叉 双花 智能合约 Merkle Tree(默克尔树) 51%攻击 三、从点到面，构建知识网络 进入第三部以后，你的区块链技术算是入门了。基于你所建立的框架，你已经有能力去理解之前晦涩难懂的概念。接下来，你便可以进一步扩大区块链技术的广度和深度，如：
其他的区块链项目，如：Filecoin、Fabric、EOS等 不同类型的共识算法 零知识证明 区块链的可扩展性方案 智能合约的编写 …… 当你学习上述新的知识的过程中，你需要刻意的去思考和构建知识间的「联系」——此知识和别的知识有什么关系？是如何关联一起的？
知识的本质永远不是信息本身，而是信息之间的联系。正是这种联系，涌现出了超越单个信息点总和的「系统性」。
而区块链技术的创新本身也恰恰是「系统性」。 在这个过程中，我主要的使用如下的系统性方法
对比 将解决同一个问题的不同技术手段归纳整理在一起，多维度进行对比，找出共性和异性。比如：PoW与PoS之间的区别？
PoW vs PoS
分类 目前解决区块链的可行性方案有哪些潜在的研发方向？具体有哪些技术手段？
区块链技术可扩展方案
提炼 尝试用最精炼的语言貌似一类相关的知识点，比如比特币的核心原理：
中本聪使用非对称加密解决电子货币的所有权问题； 用区块时间戳解决交易的存在性问题； 用分布式账本解决剔除第三方机构后交易的验证问题； 用工作量证明和最长链约定来保证节点状态的一致性，已解决「双花」问题。 架构 尝试对系统中的关键模块和模块间的关系进行抽象，并绘制成架构图，如：区块链的分层架构。
区块链分层架构
流程 也可以将根据信息流将不同的知识点串联在一起，绘制成流程图。如：以太坊交易打包流程。
以太坊交易打包流程，来源：CSDN
总之，你需要想尽一些的办法，将知识点关联在一起，逐渐结构化、系统化。
四、实践是检验真理的唯一标准 到这一步后，你掌握的区块链技术的知识体系逐步成型，接下来需要做的便是将技术落地到应用中。
首先，尝试在本地搭建比特币、以太坊的测试网络，和做不同类型的交易交易。对于以太坊，你还可以部署和调用智能合约等等。
以太坊本地私有链开发环境搭建 开始编写更加复杂的Dapp应用：
Solidity语言文档 Web3.JS接口文档 Truffle框架文档 Open Zeppelin框架文档 Ethereum Smart Contract Security Best Practices Ethereum Voting Dapp React Ethereum Dapp Example 在此环节，你的主要目标是熟悉并掌握开发Dapp的相关技能和工具。
五、Code As Documentation 最后一步，选择一个你感兴趣的项目，阅读它的源码，了解底层技术的实现原理，将理论与实践进一步融会贯通。 关于项目的选择，我个人建议是以太坊，至今为止，以太坊的应用面还是最广的，受到各大互联网公司的青睐。
至于如何阅读和学习以太坊的源码，个人建议结合以太坊的黄皮书对比阅读学习。可参考：
以太坊黄皮书-中文版 以太坊代码剖析 解读以太坊黄皮书 以太坊源代码分析 Go Ethereum Code Analysis 七、最后的最后 区块链行业真处于高速发展的时候，作为区块链从业人员，不仅仅要掌握技术，还需要时刻掌握行业动态，挖掘其他有价值的项目，把握认知变现的机会。
《区块链革命》 《货币的非国家化》 希望以上答案可以对你有所帮助！</content></entry><entry><title>Grab 2021Q4以及全年财报</title><url>https://lizj3624.github.io/post/grab-2021/</url><categories><category>grab</category><category>财报</category></categories><tags><tag>grab</tag><tag>财报</tag></tags><content type="html"> Grab是东南亚领先的超级APP，在食品配送、移动出行、金融服务的电子钱包方面是东南亚的领导者。 Grab在东南亚地区八个国家（柬埔寨、印度尼西亚、马来西亚、缅甸、菲律宾、新加坡、泰国和越南）的480个城市的交付、移动和数字金融服务领域开展业务。
Grab 2021全年财务亮点： GMV同比增长29%，至161亿美元。
2021年MTU(月交易用户)为2410w，2021年12份MTU为2770，每位用户的平均支出(定义MTU的GMV)同步增长31%至666美元。
配送和金融服务的GMV增长56%，Pre-Interco TPV同比增长37%。配送和金融服务，收入同比增长44%至6.75亿。 Grab报告的收入不包括消费者、商家和司机合作伙伴的激励措施。
2021年全年亏损36亿美元，其中包含与Grab公开上市后停止的可转换可赎回优先股相关的16亿美元非现金利息费用和3.53亿美元的一次性公开上市相关费用。
调整后的EBITDA为(8.42)亿美元，符合我们的指导范围。同比下降8%。然而，与2020年的 (6.2)% 相比，占GMV(5.2)%的调整后EBITDA利润率有所改善。
截至第四季度末，现金流动性总计90亿美元，而我们的净现金流动性为68亿美元。
Grab 2021年Q4财务亮点： GMV同比增长26%，达到45亿美元，交付和金融服务表现出强劲的同比GMV和TPV（Pre-interco）分别增长52%和29%。出行GMV同比下降11%，但继续复苏，环比增长45%。
MTU(月交易用户)同比增长3%和环比增长18%，达到2600万。每位用户的平均支出同比增长23%至173美元。
收入为1.22亿美元，同比下降44%，原因是Grab抢先投资以增加司机供应，以支持出行需求的强劲复苏。随着Grab对其类别份额和MTU增长的投资，消费者对移动性和交付的激励也增加了。
该期间的亏损为11亿美元，其中包括与Grab公开上市后停止的可转换可赎回优先股相关的3.11亿美元非现金利息费用和与一次性公开上市相关费用相关的3.28亿美元，其中2.9亿美元为非现金.
调整后的EBITDA为(3.05)亿美元，同比下降2.03亿美元。调整后EBITDA利润率为GMV的 (6.8)%，而2020年第四季度为(2.8)%。 下降的原因是上述激励措施投资增加，以及对技术和金融服务等领域的战略投资，包括数字银行我们准备在新加坡推出它。
Grab各业务线财务亮点 配送 2021年GMV为85亿美元，同比增长56%；Q4 GMV同比增长52%至24亿美元
2021年配送佣金为18.2%，高于2020的16.6%。
2021年收入为1.48亿美元，高于2020的500万美元；Q4收入下降98%至100万美元，原因是 Grab 投资了激励措施以保持其类别领导地位并增加对新服务的采用。
2021年调整后EBITDA亏损1.30亿美元，占GMV的百分比为1.5%，比2020年的3.9%有所改善。第四季度交付部门调整后EBITDA亏损84万美元。
移动出行 2021年的GMV为28亿美元，同比下降14%; Q4 GMV环比增长45%（同比下降 11%）至7.65亿美元。
2021年的出行佣金率为23.4%，高于2020年的21.3%。
2021年的收入同比增长4%至4.56亿美元。Q4收入为1.05亿美元，同比下降27%，原因是Grab投资于司机激励措施以加强司机供应以实现强劲复苏。
2021年部门调整后EBITDA为3.45亿美元，与2021年的GMV相比，利润率为12.4%，高于2020年的9.5%。Q4调整后EBITDA为7600万美元，与2020年第四季度相比下降32%。
金融服务 2021年的总支付额（InterCo 之前）为121亿美元，同比增长37%。第四季度InterCo前的TPV同比增长29%至34亿美元。
2021年的佣金率为2.3%，高于2020年的1.9%。
2021年的收入同比增长3700万美元，同期2700万美元。第四季度金融服务亏损100万美元，同比增长300万美元。
&ldquo;花呗"的TPV增长了5倍。
企业以及创新服务 GMV同比增长248%至1.53亿美元。Q4 GMV同比增长127%至5100万美元。Grab的广告GMV Q4同比增长189%。
收入同比增长22%至4400万美元。Q4同比下降39%至1600万美元。
EBITDA为930万美元，占GMV的6%，而2020年为21%；Q4 EBITDA为500万美元，同比下降1500万美元。
配送业务全年GMV占比53%，收入占比22%，由于奖励机制Q4收入大幅下降。 移动出行全年GMV占17%，收入占比67%，是Grab收入的重要来源，但是年GMV同比下降14%，年收入同比只有4%的增长，由于奖励机制Q4收入同比降低27%。 导致Q4整体收入下降44%，导致财报后股价暴跌。Q4收入进行奖励机制后效果是Q4 GMV同比增长26%，月交易用户同比增加3%，环比增加18%，到2600w。
2022年Q1展望： 配送GMV将在24亿至25亿美元之间。
移动出行GMV将在7.5亿美元至8亿美元之间。
金融服务Pre-InterCo TPV将在31亿至32亿美元之间。
展望2022年以后，Grab将在2023年上半年实现核心食品配送部门调整后EBITDA盈亏平衡，并在2023年底实现交付部门调整后EBITDA盈亏平衡， 从长远来看，Grab的目标是：移动出行调整后EBITDA占GMV的12%，配送为3%。</content></entry><entry><title>云原生API网关APISIX简介</title><url>https://lizj3624.github.io/post/apisix-primer/</url><categories><category>apisix</category><category>cloudnative</category></categories><tags><tag>apisix</tag><tag>cloudnative</tag></tags><content type="html"> 缘起 APISIX是国内在github开源社区比较活跃的云原生API网关，目前(2022-03-06)github star 8.6k，fork 1.6k。APISIX底层是基于Nginx和OpenResty， 我本人在工作中也是经常用到Nginx和OpenResty，因此对这个项目比较感兴趣，最近开始研究它，先了解它的架构以及一些概念。
架构 APISIX最底层是基于Nginx，再上一次层是OpenResty，再上一次层是ngx_lua开发的APISIX core，再上一层是APISIX Plugin Runtime(插件运行时)， 最上层是APISIX的插件，它还支持多语言(go, java等)的插件。 插件化是APISIX架构设计很不错的地方，可以使APISIX易扩展，集成了大量丰富的插件，通过rpc的方式支持多语言插件。插件请求的很多阶段被调用。 一些概念 Route路由 route路由是请求进入APISIX后，根据一定匹配规则，将请求流量转发到指定upstream或者service。
如果router配置upstream和service时，优先使用upstream 路由包含三部分：
匹配规则(比如: uri, host, remote_addr) 插件匹配(比如: 限流插件) upstream上游信息 Plugin插件 Plugin是请求/响应过程中执行的插件配置。Plugin配置可直接绑定在Route上，也可以被绑定在Service或Consumer上。 而对于同一个插件的配置，只能有一份是有效的，配置选择优先级总是Consumer > Route > Service。 一个插件在一次请求中只会执行一次，即使被同时绑定到多个不同对象中（比如Route或Service）
Service服务 Service是某类服务的抽象，是有Plugin和upstream组成的一组服务，Plugin可以选的，它通常与上游upstream服务抽象是一一对应的。 Route与Service之间，通常是N:1的关系。
Consumer消费者 Consumer是某类服务的消费者，需与用户认证体系配合才能使用。 比如不同的Consumer请求同一个API， 网关服务根据当前请求用户信息，对应不同的Plugin或Upstream配置。
Upstream上游 Upstream是虚拟主机抽象，对给定的多个服务节点按照配置规则进行负载均衡。Upstream的地址信息可以直接配置到Route(或Service) 上， 当Upstream有重复时，就需要用“引用”方式避免重复了。</content></entry><entry><title>独立开发者</title><url>https://lizj3624.github.io/post/developer/</url><categories><category>独立开发者</category></categories><tags><tag>独立开发者</tag></tags><content type="html"> 中国独立开发者列表 创造者日报 独立开发者社区</content></entry><entry><title>Cpu排名</title><url>https://lizj3624.github.io/post/cpu-rank/</url><categories/><tags><tag>cpu</tag></tags><content type="html"> 手机CPU性能天梯图 桌面CPU性能天梯图 移动端CPU综合性能排行</content></entry><entry><title>lua-nginx-module模块源码浅析</title><url>https://lizj3624.github.io/post/lua-nginx-module-arch/</url><categories><category>nginx源码分析</category></categories><tags><tag>nginx源码分析</tag><tag>lua-nginx</tag></tags><content type="html"> 最近在公司接入层的nginx支持QUIC+HTTP3的工作，我们的nginx用了lua-nginx-module模块，在启用HTTP3时，这个模块偶发epoll_ctl(1, 3) failed (17: File exists)的错误， 感觉应该是lua-nginx-module对HTTP3支持不好，因此看一下源码，适配一下HTTP3。
架构 学习lua-nginx-module模块前，先了解这个模块指令在nginx处理阶段的执行调用的情况，再次借用一下官方的图。 //master进程初始化时调用 init_by_lua* //worker进程初始化时调用 init_worker_by_lua* //ssl握手阶段调用 ssl_certificate_by_lua* set_by_lua* //rewrite阶段调用 rewrite_by_lua* //access阶段调用, 指令运行于nginx access阶段的末尾，因此总是在allow和deny这样的指令之后运行 access_by_lua* //content阶段调用, 所有请求处理阶段中最为重要的一个，运行在这个阶段的配置指令一般都肩负着生成内容（content）并输出HTTP响应 content_by_lua* //设置upstream阶段调用 balancer_by_lua* //过滤header头, 一般只用于设置Cookie和Headers等 header_filter_by_lua* //过滤body, 一般会在一次请求中被调用多次, 因为这是实现基于HTTP1.1 chunked 编码的所谓“流式输出”的 body_filter_by_lua* //日志阶段 log_by_lua* 模块初始化 lua-nginx-module也是nginx的第三方模块，它也遵守nginx模块开发规范，可以查看nginx模块化架构了解nginx的模块化开发，nginx加载lua指令时会有初始化。 先看一下这个模块的定义: ngx_module_t ngx_http_lua_module = { NGX_MODULE_V1, &amp;ngx_http_lua_module_ctx, /* module context */ ngx_http_lua_cmds, /* module directives */ NGX_HTTP_MODULE, /* module type */ NULL, /* init master */ NULL, /* init module */ ngx_http_lua_init_worker, /* init process */ NULL, /* init thread */ NULL, /* exit thread */ NULL, /* exit process */ NULL, /* exit master */ NGX_MODULE_V1_PADDING }; lua模块的init_process回调函数
ngx_int_t ngx_http_lua_init_worker(ngx_cycle_t *cycle) { //获取lua模块的配置信息 lmcf = ngx_http_cycle_get_module_main_conf(cycle, ngx_http_lua_module); ... http_ctx ... //模块create_srv_conf，merge_srv_conf，create_loc_conf，merge_loc_conf ... ctx = ngx_http_lua_create_ctx(r); ... //http request放到lua中 ngx_http_lua_set_req(lmcf->lua, r); //init_worker_by的post回调函数 (void) lmcf->init_worker_handler(cycle->log, lmcf, lmcf->lua); ... } ngx_conf_parse====>ngx_conf_handler====&raquo;ngx_http_block====>postconfiguration
lua模块的postconfiguration回调函数，初始化lua vm
static ngx_int_t ngx_http_lua_init(ngx_conf_t *cf) { ... lmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_lua_module); ... //设置ngx http处理阶段的回调函数 cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module); if (lmcf->requires_rewrite) { h = ngx_array_push(&amp;cmcf->phases[NGX_HTTP_REWRITE_PHASE].handlers); if (h == NULL) { return NGX_ERROR; } *h = ngx_http_lua_rewrite_handler; } if (lmcf->requires_access) { h = ngx_array_push(&amp;cmcf->phases[NGX_HTTP_ACCESS_PHASE].handlers); if (h == NULL) { return NGX_ERROR; } *h = ngx_http_lua_access_handler; } dd("requires log: %d", (int) lmcf->requires_log); if (lmcf->requires_log) { arr = &amp;cmcf->phases[NGX_HTTP_LOG_PHASE].handlers; h = ngx_array_push(arr); if (h == NULL) { return NGX_ERROR; } if (arr->nelts > 1) { h = arr->elts; ngx_memmove(&amp;h[1], h, (arr->nelts - 1) * sizeof(ngx_http_handler_pt)); } *h = ngx_http_lua_log_handler; } if (multi_http_blocks || lmcf->requires_header_filter) { rc = ngx_http_lua_header_filter_init(); if (rc != NGX_OK) { return rc; } } if (multi_http_blocks || lmcf->requires_body_filter) { rc = ngx_http_lua_body_filter_init(); if (rc != NGX_OK) { return rc; } } ... //如果lua环境不存在，初始化 if (lmcf->lua == NULL) { lmcf->lua = ngx_http_lua_init_vm(NULL, cf->cycle, cf->pool, lmcf, cf->log, NULL); ... //init_by_lua的post回调函数ngx_http_lua_init_by_file rc = lmcf->init_handler(cf->log, lmcf, lmcf->lua); ... } } lua-nginx-module这个模块赋予了nginx支持lua的能力，这个模块在nginx启动时初始化lua的执行环境。 为worker初始化lua vm函数，lua_State
static lua_State * ngx_http_lua_new_state(lua_State *parent_vm, ngx_cycle_t *cycle, ngx_http_lua_main_conf_t *lmcf, ngx_log_t *log) { ... L = luaL_newstate(); ... ngx_http_lua_init_registry(L, log); ngx_http_lua_init_globals(L, cycle, lmcf, log); return L; } 模块指令的执行过程 以access_by_lua*这类指令执行的过程，看一下指令的指令流程, 先看一下指令的定义
{ ngx_string("access_by_lua_file"), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF |NGX_CONF_TAKE1, ngx_http_lua_access_by_lua, NGX_HTTP_LOC_CONF_OFFSET, 0, (void *) ngx_http_lua_access_handler_file }, 指令的set函数ngx_http_lua_access_by_lua, post函数是ngx_http_lua_access_handler_file
char * ngx_http_lua_access_by_lua(ngx_conf_t *cf, ngx_command_t *cmd, void *conf) { //加载lua文件 //设置access_handler回调, post函数(ngx_http_lua_access_handler_file) llcf->access_handler = (ngx_http_handler_pt) cmd->post; } ngx_int_t ngx_http_lua_access_handler_file(ngx_http_request_t *r) { ... //获取lua vm L = ngx_http_lua_get_lua_vm(r, NULL); //加载lua到cache中 /* load Lua script file (w/ cache) sp = 1 */ rc = ngx_http_lua_cache_loadfile(r->connection->log, L, script_path, llcf->access_src_key); ... return ngx_http_lua_access_by_chunk(L, r); } static ngx_int_t ngx_http_lua_access_by_chunk(lua_State *L, ngx_http_request_t *r) { //开启lua协程,为每个请求分配一个协程 co = ngx_http_lua_new_thread(r, L, &amp;co_ref); ... //将request请求与协程绑定 ngx_http_lua_set_req(co, r); ... //执行协程 rc = ngx_http_lua_run_thread(L, r, ctx, 0); if (rc == NGX_AGAIN) { //协程处理 rc = ngx_http_lua_run_posted_threads(c, L, r, ctx, nreqs); if (rc == NGX_ERROR || rc == NGX_DONE || rc > NGX_OK) { return rc; } if (rc != NGX_OK) { return NGX_DECLINED; } } else if (rc == NGX_DONE) { //释放协程 ngx_http_lua_finalize_request(r, NGX_DONE); rc = ngx_http_lua_run_posted_threads(c, L, r, ctx, nreqs); if (rc == NGX_ERROR || rc == NGX_DONE || rc > NGX_OK) { return rc; } if (rc != NGX_OK) { return NGX_DECLINED; } } ... } 总结 从源码大致看一下lua-nginx-module的执行过程，lua vm初始化部分还有一些疑惑，后期再细细看看。</content></entry><entry><title>nginx源码分析-模块化架构</title><url>https://lizj3624.github.io/post/ngx-module-arch/</url><categories><category>nginx源码分析</category></categories><tags><tag>nginx源码分析</tag><tag>nginx</tag></tags><content type="html"> 从源码角度分析一下nginx的模块化设计架构，主要通过nginx-1.15.8源码以及陶辉写的《深入理解Nginx模块开发与架构解析》进行分析的。
nginx模块的数据结构 nginx模块化的设计主要体现在ngx_module_t的数据结构 struct ngx_module_s { ngx_uint_t ctx_index; ngx_uint_t index; char *name; ngx_uint_t spare0; ngx_uint_t spare1; ngx_uint_t version; const char *signature; void *ctx; ngx_command_t *commands; ngx_uint_t type; ngx_int_t (*init_master)(ngx_log_t *log); ngx_int_t (*init_module)(ngx_cycle_t *cycle); ngx_int_t (*init_process)(ngx_cycle_t *cycle); ngx_int_t (*init_thread)(ngx_cycle_t *cycle); void (*exit_thread)(ngx_cycle_t *cycle); void (*exit_process)(ngx_cycle_t *cycle); void (*exit_master)(ngx_cycle_t *cycle); uintptr_t spare_hook0; uintptr_t spare_hook1; uintptr_t spare_hook2; uintptr_t spare_hook3; uintptr_t spare_hook4; uintptr_t spare_hook5; uintptr_t spare_hook6; uintptr_t spare_hook7; }; typedef struct ngx_module_s ngx_module_t; 主要字段说明 ctx_index表示当前模块在这类(type类型)模块中的序号。它非常重要，Nginx的模块化设计非常依赖于各个模块的顺序，它们即用于表达优先级，也用于表明每个模块的位置，以便nginx框架快速获得某个模块的数据。
ctx_index赋值主要在ngx_count_modules函数处理的。
index表示当前模块在nginx所有模块ngx_modules中的序号，nginx在启动时会根据ngx_modules数组设置各个模块的index值
ngx_int_t ngx_preinit_modules(void) { ngx_uint_t i; for (i = 0; ngx_modules[i]; i++) { ngx_modules[i]->index = i; ngx_modules[i]->name = ngx_module_names[i]; } ngx_modules_n = i; ngx_max_module = ngx_modules_n + NGX_MAX_DYNAMIC_MODULES; return NGX_OK; } ctx ctx用于指向一类模块的上下文结构体，指向这类特定模块的公共接口，只对HTTP模块，主要ngx_http_module_t结构体，后面会介绍这个结构体
commands 模块所支持的指令。
type 模块的类型, 与ctx密切相关，主要有这种类型NGX_HTTP_MODULE、NGX_CORE_MODULE、NGX_CONF_MODULE、NGX_EVENT_MODULE、NGX_MAIL_MODULE、NGX_STREAM_MODULE
init_master 代码中好像没有调用，貌似做保留用，从字面上来，应该是master进程启动时调用。
init_module 每个模块如果设置这个回调函数，初始化时调用。
ngx_int_t ngx_init_modules(ngx_cycle_t *cycle) { ngx_uint_t i; for (i = 0; cycle->modules[i]; i++) { if (cycle->modules[i]->init_module) { if (cycle->modules[i]->init_module(cycle) != NGX_OK) { return NGX_ERROR; } } } return NGX_OK; } ngx_init_modules函数主要是由master进程fork子进程前的ngx_init_cycle调用
init_process 子进程for完成后调用。主要由ngx_worker_process_init调用，而ngx_worker_process_init主要有fork子进程后的ngx_worker_process_cycle调用。
ngx_master_process_cycle&ndash;>ngx_start_worker_processes&ndash;>ngx_worker_process_cycle&ndash;>ngx_worker_process_init&ndash;>cycle->modules[i]->init_process(cycle)
init_thread 多线程模式下调用，nginx已经支持多线程模式，但是再这里暂不讨论。
exit_thread 多线程模式下调用，nginx已经支持多线程模式，但是再这里暂不讨论。
exit_process woker子进程时调用。
exit_master master进程时调用。
模块的数据结构中的初始化回调函数init_module、init_process、exit_process、exit_master是由nginx框架调用的，跟HTTP框架无关，因此HTTP模块时可以设置为NULL，HTTP模块主要设置ctx和commands, 针对HTTP模块来说，ctx指向ngx_http_moduel_t的数据结构，commands被赋值于ngx_command_t的结构体。我们通过lua-nginx-module的模块代码。
ngx_module_t ngx_http_lua_module = { NGX_MODULE_V1, // ngx_module_t数据结构的前7个字段，通过一个宏定义统一赋值 &amp;ngx_http_lua_module_ctx, /* module context */ //ctx字段, 主要是ngx_http_module_t指针 ngx_http_lua_cmds, /* module directives */ //commands字段, 只要是ngx_command_t结构体 NGX_HTTP_MODULE, /* module type */ //type字段 NULL, /* init master */ //init_master回调函数 NULL, /* init module */ //init_module回调函数 ngx_http_lua_init_worker, /* init process */ //init_process回调函数 NULL, /* init thread */ //init_thread回调函数 NULL, /* exit thread */ //exit_thread回调函数 NULL, /* exit process */ //exit_process回调函数 NULL, /* exit master */ //exit_master回调函数 NGX_MODULE_V1_PADDING //其他字段剩余字段统一宏定义赋值 }; ctx的数据结构在ngx_module_t中是void类型，可以是任何指针类型，在HTTP模块主要是ngx_http_module_t的数据结构指针，其他模块可能是其他类型，我们先从HTTP模块分析
HTTP模块的ctx数据结构 HTTP模块的ctx主要是ngx_http_module_t的结构体指针，我们来看一下这个结构体
typedef struct { ngx_int_t (*preconfiguration)(ngx_conf_t *cf); //解析配置前调用 ngx_int_t (*postconfiguration)(ngx_conf_t *cf); //完成配置解析后调用 void *(*create_main_conf)(ngx_conf_t *cf); //main级别(http{}块配置项)中的全局配置时，回调函数创建存储全局配置的结构体 char *(*init_main_conf)(ngx_conf_t *cf, void *conf); //main级别配置项的初始化 void *(*create_srv_conf)(ngx_conf_t *cf); //srv级别(server{}块)的配置时，回调函数创建存储配置的结构体 char *(*merge_srv_conf)(ngx_conf_t *cf, void *prev, void *conf); //srv级别初始化回调函数 void *(*create_loc_conf)(ngx_conf_t *cf); //loc级别(location{})的配置时，回调函数创建存储配置的结构体 char *(*merge_loc_conf)(ngx_conf_t *cf, void *prev, void *conf); //用于合并srv级别和loc级别同名配置项 } ngx_http_module_t; 这8个回调函数在HTTP模块的调用顺序可能跟定义顺序不一致，实际顺序应该如下：
create_main_conf
create_srv_conf
creat_loc_conf
preconfiguration
init_main_conf
init_srv_conf
init_loc_conf
postconfiguration
这8个函数都在ngx_http_block函数中调用
static char * ngx_http_block(ngx_conf_t *cf, ngx_command_t *cmd, void *conf) { ... //初始化ngx_http_conf_ctx_t的ctx，ctx->main_conf，ctx->srv_conf，ctx->loc_conf //调用逐个Http模块的create_main_conf，create_srv_conf，create_loc_conf //调用preconfiguration //调用http{}块的配置 rv = ngx_conf_parse(cf, NULL); //调用各个模块的init_main_conf，init_srv_conf，init_loc_conf //调用各个模块的postconfiguration ... } 我们来看一下lua-nginx-module的ngx_http_module_t
ngx_http_module_t ngx_http_lua_module_ctx = { NULL, /* preconfiguration */ ngx_http_lua_init, /* postconfiguration */ ngx_http_lua_create_main_conf, /* create main configuration */ ngx_http_lua_init_main_conf, /* init main configuration */ ngx_http_lua_create_srv_conf, /* create server configuration */ ngx_http_lua_merge_srv_conf, /* merge server configuration */ ngx_http_lua_create_loc_conf, /* create location configuration */ ngx_http_lua_merge_loc_conf /* merge location configuration */ }; 除了preconfiguration为NULL，其他都赋值了相应的回调函数。
指令数据结构 指令用于定义模块的配置文件的指令参数，主要是ngx_command_t的数据结构
struct ngx_command_s { ngx_str_t name; //指令名称，比如gzip ngx_uint_t type; //类型，出现的位置，比如http{}，server{}, loc{} char *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); //解析指令的回调函数 ngx_uint_t conf; //在配置文件中偏移量 ngx_uint_t offset; //通常用于预设的解析方法配置项，这是配置模块的一个优秀设计，需要conf配合使用 void *post; //配置读取后的处理方法 }; typedef struct ngx_command_s ngx_command_t; 我们来看一下lua-nginx-module的ngx_command_t，这个模块的指令太多，我截取一部分看一下
static ngx_command_t ngx_http_lua_cmds[] = { ... /* access_by_lua "&lt;inline script>" */ { ngx_string("access_by_lua"), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF |NGX_CONF_TAKE1, ngx_http_lua_access_by_lua, NGX_HTTP_LOC_CONF_OFFSET, 0, (void *) ngx_http_lua_access_handler_inline }, /* access_by_lua_block { &lt;inline script> } */ { ngx_string("access_by_lua_block"), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF |NGX_CONF_BLOCK|NGX_CONF_NOARGS, ngx_http_lua_access_by_lua_block, NGX_HTTP_LOC_CONF_OFFSET, 0, (void *) ngx_http_lua_access_handler_inline }, ... ngx_null_command } 指令accee_by_lua的set函数ngx_http_lua_access_by_lua，post函数ngx_http_lua_access_handler_inline
总结 开发nginx第三方模块时，要严格ngx_module_t格式定义模块，只有这样nginx框架才能调用这个三方模块。</content></entry><entry><title>沃伦.巴菲特致股东的信-2021</title><url>https://lizj3624.github.io/post/warren-buffett-letter-2021/</url><categories><category>巴菲特致股东的信</category><category>财经</category></categories><tags><tag>巴菲特致股东的信</tag><tag>财经</tag></tags><content type="html"> 2022年2月26号巴菲特致股东的亲笔写发布，在2021年疫情和高通胀压力下，美元加息预期越来越迫切的情况下，科技股大幅度的回调，而伯克希尔营收逆势增长25%。 长期来看，1965-2021年，伯克希尔的年化收益为20.1%，显著超过标普500指数的10.5%, 1964-2021年伯克希尔达到令人吃惊的3641613%，也就是3.6万多倍多, &lsquo;股神&rsquo;还是那个股神。 巴菲特致股东的信2021-英文版, 中文版有聪明的投资者公众号翻译
北京时间2月26日晚间，伯克希尔哈撒韦公司官网公布了2021年年度报告，以及一份巴菲特每年亲自撰写的致股东信。
今年巴菲特大约是“跳着踢踏舞”的节奏写完伯克希尔的股东信。
股东信只有12页，篇幅越来越少，但这几年的感性色彩渐浓。
2021年，伯克希尔扬眉吐气地跑赢标普500指数，而公司营业利润在第四季度和全年都飙升，旗下业务在疫情带来的经济放缓中显著恢复生机。
伯克希尔2021年度营业收入总计 274.55 亿美元，比 2020 年的 219.92 亿美元增长了 25.2%。
巴菲特在 2021 年回购了创纪录数量的伯克希尔股票，总额达到约 270 亿美元。
在今年的信中，巴菲特连用“惊讶”一词。确实，至少这张成绩单对于股东和市场而言，称得上是惊喜的。
股东信最值得关注的几点，聪明投资者特别标注出来：
累计回报3.6万倍，复利之杖的神力！ 伯克希尔去年跑赢标普500指数0.9个百分点。
长期来看，1965-2021年，伯克希尔的年化收益为20.1%，显著超过标普500指数的10.5%。
尤其是看累计回报，1964-2021年伯克希尔达到令人吃惊的3641613%，也就是3.6万多倍多，而截至2020年的总回报是2.8万倍。
好吧，这个数字对于并没有可能参与始终的我们来说，没什么意义，但至少看到了活生生的例子，就是复利之杖的神力。
虽然并不控股，巴菲特还是把苹果列为“我们的四大巨头”。 考虑到其他三巨头都是伯克希尔控股业务，可见苹果以市值而论对于伯克希尔的贡献之大。
买入苹果不是很早的事情。巴菲特其实是在2016 年，在投资副手 Todd和 Ted的影响下开始购买苹果股票。到 2018 年年中，伯克希尔已经累计持有苹果5% 的股份，价值 360 亿美元。
如今，苹果的投资现在价值超过 1600 亿美元，占伯克希尔股票投资组合的 40%。
2021年巴菲特并没有增减苹果股票，但因为库克股票回购策略，让投资者“不必动一根指头”就增加了收益。
他对回购的作用一如既往地激赏。
铁路和能源两个支柱业务，去年也是创纪录表现。 BNSF（美国伯灵顿北方圣太菲铁路运输公司）和BHE（伯克希尔哈撒韦能源公司）去年净利润分别达到60亿美元、40亿美元，都创了纪录。
伯克希尔第四季度的营业利润飙升 45%，都要归功于其铁路、公用事业和能源业务在疫情对经济的打击中持续反弹。
2021年回购花了点钱出去，伯克希尔目前仍然持有1440亿美元现金。 2020年，伯克希尔已经拿出 240多亿美元回购股份，当时巴菲特就说2021年还将继续加大回购力度。
果然，拿出了270亿美元。
巴菲特持续回购，还是认为伯克希尔价值被低估的，按他的心意应该想要买更多。问题是，公司股东比较惜售，要大体量回购，只能慢慢来。
巴菲特在比亚迪上赚了32倍，2021年一股没卖 比亚迪现在依然是伯克希尔第八大重仓股（非控股的公司中）。
2008年9月，伯克希尔以每股8港元的价格购买2.25亿股比亚迪H股，总金额约2.3亿美元，并一路持有。年报显示，巴菲特在比亚迪的投资上已赚了32倍，但2021年一股都没卖，虽然比亚迪的“超级铁粉”李录，都在连续减持套现。
讲了一则轶事，没有TTI的保罗·安德鲁斯就不会有后来收购BNSF。 去年3月，创始人兼首席执行官保罗·安德鲁斯去世。50年来，安德鲁斯带领TTI取得非凡成就，成为业内卓越的电子元器件分销商之一。
TTI在2007年成为伯克希尔旗下子公司。巴菲特很详细地回忆跟安德鲁斯初次相见以及合作十几年的过往，所有赞美其实可以归为两句话：
安德鲁斯是位真正的企业家，不仅经营厉害，而且品格高尚；
如果没有当年投TTI，也就不会有2009年因为要参观TTI选择在沃斯堡开伯克希尔董事会，也就不会有后面投BNSF的事儿。
巴菲特把这归功于安德鲁斯给他的好运气。
巴菲特预测，未来一个世纪，BNSF将是伯克希尔乃至美国的最核心的资产。
今年股东聚会将在奥马哈重启，定于4月29日-5月1日。
希望顺利。
以下为聪明投资者的全文精译：
致伯克希尔哈撒韦公司股东：
查理·芒格是我的长期合作伙伴，我的工作是管理他的部分资产。能获得他的信任，我感到非常荣幸。
我们有责任向股东们报告大家想知道的情况。我们非常开心能够通过这封年度信件以及年度会议来与股东们直接沟通。
我们的政策是平等对待所有股东，因此我们不与分析师或大型机构进行讨论。我们会尽可能地在周六早上发布重要的信息，以便在周一开盘前，让股东和媒体有尽量多的时间来消化。
伯克希尔公司定期向SEC提交的年度10-K报告中列出了大量伯克希尔公司的事实和数据，这些也会在K-1至K-119页上呈现。
一些股东会觉得这些细节引人入胜，也有其他股东更愿意了解我和查理认为的在伯克希尔出现的那些新的或有趣的东西。
但在2021年，这些几乎没有。
不过，我们确实在提高公司股票的内在价值方面取得了合理进展，这项任务是我57年来的首要职责，而且未来一直是。
股东们拥有什么 伯克希尔拥有各种各样的公司，有些是全资控股，有些只是部分持股。
后者主要由美国大公司的可交易的普通股组成。
此外，我们还拥有一些海外资产，并参与了一些合资企业以及其他类型的合作项目。
无论我们的所有权形式如何，我们的目标都是对那些拥有护城河以及一流CEO的企业进行有意义的投资。
请特别注意，我们持有股票是基于我们对企业长期业务表现的预期，而不是拿来作为交易的工具。
这一点至关重要：查理和我不是在选股票，我们是在选商业模式和企业。
我也曾犯了很多错。所以最终结果是，我们广泛投资的企业中，包括一些具有真正非凡的企业，以及一些表现还不赖的企业，当然也有不怎么样的。
我们通过股票市场来投资，因为有时确实可以用便宜价格买到非常优秀的企业。这种“守株待兔”的做法在谈判交易中太罕见了，也不太会普遍存在。
但在二级市场，可以随时交易，错了也容易纠正。
惊讶，惊讶 以下是一些关于公司的信息，即使是经验丰富的投资者也常常感到惊讶：
（1）许多人认为伯克希尔是一个庞大而有点奇怪的金融资产组合。事实上，伯克希尔拥有并运营的美国“基础设施”资产——在我们的资产负债表上被归类为不动产、厂房和设备——比其他任何美国公司都多。
虽然这一优势从来不是我们追求的目标，但是这已经成为事实。
截至年底，伯克希尔的资产负债表上所记录的国内基础设施资产价值为1580亿美元。
这一数字在去年有所增加，未来还会继续，因为伯克希尔将持续前进。
（2）伯克希尔每年都要缴纳大量的联邦所得税。2021年我们就缴纳了33亿美元，而美国财政部报告的企业所得税收入总额为4020亿美元。此外，伯克希尔还缴纳了大量的州税和外国税。
可以说，伯克希尔的股东们“坐在办公室里都能为国做贡献”。
伯克希尔的历史生动说明了政府和美国企业之间那种无形又难以言说的纽带关系。
1955年初，伯克希尔精纺和哈撒韦制造同意合并他们的业务。在请求股东批准的过程中，这两家备受尊敬的新英格兰纺织公司对此次合并寄予厚望。
例如，哈撒韦的询价向股东保证“资源和管理的结合将造就纺织行业最强大、最高效的组织之一。”当时担任该公司顾问的雷曼兄弟也非常赞同这一乐观的说法。
我敢肯定，对于福尔河（伯克希尔）和新贝德福德（哈撒韦）来说，这是令人愉快的日子。然而，当乐队停止演奏、银行家们回家后，股东们将面临一场灾难。
在合并后的9年里，伯克希尔的所有者目睹了公司的净资产从5140万美元跌至2210万美元，部分是由于股票回购、欠考虑的股息政策以及工厂停产导致的。
但数千名员工9年的努力也带来了运营亏损。伯克希尔的困境并不罕见：新英格兰纺织业已经悄然进入了漫长且不可逆的死亡之旅。
在合并后的9年里，美国财政部也因伯克希尔而遇到了麻烦。在此期间内，公司只向政府缴纳了337,359美元的所得税——每天只有可怜的100美元。
1965年初，情况发生了变化。
伯克希尔有了新的管理层，重新分配了可用现金，并将所有收益基本都引导到了各种良好的业务中，其中大部分业务多年来一直保持良好。
收益的再投资与复利的力量结合在一起发挥了神奇的作用，股东们也因此赚钱了。
应该指出的是，伯克希尔的股东并不是这一航向调整中唯一受益者。背后“沉默的伙伴”——美国财政部持续从公司收取了数百亿美元的所得税。
还记得之前的每天100美元吗？现在，伯克希尔每天向财政部支付大约900万美元。
公平地说，对于我们的政府合作伙伴，我们的股东应该承认——事实上应该大肆宣扬——伯克希尔之所以有这样的繁荣，就是因为公司在美国。
如果没有伯克希尔，我们的国家在1965年以来的这些年里依旧可以取得辉煌的成就。然而，如果我们不是在美国，伯克希尔永远不会变成今天这个样子。
所以当你看到国旗时，请说声谢谢。
（3）伯克希尔在1967年斥资860万美元收购了国家保险公司，现在已成为保险“浮存金”领域的世界领先者。
“浮存金”是我们持有并可以用于投资的，不属于我们的资金。
包括一笔来自人寿保险的资金量相对较小的钱，伯克希尔的浮存金总额已经从刚进军保险领域时的1900万美元增长到了现在的1470亿美元。
到目前为止，这些浮动资金的成本几乎为零。虽然我们经历了保险损失加上运营费用超过保费的若干年份，但总体而言，我们获得了55年的适度利润。
同样重要的是，浮存金是非常具有粘性的。由于我们保险业务产生的资金每天都在变动，但总金额不会急剧下降，因此当用浮存金投资时，我们可以考虑长期投资。
如果你还不熟悉浮存金的概念，请参阅A-5页上的详细说明。
令人惊讶的是，去年我们的浮存金增加了90亿美元，这对伯克希尔公司的所有者来说非常重要，虽然没有反映在我们的GAAP（“公认会计原则”）的收益和净值报告中。
我们在保险业创造的巨大价值，很大程度上要归功于伯克希尔公司在1986年聘用了Ajit Jain（阿吉特·贾）。
我们第一次见面是在一个周六的上午，当时我就询问阿吉特在保险行业的经历，他的回答是“没有。”
我说“没有人是完美的”，然后雇佣了他。
那是我的幸运日：阿吉特实际上是一个非常完美的选择。更棒的是，35年后，他依然如此。
关于保险的最后想说的是：我认为伯克希尔的浮存金很可能——但远不能保证——不太会造成长期承保损失。
但我可以肯定的是，未来几年里会经历承保损失，而且涉及金额不小。
当然，伯克希尔在应对灾难性事件方面的能力是其他保险公司无法媲美的，而且这一优势在我和查理离开后还将持续保持下去。
我们的四巨头 通过伯克希尔，我们的股东拥有数十家企业，而其中一些公司也有自己的子公司。例如，Marmon有100多个独立业务，从铁路车辆租赁到医疗设备制造等等。
（1）尽管如此，我们“四大巨头”公司的运营占了伯克希尔公司价值的很大一部分。
领头的是我们的保险业务，伯克希尔拥有其100%的股份。我们之前也描述过该业务的巨大的浮存金价值，我们用这些浮存金不断投资以支持保险的最终保障承诺，结果投资规模越滚越大。
保险业务是为伯克希尔公司量身定做的，它永远不会过时，而且业务销量通常会随着经济增长和通货膨胀而不断增长。
此外，诚信和资本将一直非常重要，我们公司能够而且一定能表现得越来越好。
当然，也有其他一些保险公司拥有优秀的商业模式和前景。然而，复制伯克希尔的运营模式几乎是不可能的。
（2）苹果——以年终市值计算的亚军——是另外一种不同的持股方式。
我们对其的所有权仅为5.55%，高于一年前的5.39%，这个增幅感觉不值一提。
但考虑到苹果2021年的收益中，每0.1%的持股都是1亿美元。我们并没有花费伯克希尔的钱来进行增持，是苹果的回购起了作用。
重要的是，要知道伯克希尔的GAAP收益报告中只计算了苹果的股息。
去年，苹果支付了我们7.85亿美元的股息。然而，我们在苹果“持股份额”的利润达到了惊人的56亿美元。
公司保留的大部分资金用于回购苹果股份，我们对此表示赞赏。苹果杰出的首席执行官蒂姆·库克将苹果产品的用户视为自己的初恋，这很合理，但蒂姆的其他支持者也从他的管理风格中受益匪浅。
（3）BNSF（伯灵顿北方圣太菲铁路）是我们的第三大持仓，它依然是美国商业的头号动脉，是美国和伯克希尔不可或缺的资产。
如果BNSF运输的产品改用卡车运输，那么美国的碳排放量将会井喷。
2021年，BNSF的利润达到了创纪录的60亿美元。
这里需要指出的是，我们谈论的是我们喜欢的老式算法：扣除利息、税收、折旧、摊销和所有形式计提后的利润。（我们的这种算法也发出了一个警告：随着股市上涨，对收益的进行欺骗性的“调整”已经变得更加频繁，也更加不切实际。恕我直言，牛市让大家越来越膨胀了……）
BNSF的火车去年行驶了1.43亿英里，运送了5.35亿吨货物。
这两项成就都远远超过了其他任何一家美国铁路公司。大家可以为自己的铁路感到骄傲。
（4）我们的最后一只重仓股BHE（伯克希尔哈撒韦能源公司）在2021年赚了创纪录的40亿美元。
比2000年伯克希尔第一次购买BHE的股票时的利润（1.22亿美元增）增长了30多倍。现在，伯克希尔持有该公司91.1%的股份。
BHE的社会成就与其财务业绩一样引人注目。该公司在2000年没有风能，也没有太阳能发电。当时，它只是被认为是美国庞大的电力事业行业中一个相对较新的、较小的参与者。
随后，在大卫·索科尔和格雷格·阿贝尔的领导下，BHE成为了一家公用事业公司（请不要抱怨），以及美国风能、太阳能和输电领域的领军企业。
关于格雷格的这些成就的报告位于A-3和A-4页。你会发现那里的介绍绝对不是时下流行的“洗绿”（ 指企业伪装成环境之友,试图掩盖对社会和环境的破坏,以此保全和扩大自己的市场或影响力）故事。
自2007年开始，BHE每年都会详细介绍其在可再生能源和输电方面的计划和业绩。
想进一步了解这些信息，请访问BHE的网站brkenergy.com。在那里，你会看到该公司长期以来一直在实施应对气候变化的举措，这些举措耗尽了其所有的收入。但未来有更多的机会——BHE拥有良好的管理、经验、资本，可以满足国家对大型电力项目的需求。
现在让我们来谈谈我们没有控股的公司，这个表再次提到了苹果。
下表列出了我们持仓市值最大的15只股票，其中几只是伯克希尔的两位长期投资经理托德•库姆斯（Todd Combs）和特德•韦施勒（Ted Weschler）选择的。
到2021年底，这对明星投资经理对340亿美元的投资拥有完全的权力，其中许多投资都没有达到我们在表中使用的门槛值。
此外，托德和特德管理的相当大一部分资金存在伯克希尔旗下企业的各种养老金计划中，这些计划的资产未包含在此表中。 美国国债 伯克希尔的资产负债表包括1440亿美元的现金和现金等价物（不包括持有的BNSF和BHE）。其中，1200亿美元以美国国债的形式持有，全部在一年之内到期。
1%的公开市场中的国债，有大约半数资金来自伯克希尔。
查理和我已承诺，伯克希尔将始终持有超过300亿美元的现金和等价物（包括除BNSF和BHE以外的子公司）。
我们希望伯克希尔在财务上坚不可摧，永不依赖陌生人（甚至朋友）的恩惠。
我们希望夜夜安枕，希望我们的债权人、保险投保人和股东们也如此。
但1440亿美元，会不会太多了？
我向你保证，这笔巨款并不是爱国主义的疯狂表现。查理和我也没有失去对“拥有一家企业”的压倒性偏好。
事实上，80年前的1942年3月11日，当我购买了三股Cities Services优先股时，我第一次表现出对拥有企业的热情。
它们的成本是114.75美元，花费了我所有的积蓄。（当天道琼斯工业平均指数收于99点，这一事实告诉我们：永远不要做空美国。）
在我最初遭受亏损之后，我总是将至少80%的净资产投资在股票上。在那段时间里，我最青睐的状态是满仓—现在仍然如此。
伯克希尔目前的仓位在80%左右，是因为我没找到符合我们长期持有标准的整个公司或其中一小部分（流通股）。
查理和我在过去不时忍受着类似的现金头寸很大的状况。这些时期从来都不令人愉快，也不是永久性的。
幸运的是，在2020年和2021年，我们找到一个温和的、有吸引力的替代现金的方案。
股票回购 我们可以通过三种方式增加股东的投资价值。
第一种方式始终是我们心仪的首选：通过内部增长或收购来提高伯克希尔控股企业的长期盈利能力。现在，内部增长带来的回报远高于收购。然而，与伯克希尔的资源相比，这些机会的规模很小。
我们的第二个选择是购买公开交易的优秀及伟大企业的流通股。有时，这样的可能性既多又极具吸引力。然而如今，我们几乎没有发现什么能让我们兴奋的东西。
这在很大程度上是因为一个真理：长期低利率推动所有生产性投资的价格上涨，无论是股票、地产、农业、原油等等。其他因素也会影响估值，但利率始终很重要。
我们创造价值的最后一条途径是回购伯克希尔的股票。
通过这个简单的举动，我们增加了股东在伯克希尔众多控股和非控股企业中的份额。
当价格跟价值相比很便宜时，这就是我们股东增加财富的最简单、最确定的方式。（除了为持续股东增加价值外，其他几方也获得了收益：回购对回购股份的卖方和社会都有一定的好处。）
随着其他途径越来越没有吸引力，回购对伯克希尔股东来说就很有意义了。
在过去两年中，我们回购了截止2019年末外部流通股的9%，总成本517亿美元。这笔支出使我们的长期股东拥有伯克希尔所有业务能够多出大约10%，无论这些业务是全资拥有（如BNSF和GEICO）还是部分拥有（如可口可乐和穆迪）。
我想强调的是，要使伯克希尔的股票回购有意义，我们的股票必须提供适当的价格。
我们既然不想为其他公司的股票多付钱，那如果我们在回购伯克希尔股票时支出过高，也得不偿失。
从去年年底到2022年2月23日以来，我们以12亿美元的成本回购了更多股票。我们的胃口仍然很大，但始终取决于价格。
必须得说，伯克希尔股票的回购机会有限，因为它拥有高品质的投资者。
如果我们的股票是被短期投机者大量持有，其价格波动和交易量都会大幅放大，这样可能给我们创造更多有价值的回购机会，让长期股东们从投机性回购中获利。
尽管如此，查理和我还是更喜欢我们现在的股东。
最后，伯克希尔所特有的容易被忽视的价值计算：正如我们已经讨论过的，正确的保险“浮存金”对我们来说是很有价值的。
事实上，回购会自动增加每股“浮存金”的金额。
这一数字在过去两年中增长了25%，从每股“A”类股79,387美元上升到99,497美元，这项收益意义很大。
正如前面提到的，这要归功于回购。
一个了不起的人和一个了不起的事业 去年，保罗·安德鲁斯去世了。
保罗是总部位于沃斯堡的伯克希尔子公司TTI的创始人兼首席执行官。
在他的一生中，无论是在事业上还是在个人追求上，保罗都不声不响地表现出了查理和我所钦佩的所有品质。他的故事应该被讲出来。
1971年，保罗在通用动力公司做采购代理。而在失去一份巨额的国防合同后，该公司解雇了包括保罗在内的数千名员工。
由于彼时他的第一个孩子即将出生，保罗决定赌上一把，用自己的500美元积蓄创建了德克萨斯电子公司(Tex-Tronic，后来改名为TTI)。
该公司成立的目标是销售小型电子元器件，第一年的销售额达到了总销售额11.2万美元。今天，TTI的产品市场超过100万种，年销售额达77亿美元。
但回到2006年：63岁的保罗发现自己与家人、工作和同事相处得很幸福。但他有一个挥之不去的担忧，因为他最近亲眼目睹了一个朋友的早逝，以及随之而来的对其家庭和生意造成的灾难性后果，这让他的担忧更加严重。
保罗在2006年问自己，如果他意外死亡，许多依靠他的人将会发生什么?
整整一年，保罗都在为自己的选择而苦苦挣扎。把公司卖给竞争对手？从严格的经济学观点来看，这条路线最有意义。毕竟，竞争对手可以预见到利润丰厚的“协同效应”——当收购者削减TTI的重复职能时，可以实现成本节省。
但是……这样的买家肯定还会保留其首席财务官、法律顾问和人力资源部门。
因此，TTI公司的同一职能部门将被集体裁员。而且，如果需要一个新的配送中心，收购方的家乡城市肯定会比沃斯堡更受青睐。
不管财务效益如何，保罗很快就得出结论，把公司卖给竞争对手不适合他。接下来，他考虑寻找一个金融买家——这个物种曾被恰当地称为杠杆收购公司。然而保罗知道，这样的买家会专注于“退出策略”。
谁知道那会是什么呢？ 考虑到这一切，保罗发现自己没有兴趣将他35年以来苦心经营的成果交给一个中间商。
当保罗见到我时，他解释了为什么他把这两个备选买家排除在外。然后他用比这更委婉的措辞总结了他的困境——“在考虑了一年其他选择后，我想把公司卖给伯克希尔，因为你是唯一剩下的人。”
所以我提出了报价，保罗答应了。一次会面，一顿午餐，达成了一笔交易。
用“从此过上了幸福的生活”来形容我俩都显得平淡无奇。
当伯克希尔收购TTI时，该公司雇佣了2387名员工。现在这个数字是8043。其中很大一部分增长发生在沃斯堡及其周边地区。公司的盈利增长了673%。
每年，我都会打电话给保罗，告诉他，他的薪水应该大幅增加。而每年，他都会告诉我，“我们可以明年再谈，沃伦，我现在太忙了。”
当我和格雷格•阿贝尔参加保罗的追悼会时，我们见到了他的子孙辈、长期合作伙伴（包括TTI的第一位员工），和约翰•罗奇（John Roach），他是伯克希尔于2000年收购的沃斯堡一家公司的前首席执行官。正是约翰把保罗引到奥马哈的，他本能地知道我们会是绝配。
在追悼会上，我和格雷格听说了保罗默默支持的许多人和组织。他的慷慨非同寻常——始终致力于改善他人的生活，尤其是沃斯堡的人们。
在所有方面，保罗都是个杰出的人。
运气——偶尔是非凡的运气——在伯克希尔发挥了作用。如果保罗和我没有共同的朋友——约翰•罗奇，TTI也不会在我们这里安家。但这充足的运气仅仅是个开始。TTI很快就将伯克希尔引向了其最重要的收购。
每年秋天，伯克希尔的董事们都会聚集在一起，听我们的几位高管讲话。
我们有时会根据近期收购的地点来选择会议地点，这意味着董事们可以与新子公司的首席执行官会面，并了解更多关于被收购方的活动。
在2009年秋天，我们因此选择了沃斯堡，以便我们可以访问TTI。当时，总部同样位于沃思堡的BNSF是我们持有股份第三多的公司。尽管有这么多的股份，我却从来没有去过这家铁路公司的总部。
我的助理黛布·博萨内克（Deb Bosanek）将董事会的开幕晚宴安排在10月22日。与此同时，那天我安排早些时候会见马特·罗斯（Matt Rose），他是BNSF的首席执行官。
我一直钦佩他的成就。当我确定这个日期的时候，我没有想到我们的聚会将与BNSF在22日晚些时候发布第三季度盈利报告同时举行。
市场对这家铁路公司的业绩反应不佳。“大衰退”在那年第三季度全面爆发，BNSF的收益情况反映了这种衰退。经济前景也很黯淡，华尔街对铁路也不友好。
第二天，我再次与马特会面，并建议伯克希尔将为铁路公司提供一个比作为上市公司所能期望的更好的长期归宿。我还告诉他伯克希尔愿意支付的最高价格。
马特将这一提议转达给了他的董事和顾问。经过忙碌的11天后，伯克希尔和BNSF宣布了一项确定交易。
在这里，我冒险做出一个罕见的预测：BNSF未来一个世纪，成为伯克希尔乃至美国最核心的资产。
如果保罗•安德鲁斯没有将伯克希尔视为TTI的合适归宿地，BNSF的收购就永远不会发生。
致谢 70年前，我教授了我的第一堂投资课。从那时起，我几乎每年都很享受与各个年龄段的学生一起工作，最终我在2018年从这个追求中 &ldquo;退休&rdquo;。
一路走来，我最艰难的听众是我孙子的五年级班级。这些11岁的孩子在座位上扭来扭去，茫然地看着我，直到我提到可口可乐(Coca-Cola)及其著名的秘密配方时。瞬间，每个人都举起手来，我明白了“秘密”对孩子们来说是一种诱惑。
教学就像写作一样，帮助我发展和理清了自己的思路。查理把这种现象称为猩猩效应：如果你和一只猩猩坐在一起，向它仔细解释你所珍视的一个想法，你可能会留下一只迷惑不解的灵长类动物，但你自己的思维会更清晰。
和大学生交谈则要有效得多。我敦促他们在：
（1）专业领域找工作；
（2）如果他们不差钱的话，找他们想选择的人一起工作。
我承认，经济现实可能会干扰这种选择。
即便如此，我还是敦促学生们永远不要放弃追求，因为当他们找到那种热爱的工作时，他们就不再是“社畜”了。
查理和我在经历了一些早期的挫折后，走上了这条自由的道路。我们都曾在我祖父的杂货店里做兼职——查理1940年、我1942年。我们都被分配了无聊的任务，报酬也少，这绝对不是我们想要的。
后来，查理开始从事法律工作，而我则尝试着卖证券。我们对工作的满意度仍然不高。
最后，在伯克希尔，我们找到了自己喜欢做的事情。除了极少数例外，我们现在已经与我们喜欢和信任的人“工作”了几十年。
与保罗•安德鲁斯（Paul Andrews）或我去年说过的伯克希尔大家庭这样的经理人共事，是一种生活乐趣。
在我们的总部，我们雇佣正派和有才华的人，没有一个人是笨蛋。每年的平均流动率大概是一个人。
不过我想强调另一件事，它使我们的工作变得有趣和令人满意——为股东工作。对查理和我来说，没有什么比获得个人长期股东的信任更值得的了。
几十年来，他们加入我们，期望我们成为他们资金的可靠托管人。
显然，我们不能选择我们的股东，如果我们的经营形式是合伙的话，我们可以这样做。任何人现在都可以购买伯克希尔的股票，并打算很快再出售这些股票。
当然，我们会有一些这样的股东，就像我们会有指数基金持有大量伯克希尔股票，只是因为它们被要求这么做。
伯克希尔拥有一个庞大的个人和家庭团队，他们选择加入我们的行列，且“至死不渝”，这非常不同寻常。通常他们把储蓄的很大一部分——对有些人来说可能是过多的存款——托付给我们。
这些股东有时会觉得，伯克希尔可能远不是他们能做出的最佳选择。但他们会补充说，伯克希尔在他们最满意的公司中已经排名非常靠前。
平均而言，那些对自己的投资感到满意的人，会比那些被不断变化的新闻、传言和承诺所影响的人会取得更好的结果。
长期个人股东既是我和查理一直寻求的“合作伙伴”，也是我们在伯克希尔做出决策时一直考虑的目标群体。
我们想对他们说：“为你们‘工作’感觉很好，非常感谢你们的信任。”
年度股东大会 日期已经确定！伯克希尔将于4月29日星期五至5月1日星期日在奥马哈举行年度股东大会。详细情况见A-1和A-2页。奥马哈和我都热切期待你们的到来。
在这封信的结尾，我顺便打个广告。“表弟”吉米·巴菲特设计了一艘浮筒式“派对”游艇，目前由伯克希尔的子公司Forest River制造。这艘船将于4月29日在伯克希尔股东大会上发布。限时两天内，股东们可以以10%的折扣购买吉米的杰作。你们的董事长会买一艘给家人使用，快加入我们吧。
2022年2月26日 沃伦·巴菲特</content></entry><entry><title>OpenResty中的lua协程</title><url>https://lizj3624.github.io/post/ngx_lua/</url><categories><category>OpenResty</category><category>nginx</category><category>ngx_lua</category></categories><tags><tag>OpenResty</tag><tag>nginx</tag><tag>ngx_lua</tag></tags><content type="html"> OpenResty是一个基于nginx与Lua的高性能Web平台，其内部集成了大量精良的Lua库、第三方模块以及大多数的依赖项。 用于方便地搭建能够处理超高并发、扩展性极高的动态Web应用、Web服务和动态网关。 研究和学习ngx_lua以及lua协程对理解OpenResty源码很有帮助, 收集一些ngx_lua源码讲解的文章。
ngx_lua nginx是事件驱动的异步处理方式，Lua语言本身是同步处理，但是Lua原生支持协程，给nginx与Lua的结合提供了机会。
nginx可以同时处理数以万计的网络连接，Lua可以同时存在很多协程，简单一点想，对每个到来的网络连接，创建一个新的协程去处理，处理完毕后释放协程。 和Apache为每个连接fork一个进程处理的流程十分相似，只不过多个进程换成了多个协程。
协程相比较进程占用资源很小，协程之间的切换性能消耗非常小，几乎就相当于函数调用一样。以同步的方式写程序，实现了异步处理的效率。当然实际的编程实现并没有多进程那么简单。
在Lua中，每个协程对应有一个lua_State结构体， 这个结构体中保存了协程的所有信息。所有的协程共享一个global_State结构体，这个结构体保存全局相关的一些信息，主要是所有需要垃圾回收的对象。
通常创建Lua执行环境都是从lua_open(即luaL_newstate)开始, lua_open会创建一个global_State结构，创建一个协程作为主协程ngx_http_lua_module是在读取配置后的postconfiguration阶段创建Lua环境的， 除此之外还做了一个额外的操作，主要是创建了名为ngx，类型为table的全局变量，所有Lua与nginx的交互都是通过ngx这个全局变量来实现的，如ngx.sleep, ngx.socket等方法都在这个的table中。
nginx中请求的处理是分阶段的，ngx_http_lua_module在多个阶段挂载了回调函数，这里ngx_lua的图. 在rewrite, access 等多个阶段，都有相应的*_by_lua*处理。
这里以access阶段为例。先通过ngx_http_lua_get_lua_vm获取主协程的lua_State结构体L，再通过ngx_http_lua_cache_loadbuffer获取解析后的lua代码， 然后通过ngx_http_lua_access_by_chunk执行lua代码。
ngx_int_t ngx_http_lua_access_handler_inline(ngx_http_request_t *r) { ngx_int_t rc; lua_State *L; ngx_http_lua_loc_conf_t *llcf; llcf = ngx_http_get_module_loc_conf(r, ngx_http_lua_module); L = ngx_http_lua_get_lua_vm(r, NULL); /* load Lua inline script (w/ cache) sp = 1 */ rc = ngx_http_lua_cache_loadbuffer(r->connection->log, L, llcf->access_src.value.data, llcf->access_src.value.len, llcf->access_src_key, (const char *) llcf->access_chunkname); if (rc != NGX_OK) { return NGX_HTTP_INTERNAL_SERVER_ERROR; } return ngx_http_lua_access_by_chunk(L, r); } 在balancer_by_lua*, header_filter_by_lua*, body_filter_by_lua, log_by_lua阶段中，直接在主协程中执行代码，而在access，content等其他几个阶段中，会创建一个新的协程去执行此阶段的lua代码。表现在API层面，两者的区别就是能否执行ngx.sleep, ngx.socket, ngx.thread这几个命令。
Lua中的协程可以随时挂起，一段时间后继续运行。在access等阶段会新建协程， 新的协程只处理一个请求，可以方便的挂起来，不会影响其他的协程。而在log阶段没有创建新的协程，主协程是不能执行ngx.sleep等阻塞操作的。
Lua中的协程也是GC对象，会被系统进行垃圾回收时销毁掉，为了保证挂起的协程不会被GC掉，ngx_http_lua_module在全局的注册表中创建了一个table，新创建的协程保存在table中，协程执行完毕后从table中注销，GC时就会将已注销的协程回收掉。
ngx_http_lua_module初始Lua运行环境时，执行ngx_http_lua_init_registry函数，在注册表创建了几个table，key为ngx_http_lua_coroutines_key的table保存所有的协程。
static void ngx_http_lua_init_registry(lua_State *L, ngx_log_t *log) { ngx_log_debug0(NGX_LOG_DEBUG_HTTP, log, 0, "lua initializing lua registry"); /* register a table to anchor lua coroutines reliably: **/ lua_pushlightuserdata(L, &amp;ngx_http_lua_coroutines_key); lua_createtable(L, 0, 32 /* nrec */); lua_rawset(L, LUA_REGISTRYINDEX); /* create the registry entry for the Lua request ctx data table */ lua_pushliteral(L, ngx_http_lua_ctx_tables_key); lua_createtable(L, 0, 32 /* nrec */); lua_rawset(L, LUA_REGISTRYINDEX); /* create the registry entry for the Lua socket connection pool table */ lua_pushlightuserdata(L, &amp;ngx_http_lua_socket_pool_key); lua_createtable(L, 0, 8 /* nrec */); lua_rawset(L, LUA_REGISTRYINDEX); #if (NGX_PCRE) /* create the registry entry for the Lua precompiled regex object cache */ lua_pushlightuserdata(L, &amp;ngx_http_lua_regex_cache_key); lua_createtable(L, 0, 16 /* nrec */); lua_rawset(L, LUA_REGISTRYINDEX); #endif lua_pushlightuserdata(L, &amp;ngx_http_lua_code_cache_key); lua_createtable(L, 0, 8 /* nrec */); lua_rawset(L, LUA_REGISTRYINDEX); } nginx中处理请求都是围绕ngx_http_request_t结构体进行了，一个ngx_http_request_t结构体代表了当前正在处理的一个请求。 ngx_http_lua_module处理Lua脚本时要与nginx进行交互，也要通过这个结构体实现。 为此在创建新的协程后，将相关联的ngx_http_request_t的指针保存在了lua_State的全局变量中。
如下所示，通过ngx_http_lua_set_req将请求与协程关联。
static ngx_inline void ngx_http_lua_set_req(lua_State *L, ngx_http_request_t *r) { lua_pushlightuserdata(L, r); lua_setglobal(L, ngx_http_lua_req_key); } 通过ngx_http_lua_get_req从lua_State中获取协程关联的请求。
static ngx_inline ngx_http_request_t * ngx_http_lua_get_req(lua_State *L) { ngx_http_request_t *r; lua_getglobal(L, ngx_http_lua_req_key); r = lua_touserdata(L, -1); lua_pop(L, 1); return r; } 下面这个是ngx.get_method的API的实现，很简单的逻辑，通过ngx_http_lua_get_req获取请求的ngx_http_request_t结构体， 从结构体中把代表请求方法字符串返回。ngx_http_lua_module提供的API大都通过这种方式来实现。
static int ngx_http_lua_ngx_req_get_method(lua_State *L) { int n; ngx_http_request_t *r; n = lua_gettop(L); if (n != 0) { return luaL_error(L, "only one argument expected but got %d", n); } r = ngx_http_lua_get_req(L); if (r == NULL) { return luaL_error(L, "request object not found"); } ngx_http_lua_check_fake_request(L, r); lua_pushlstring(L, (char *) r->method_name.data, r->method_name.len); return 1; } 引用参考文章 ngx_lua中的lua协程
OpenResty讲解
OpenResty中ngx_lua
OpenResty精华整理</content></entry><entry><title>nginx epoll惊群</title><url>https://lizj3624.github.io/post/ngx-epoll/</url><categories><category>nginx</category><category>epoll</category></categories><tags><tag>nginx</tag><tag>epoll</tag></tags><content type="html"> nginx是目前比较流行的高性能的负载均衡，反向代理，静态web服务器，它的高性能主要是基于epoll(Linux)的事件框架。
nginx是开源，我们可以通过阅读源码分析它的epoll事件的实现。 还有epoll存在惊群的问题，看看nginx是如何解决的这个问题的。 从网络上收集整理一些资料，在此汇总一下，以便查阅。
惊群现象 首先，我们看看维基百科对惊群的定义,简而言之， 惊群现象（thundering herd）就是当多个进程和线程在同时阻塞等待同一个事件时，如果这个事件发生，会唤醒所有的进程， 但最终只可能有一个进程/线程对该事件进行处理，其他进程/线程会在失败后重新休眠，这种性能浪费就是惊群。
accept惊群 考虑如下场景：
主进程创建socket、bind、 listeni之后，fork出多个子进程，每个子进程都开始循环处理accept这个socket。 每个进程都阻塞在accpet上，当一个新的连接到来时，所有的进程都会被唤醒，但其中只有一个进程会accept成功， 其余皆失败，重新休眠。这就是accept惊群。
那么这个问题真的存在吗？
事实上，历史上，Linux的accpet确实存在惊群问题，但现在的内核都解决该问题了。即当多个进程/线程都阻塞在对同一个socket的accept调用上时， 当有一个新的连接到来，内核只会唤醒一个进程，其他进程保持休眠，压根就不会被唤醒。
测试验证代码:
#include &lt;sys/types.h>#include &lt;sys/socket.h>#include &lt;netinet/in.h>#include &lt;sys/wait.h>#include &lt;stdio.h>#include &lt;string.h>#define PROCESS_NUM 10 int main() { int fd = socket(PF_INET, SOCK_STREAM, 0); int connfd; int pid; char sendbuff[1024]; struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = htonl(INADDR_ANY); serveraddr.sin_port = htons(1234); bind(fd, (struct sockaddr*)&amp;serveraddr, sizeof(serveraddr)); listen(fd, 1024); int i; for(i = 0; i &lt; PROCESS_NUM; i++) { int pid = fork(); if(pid == 0) { while(1) { connfd = accept(fd, (struct sockaddr*)NULL, NULL); snprintf(sendbuff, sizeof(sendbuff), "accept PID is %d\n", getpid()); send(connfd, sendbuff, strlen(sendbuff) + 1, 0); printf("process %d accept success!\n", getpid()); close(connfd); } } } int status; wait(&amp;status); return 0; } 当我们对该服务器发起连接请求（用 telnet/curl 等模拟）时，会看到只有一个进程被唤醒。
关于 accept 惊群的一些帖子或文章：
Does the Thundering Herd Problem exist on Linux anymore? 历史上解决 linux accept 惊群的补丁讨论 其实，在linux2.6内核上，accept系统调用已经不存在惊群了（至少我在2.6.18内核版本上已经不存在）
epoll惊群 如上所述，accept已经不存在惊群问题，但epoll上还是存在惊群问题。即如果多个进程/线程阻塞在监听同一个listening socket fd的epoll_wait上， 当有一个新的连接到来时，所有的进程都会被唤醒。
考虑如下场景：
主进程创建socket、bind、 listen后，将该socket加入到epoll中，然后 fork出多个子进程，每个进程都阻塞在epoll_wait上，如果有事件到来， 则判断该事件是否是该socket上的事件，如果是说明有新的连接到来了，则进行accept操作。为了简化处理， 忽略后续的读写以及对accept返回的新的套接字的处理，直接断开连接。
那么，当新的连接到来时，是否每个阻塞在epoll_wait上的进程都会被唤醒呢？
很多博客中提到，测试表明虽然epoll_wait 不会像accept那样只唤醒一个进程/线程，但也不会把所有的进程/线程都唤醒。 例如这篇文章：关于多进程 epoll 与 “惊群”问题。
测试验证代码:
#include &lt;sys/types.h>#include &lt;sys/socket.h>#include &lt;sys/epoll.h>#include &lt;netdb.h>#include &lt;string.h>#include &lt;stdio.h>#include &lt;unistd.h>#include &lt;fcntl.h>#include &lt;stdlib.h>#include &lt;errno.h>#include &lt;sys/wait.h>#define PROCESS_NUM 10 static int create_and_bind (char *port) { int fd = socket(PF_INET, SOCK_STREAM, 0); struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = htonl(INADDR_ANY); serveraddr.sin_port = htons(atoi(port)); bind(fd, (struct sockaddr*)&amp;serveraddr, sizeof(serveraddr)); return fd; } static int make_socket_non_blocking (int sfd) { int flags, s; flags = fcntl (sfd, F_GETFL, 0); if (flags == -1) { perror ("fcntl"); return -1; } flags |= O_NONBLOCK; s = fcntl (sfd, F_SETFL, flags); if (s == -1) { perror ("fcntl"); return -1; } return 0; } #define MAXEVENTS 64 int main (int argc, char *argv[]) { int sfd, s; int efd; struct epoll_event event; struct epoll_event *events; sfd = create_and_bind("1234"); if (sfd == -1) abort (); s = make_socket_non_blocking (sfd); if (s == -1) abort (); s = listen(sfd, SOMAXCONN); if (s == -1) { perror ("listen"); abort (); } efd = epoll_create(MAXEVENTS); if (efd == -1) { perror("epoll_create"); abort(); } event.data.fd = sfd; //event.events = EPOLLIN | EPOLLET; event.events = EPOLLIN; s = epoll_ctl(efd, EPOLL_CTL_ADD, sfd, &amp;event); if (s == -1) { perror("epoll_ctl"); abort(); } /* Buffer where events are returned */ events = calloc(MAXEVENTS, sizeof event); int k; for(k = 0; k &lt; PROCESS_NUM; k++) { int pid = fork(); if(pid == 0) { /* The event loop */ while (1) { int n, i; n = epoll_wait(efd, events, MAXEVENTS, -1); printf("process %d return from epoll_wait!\n", getpid()); /* sleep here is very important!*/ //sleep(2); for (i = 0; i &lt; n; i++) { if ((events[i].events &amp; EPOLLERR) || (events[i].events &amp; EPOLLHUP) || (!(events[i].events &amp; EPOLLIN))) { /* An error has occured on this fd, or the socket is not ready for reading (why were we notified then?) */ fprintf (stderr, "epoll error\n"); close (events[i].data.fd); continue; } else if (sfd == events[i].data.fd) { /* We have a notification on the listening socket, which means one or more incoming connections. */ struct sockaddr in_addr; socklen_t in_len; int infd; char hbuf[NI_MAXHOST], sbuf[NI_MAXSERV]; in_len = sizeof in_addr; infd = accept(sfd, &amp;in_addr, &amp;in_len); if (infd == -1) { printf("process %d accept failed!\n", getpid()); break; } printf("process %d accept successed!\n", getpid()); /* Make the incoming socket non-blocking and add it to the list of fds to monitor. */ close(infd); } } } } } int status; wait(&amp;status); free (events); close (sfd); return EXIT_SUCCESS; } 发现确实如上面那篇博客里所说，当我模拟发起一个请求时，只有一个或少数几个进程被唤醒了。
也就是说，到目前为止，还没有得到一个确定的答案。但后来，在下面这篇博客中看到这样一个评论
这个总结，需要进一步阐述，看上去是只有4个进程唤醒了，而事实上，其余进程没有被唤醒的原因是你的某个进程已经处理完这个accept，内核队列上已经没有这个事件， 无需唤醒其他进程。你可以在epoll获知这个accept事件的时候，不要立即去处理，而是sleep下，这样所有的进程都会被唤起。
看到这个评论后，我顿时如醍醐灌顶，重新修改了上面的测试程序，即在epoll_wait返回后，加了个sleep语句，这时再测试，果然发现所有的进程都被唤醒了。
所以，epoll_wait上的惊群确实是存在的。
为什么Kernel不处理Epoll惊群 看到这里，我们可能有疑惑了，为什么内核对accept的惊群做了处理，而现在仍然存在epoll的惊群现象呢？
我想，应该是这样的：
accept确实应该只能被一个进程调用成功，内核很清楚这一点。但epoll不一样，他监听的文件描述符，除了可能后续被accept调用外，还有可能是其他网络IO事件的， 而其他IO事件是否只能由一个进程处理，是不一定的，内核不能保证这一点，这是一个由用户决定的事情，例如可能一个文件会由多个进程来读写。所以对epoll的惊群，内核则不予处理。
nginx解决惊群的方法 nginx的epoll框架 nginx主进程解析配置，将listen指令初始化到全局变量ngx_cycle的listening数组之中。此时监听套接字的创建、绑定工作早已完成。
nginx主进程fork出多个子进程(worker进程), 每个子进程执行ngx_worker_process_init, 为每个子进程创建epoll句柄。
每个子进程执行ngx_process_events_and_timers，这就进入到事件处理的核心逻辑了，如果开启 accept_mutex，每个进程争抢锁, epoll_wait等待处理网络事件。
accept_mutex锁 如果开启了accept_mutex锁，每个worker都会先去抢自旋锁，只有抢占成功了，才把socket加入到epoll中，accept请求后释放锁, accept_mutex锁也有负载均衡的作用。 accept_mutex效率低下，特别是在长连接的时候。因为长连接时，一个进程长时间占用accept_mutex锁，使得其它进程得不到accept的机会。因此不建议使用，默认是关闭的。
EPOLLEXCLUSIVE标识 EPOLLEXCLUSIVE是4.5+内核新添加的一个epoll的标识，Ngnix 在1.11.3之后添加了NGX_EXCLUSIVE_EVENT。 EPOLLEXCLUSIVE标识会保证一个事件发生时候只有一个线程会被唤醒，以避免多侦听下的“惊群”问题。 不过任一时候只能有一个工作线程调用accept，限制了真正并行的吞吐量。
SO_REUSEPORT 选项 SO_REUSEPORT是惊群最好的解决方法，Ngnix在1.9.1中加入了这个选项，每个worker都有自己的socket，这些socket都bind同一个端口。 当新请求到来时，内核根据四元组信息进行负载均衡，非常高效。
Linux 3.9版本的内核对reuseport做了支持，在4.6版本内核做了优化，详细参看关于Linux UDP/TCP reuseport 二三事
总结 现在我们对惊群及Nginx的处理总结如下：
accept不会有惊群，epoll_wait才会。
Nginx的accept_mutex，并不是解决accept惊群问题，而是解决epoll_wait惊群问题。
说Nginx解决了epoll_wait惊群问题，也是不对的，它只是控制是否将监听套接字加入到epoll中。 监听套接字只在一个子进程的epoll中，当新的连接来到时，其他子进程当然不会惊醒了。
引用文章 accept与epoll惊群
Nginx是如何解决epoll惊群的
“惊群”，看看nginx是怎么解决它的
关于Linux UDP/TCP reuseport 二三事
重新实现reuseport逻辑，实现一致性哈希</content></entry><entry><title>区块链加密货币入门</title><url>https://lizj3624.github.io/post/blockchain/</url><categories><category>blockchain</category></categories><tags><tag>blockchain</tag><tag>bitcoin</tag><tag>cryptocurrency</tag></tags><content type="html"> 2008年10月31号加密hacker中本聪发表了比特币白皮书，2009年1月3日，创世区块诞生，比特币诞生， 区块链和加密货币的大门被打开，区块链加密货币经过10多年的发展已经被很多人所接受，现在还是发展初级阶段，未来大有可为，从现在开始学习区块链技术，今年争取拥有加密货币资产。
Bitcoin 比特币是有加密hacker中本聪由2009年1月3号创建。
比特币白皮书
精通比特币
比特币生态资源
Ethereum 以太坊是由维塔利克·布特林(V神)2013年提出的，发表了以太坊白皮书，支持智能合约。
以太坊白皮书
精通以太坊
以太坊生态资源
IPFS 星际文件系统(IPFS)是一个旨在实现文件的分布式存储、共享和持久化的网络传输协议，文件币(filecoin)。
IPFS Polkadot 波卡是由以太坊前CTO，以太坊黄皮书作者Gavin Wood博士创建，支持跨链。
波卡 Solana solana NFT NFT(非同质化代币)是一种被称为区块链数字账本上的数据单位，每个代币可以代表一个独特的数字资料，作为虚拟商品所有权的电子认证或证书。
OpenSea
NFT School
NFT Storage
DeFi 去中心化金融（英语：Decentralized finance，俗称DeFi）是一种创建于区块链上的金融，它不依赖券商、交易所或银行等金融机构提供金融工具，而是利用区块链上的智能合约（例如以太坊）进行金融活动。
DeFi Pulse
Compound
ENS 以太坊域名服务（Ethereum Name Service）是一个基于以太坊区块链的分布式、开放和可扩展的命名系统。 通俗地说，ENS就是区块链中的域名系统。 ENS 域名让人们没有必要再复制或输入冗长的区块链地址。
ENS
ENS中文介绍
Web3.0 图片引用indigo公众号</content></entry><entry><title>Kubernetes入门</title><url>https://lizj3624.github.io/post/kubernetes-primer/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag><tag>k8s</tag><tag>cloudnative</tag></tags><content type="html"> 以容器(docker)和容器编排(kubernetes)的云原生技术栈在后端开发中越来越重要，每个技术童鞋都有必要熟悉这个技术栈
kubernetes入门 kubernetes的核心组件 API Server API server 的核心功能是提供k8s各类资源对象(如Pod、RC、Service)的增删改查及Watch等HTTP REST接口，成为集群内各个功能模块之间数据交互和通信的中心枢纽，是整个集群的数据总线和数据中心，运行在master节点。 通常还具有以下功能。
集群管理的API入口 资源配额控制的入口 提供了完备的集群安全机制。 通常我们会通过kubectl命令与API server进行交互，提供restful API，所以说也可以通过代码方式直接调用k8s的API server。
控制器管理器(controller-manager) controller-manager作为集群内部的管理控制中心，负责集群内部的Node、Pod、Endpoint、Namespace、ServiceAccount、ResourceQuota等的管理，意为控制器，运行在master节点。
ReplicaSet Controller(副本控制器): 管理控制 pod 副本（服务集群）的数量，以使其永远与预期设定的数量保持一致。 Endpoint Controller(节点控制器): Endpoint用来表示kubernetes集群中Service对应的后端Pod副本的访问地址，Endpoint Controller则是用来生成和维护Endpoints对象的控制器，其主要负责监听Service和对应Pod副本变化。 Deployment Controller(部署控制器): Deployment中文意思为部署、调度，通过Deployment我们能操作RS（ReplicaSet） StatefulSet Controller(状态控制器): StatefulSet的出现是K8S为了解决 “有状态” 应用落地而产生的，Stateful这个单词本身就是“有状态”的意思 DaemonSet Controller(收回控制器): Daemon本身就是守护进程的意思，那么很显然DaemonSet就是K8S里实现守护进程机制的控制器 Job Controller(任务控制器): 在K8S里运行批处理任务我们用Job即可 CronJob Controller(cronjob控制器): 定时任务 调度器(scheduler) kube-scheduler意为调度器，在集群承担了"承上启下"的重要功能，“承上”指的是它负责接收 Controller -manager创建的新Pod。为其安排一个可以安置的node;“启下”指的是安置完成之后，目前Node上的kubelet服务进程接管后继续工作，负责Pod生命周期中的下半生。
kubelet 一个在集群中每个节点(node)上运行的代理。 它保证容器(containers)都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。
kube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务(Service) 概念的一部分。
etcd 存储数据
kubernetes的请求流程 Pod Pod可以理解为是一组功能相同的容器，装的是docker创建的容器，也就是用来封装容器的一个容器； Pod 是一个虚拟化分组，有自己的IP地址和主机名hostname，利用namespace 进行资源隔离，相当于一台独立沙箱环境； Pod 相当于一台独立主机，内部可以封装一个或多个容器(通常是一组相关的容器)，内部容器之间访问采用 localhost。 Pod可以理解为豌豆荚
Service Kubernetes Service定义了逻辑上的一组Pod的抽象，可以通过一定策略访问这个Service, 我们一般称为微服务。 Service所针对的Pods集合通常是通过选择算符(标签选择器)来确定的， Pod经常被创建和销毁，IP地址不固定，Service定义一组逻辑上的一组Pod的抽象，通过kube-proxy自动分配一个集群内部可以访问的虚IP，称为cluster IP。
在 Kubernetes 中，可以通过 Cluster Ip 来找到 Pod 的访问规则，但是 Cluster Ip 不好记啊，所以 Kuberbetes 提供了一个 CoreDns 的组件来对 Service 进行解析。 CoreDns 是一个DNS服务器，每当有Service创建时，都会在DNS服务里面增加一条记录。集群中的Pod可以通过&lt;SERVICE_NAME>.&lt;NAMESPACE_NAME>访问Service
dig codereviewapi Server: 10.96.0.10 Address: 10.96.0.10:53 Name: codereviewapi.codereview.svc.cluster.local Address: 10.111.72.52 Kubernetes Service对外暴露服务通过NodePort、LoadBalancer和ExternalName
NodePort：建立在ClusterIP类型之上，其在每个Node的IP地址的某静态端口（NodePort）暴露服务，NodePort的路由目标为ClusterIP，简单来说，NodePort类型就是在工作节点的IP地址上选择一个端口用于将集群外部的用户请求转发至目标Service的ClusterIP和Port，这种类型的Service既可如ClusterIP一样受到集群内部客户端Pod的访问，也会受到集群外部客户端通过套接字NodeIP:NodePort进行的请求；
LoadBalancer：建构在NodePort类型之上，其通过cloud provider提供的负载均衡器将服务暴露到集群外部，LoadBalancer类型的Service会指向关联至Kubernetes集群外部的某个负载均衡设备，该设备通过工作节点之上的NodePort向集群内部发送请求流量，这种Service的优势在于，能够把来自于集群外部客户端的请求调度至所有节点（或部分节点）的NodePort之上，而不是依赖于客户端自行决定连接至哪个节点，从而避免了因客户端指定的节点故障而导致的服务不可用；
ExternalName：通过将Service映射至由externalName字段的内容指定的主机名来暴露服务，此主机名需要被DNS服务解析至CNAME类型的记录。这种类型并非定义由Kubernetes集群提供的服务，而是把集群外部的某服务以DNS CNAME记录的方式映射到集群内，从而让集群内的Pod资源能够访问外部的Service的一种实现方式，这种类型的Service没有ClusterIP和NodePort，也没有标签选择器用于选择Pod资源。
Ingress Service对集群之外暴露服务的主要方式有两种：NodePort和LoadBalancer，但是这两种方式，都有一定的缺点：
NodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显。
LoadBalancer的缺点是每个Service都需要一个LB，浪费，麻烦，并且需要kubernetes之外的设备的支持。
Ingress相当于一个七层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解为Ingress里面建立了诸多映射规则，Ingress Controller通过监听这些配置规则并转化为Nginx的反向代理配置，然后对外提供服务。</content></entry><entry><title>Docker常用的命令</title><url>https://lizj3624.github.io/post/docker-cmd/</url><categories><category>docker</category></categories><tags><tag>docker</tag></tags><content type="html"> 一、汇总： Docker环境信息 — docker [info|version] 容器生命周期管理 — docker [create|exec|run|start|stop|restart|kill|rm|pause|unpause] 容器操作运维 — docker [ps|inspect|top|attach|wait|export|port|rename|stat] 容器rootfs命令 — docker [commit|cp|diff] 镜像仓库 — docker [login|pull|push|search] 本地镜像管理 — docker [build|images|rmi|tag|save|import|load] 容器资源管理 — docker [volume|network] 系统日志信息 — docker [events|history|logs] 常用命令的含义：
1、docker命令介绍 docker --help 管理命令: container 管理容器 image 管理镜像 network 管理网络
命令： attach 介入到一个正在运行的容器 build 根据Dockerfile构建一个镜像 commit 根据容器的更改创建一个新的镜像 cp 在本地文件系统与容器中复制 文件/文件夹 create 创建一个新容器 exec 在容器中执行一条命令 images 列出镜像 kill 杀死一个或多个正在运行的容器
logs 取得容器的日志 pause 暂停一个或多个容器的所有进程 ps 列出所有容器 pull 拉取一个镜像或仓库到registry push 推送一个镜像或仓库到registry rename 重命名一个容器 restart 重新启动一个或多个容器 rm 删除一个或多个容器 rmi 删除一个或多个镜像 run 在一个新的容器中执行一条命令 search 在Docker Hub中搜索镜像 start 启动一个或多个已经停止运行的容器 stats 显示一个容器的实时资源占用 stop 停止一个或多个正在运行的容器 tag 为镜像创建一个新的标签 top 显示一个容器内的所有进程 unpause 恢复一个或多个容器内所有被暂停的进程
docker info #查看系统(docker)层面信息，包括管理的images, containers数等 docker version #查看docker的版本号，包括客户端、服务端、依赖的Go等 二、镜像相关 1、拉取镜像 # docker pull &lt;image> 从docker registry server 中下拉image docker pull nginx 2、查看镜像 docker images ##过滤掉中间镜像（现有镜像的父镜像） docker images -a ##列出所有的images 3、推送镜像 docker push &lt;image|repository> #推送一个image或repository到registry docker push &lt;image|repository>:TAG #同上，指定tag 4、删除镜像 docker rmi 常用参数：
-f：强制删除运行中的容器
5、创建镜像 （1）对源镜像更改后重新建立新镜像
docker commit &lt;container> [repo:tag] ##将一个container固化为一个新的image，后面的repo:tag可选 常用参数：
-m：本次提交信息
--author="" ：作者
（2）使用Dockerfile文件来构建镜像
docker build 常用参数：
-t x/y:z：指定镜像的命名空间为x，仓库为y，tag为z 6、搜索镜像 docker search nginx 7、登录远端镜像仓库 docker login --username=yourhubusername --email=youremail@company.com 8、查看镜像底层信息 docker inspect &lt;image|container> ##查看image或container的底层信息 9、镜像导入和导出 ##快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。 docker save ##保存的是镜像（image），docker export 保存的是容器（container）； docker load ##用来载入镜像包，docker import 用来载入容器包，但两者都会恢复为镜像； docker load ##不能对载入的镜像重命名，而 docker import 可以为镜像指定新名称，如： docker import ubuntu.tar merge_gt/ubuntu:v1(新名称)。 三、容器相关 1、运行容器 docker run 常用参数：
--name:为容器指定名称
-it:启动一个交互型容器，此参数为我们和容器提供了一个交互shell
-d:创建后台型容器
-restart=always:容器退出后自动重启
-restart=on-failure:x:容器退出时如果返回值是非0，就会尝试重启x次
-p x:y :主机端口：容器端口
-P：随机分配一个49000到49900的端口
-v：创建数据卷
-n :指定dns
-h : 指定容器的hostname
-e ：设置环境变量
-m :设置容器使用内存最大值
--net: 指定容器的网络连接类型，支持bridge/host/none/container
--link=x: 添加链接到另一个容器x
--expose=x: 开放端口x
这里docker create和docker run -it创建的容器都是交互型容器
2、查看正在运行的容器 docker ps 常用参数： -a：查看所有容器 -l:只列出最近创建的 -n=x:只列出最后创建的x个 -q: 只列出容器id
3、停止容器 docker stop ##方式较温柔，慢慢的停止容器的运行 docker kill ##方式简单粗暴，立即停止容器运行 docker start/stop/restart &lt;container> ##开启/停止/重启container docker start -i &lt;container> ##启动一个container并进入交互模式 4、删除容器 docker rm &lt;container...> ##删除一个或多个container docker rm `docker ps -a -q` ##删除所有的container docker ps -a -q | xargs docker rm ##同上, 删除所有的container 常用参数： -f：强制删除运行中的容器
5、查看容器日志 docker logs &lt;container> ###查看container的日志，也就是执行命令的一些输出 常用参数： -f：实时查看日志 --tail=x:查看最后x行 -t:查看日志产生的时间
6、查看容器进程 docker top 7、查看容器配置信息 docker inspect 常用参数：
-f='{{x}}'：查看x配置 8、进入容器 （1）进入交互型容器
docker attch （2）进入后台型容器
docker exec 常用参数： -it 容器id /bin/bash：进入到后台容器
9、使用docker cp将文件从本地复制到容器 docker cp index.html hardcore_torvalds:usr/share/nginx/html/ 四、dockerfile 1、docker build docker build &lt;path> ##寻找path路径下名为的Dockerfile的配置文件，使用此配置生成新的image docker build -t repo[:tag] ##同上，可以指定repo和可选的tag docker build - &lt; &lt;dockerfile> ###使用指定的dockerfile配置文件，docker以stdin方式获取内容，使用此配置生成新的image 2、常用命令 FROM命令: 既然我们是在原有的centos镜像的基础上做定制，那么我们的新镜像也一定是需要以centos这个镜像为基础的，而FROM命令则代表了这个意思，在DockerFile中，基础镜像是必须指定的，FROM指令的作用就是指定基础镜像，因此一个DockerFile中,FROM是必备的指令，而且就像java，python的import关键字一样，在DockerFile中，FROM指令必须放在第一条指令的位置
当然，这个时候可能有朋友会问了，我要是不想在其他的镜像上定制镜像怎么办呢，没问题啊，Docker 提供了scratch 这个虚拟镜像，如果你选择 FROM scratch 的话，则意味着你不以任何镜像为基础，接下来所写的指令将作为镜像的第一层开始存在，当然，在某些情况下，比如linux下静态编译的程序，运行的时候不需要操作系统提供运行时的支持，这个时候FROM scratch 是没有问题的，反而会大幅降低我们的镜像体积。
ENV指令 功能：设置环境变量
同样的，DockerFile也提供了两种格式：
ENV key value ENV key1=value1 key2=value2 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN， 还是运行时的应用，都可以直接使用这里定义的环境变量。
可以看到我们示例中使用ENV设置mypath变量之后，在下一行WORKDIR则使用到了mypath这个变量
ENV mypath /tmp ##设置环境变量 WORKDIR $mypath ###指定工作目录 WORKDIR 指令： 功能，指定工作目录
格式为：WORKDIR 工作目录路径，如果这个目录不存在的话，WORKDIR则会帮助我们创建这个目录。
设置过工作目录之后，当我们启动容器，会直接进入该工作目录
[root@8081304919c9 tmp]# RUN命令: RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令也是在定制镜像时是较为常用的指令之一。
RUN命令的格式一共有两种，分别是:
Shell格式
RUN``命令，就像直接在命令行中输入命令一样，比如RUN yum -y install vim`就是使用的这种格式
exec格式
RUN[&ldquo;可执行文件&rdquo;,&ldquo;参数1&rdquo;,&ldquo;参数2&rdquo;]，感觉就像调用函数一样
就像我们在上一篇文章中说过的那样，DockerFile中每一条指令都会建立一层，比如我们上面执行过下面这条命令
RUN yum -y install vim 执行结束之后，则调用commit提交这一层的修改，使之构成一个新的镜像，怎么样，是不是豁然开朗了呢。
同样的，Dockerfile支持Shell类的行尾添加 \的命令换行方式，以 及行首#进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。
提示：
如果使用apt方式安装的话，最后不要忘记清理掉额外产生的apt缓存文件，如果不清理的话会让我们的镜像显得非常臃肿。因为DockerFile生成一层新的镜像的时候，并不会删除上一层镜像所残留的文件。
EXPOSE指令： 功能：声明端口
格式： EXPOSE 端口1 端口2
EXPOSE 指令是声明运行时容器提供服务端口，这当然只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。这样声明主要是为了方便后期我们配置端口映射。
CMD指令： 之前介绍容器的时候曾经说过，Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。
同样的，DockerFile也为我们提供了两种格式来使用CMD命令:
shell格式：CMD命令 exec 格式：CMD ["可执行文件", "参数 1", "参数 2"...] 示例中，我们使用的是第一种：
CMD /bin/bash 这条指令带来的效果就是，当我们通过run -it 启动命令的时候，容器会自动执行/bin/bash，centos默认也是CMD /bin/bash，所以当我们运行centos镜像的时候，会自动进入bash环境里面。
当然，我们也可以通过运行时指定命令的方式来体换默认的命令，比如:
docker run -it centos cat /etc/os-release 这样当我们运行镜像的时候，cat /etc/os-release就会替代默认的CMD /bin/bash输出系统的版本信息了。
如果使用shell格式的话， 实际的命令会被包装为sh -c的参数的形式进行执行。
比如：
CMD echo $HOME 在实际执行中，会将其变更为
CMD [ "sh", "-c", "echo $HOME" ] 当然还有很多初学者特别容易犯的问题，就是去启动后台服务，比如:
CMD service nginx start 这样子去用，会发现容器运行了一会就自动退出了。
我们之前不止一次的提醒过，容器不是虚拟机，容器就是进程，容器内的应用都应该以前台运行，而不是像虚拟机，物理机那样去运行后台服务，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。
怎么理解呢？想想偶像剧，容器是女主角，主进程是男主角
你走了，我也不活了（撕心裂肺大哭），大概就是这么个意思。
正如我们前面所提出的，实际上CMD service nginx start最终会被理解为：
CMD [ "sh", "-c", "service nginx start"] 在这里，我们主进程实际就是sh，当我们service nginx start执行完毕之后，那么sh自然就会退出了，主进程退出，容器自然就会相应的停止。争取的做法是直接执行nginx可执行文件，并且声明以前台的形式运行:
CMD ["nginx", "-g", "daemon off;"] 到这里，我们示例中所涉及到的命令已经讲完了，当然，这并不够，Docker中仍然有很多命令是我们使用比较频繁的，下面我们的部分作为补充，讲一下其他常用的DockerFile命令。
COPY 命令: 功能:复制文件
Docker依旧提供了两种格式供我们选择:
COPY [&ndash;chown=:] &lt;源路径>&hellip; &lt;目标路径> COPY [&ndash;chown=:] ["&lt;源路径 1>",&hellip; &ldquo;&lt;目标路径>"] 到这里大家其实会发现，Docker提供的两种格式其实都是差不多的用法，一种类似于命令行，一种则类似于函数调用。
第一种例如(将package.json拷贝到/usr/src/app/目录下):
COPY package.json /usr/src/app/ 其次，目标路径 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径 ，工作目录可以用 WORKDIR 指令来指定，如果需要改变文件所属的用户或者用户组，可以加上&ndash;chown 选项。
需要注意的是，使用 COPY 指 令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这 个特性对于镜像定制很有用。
ADD命令： ADD命令可以理解为COPY命令的高级版，格式和用法与COPY几乎一致，ADD在COPY的基础上增加了一些功能，比如源路径可以是一个URL链接，当你这么用的时候，Docker会尝试着先将该URL代表的文件下载下来，然后复制到目标目录上去，其他的则是在COPY的基础上增加了解压缩之类的操作，码字码的手疼，需要了解的朋友可以去官网查看相关的文档，这里我就不延申了。
VOLUME 定义匿名卷: 在上一篇中，我们有讲容器卷这个概念，为了防止运行时用户忘记 将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些 目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运 行，不会向容器存储层写入大量数据。
例如:
VOLUME /data 复制代码 运行时通过-v参数即可以覆盖默认的匿名卷设置。
USER 命令: 功能:指定当前用户
格式:USER 用户名:用户组
USER指令和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER则是改变之后层的执行RUN, CMD以及ENTRYPOINT这类命令的身份。当然，和WORKDIR一样，USER只是帮助你切换到指定用户。
当然这个大前提是，你的User用户是事先存在好的。
3、dockerfile用例 FROM centos ##继承至centos ENV mypath /tmp ##设置环境变量 WORKDIR $mypath ##指定工作目录 RUN yum -y install vim ##执行yum命令安装vim RUN yum -y install net-tools ###执行yum命令安装net-tools EXPOSE 80 ###对外默认暴露的端口是80 CMD /bin/bash ###CMD 容器启动命令，在运行容器的时候会自动执行这行命令，比如当我们 docker run -it centos 的时候，就会直接进入bash ##然后编译该镜像 docker build -f ./DockerFile -t mycentos:1.3. -t ##新镜像名字:版本 -f ###文件 -d 文件夹 引用 dockerfile的最佳实践
docker命令</content></entry><entry><title>Docker入门与实践</title><url>https://lizj3624.github.io/post/docker-primer/</url><categories><category>docker</category></categories><tags><tag>docker</tag></tags><content type="html"> 基础入门 docker命令大全速查 docker命令大全速查
docker核心概念 容器: Container 镜像: Image 仓库: Repository 使用docker镜像 获取镜像 # docker [image] pull NAME:[TAG] # NAME是镜像的名字，TAG是标签 docker pull ubuntu:18.04 docker pull registry.hub.docker.com/ubuntu:18.04 查看镜像信息 docker image docker tag ubuntu:latest myybuntu:latest docker inspect ubuntu:18.04 docker history ubuntu:18.04 查找 docker search --filter=stars=4 nginx 删除 docker rmi myubuntu:latest 创建容器 docker commit -m "add new file" -a "Docker Newbee" a925cb40b3f0 test:0.1 cat ubuntu-18.04-x86_64-minimal.tar.gz |docker import - ubuntu:18.04 # docker file 存出和载入镜像 docker load -i ubuntu_18.04.tar docker load &lt; ubuntu_18.04.tar docker tag test:latest user/test:latest docker push user/test:latest 操作容器 ## 创建容器 docker create -it ubuntu:latest ## 启动已经创建的容器 docker start af ## 创建并启动容器 docker run ubuntu /bin/echo 'Hello workd' -d 守护 ## 停止 docker pause [contains] docker stop ce5 docker restart ce5 ## 进入容器 docker attach docker exec -it 243c32535da7 /bin/bash ## 删除 docker rm ce554267d7a4 docker数据管理 数据卷将主机操作系统的目录直接映射到容器，类型Linux的mount行为
docker volume create -d local test # -mount 选项支持三种类型的数据卷，包括 : # volume : 普通数据卷，映射到主机/ var/lib/docker/volumes 路径下; # bind:绑定数据卷，映射到主机指定路径下; # tmpfs :临时数据卷，只存在于内存中 。 docker run d P -name web mount type=bind,source=/webapp,destination=/opt/ webapp training/webapp python app.py docker run -d -P --name web -v /webapp:/opt/webapp training/webapp python app.py # 只读 ro docker run -d -P --name web -v /webapp: /opt/webapp:ro training/webapp python app.py # 数据卷容器 docker run -it -v /dbdata --name dbdata ubuntu docker run -it --volumes-from dbdata -name db1 ubuntu # 数据卷容器备份和恢复 docker run -volumes-from dbdata -v $ (pwd) :/backup - -name worker ubuntu tar cvf /backup/backup.tar /dbdata docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 端口映射与容器互联 当容器中运行一些网络应用， 要让外部访问这些应用时， 可以通过-P或-p参数来指 定端口映射。当使用平(大写的)标记时， Docker会随机映射一个49000~49900的端口 到内部容器开放的网络端口:
# 本地主机的49155被映射到了容器的5000端口 docker run -d -P training/webapp python app.py # -p (小写的)则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。 支持的格式有 IP:HostPort:ContainerPort | IP::ContainerPort | HostPort:ContainerPort。 docker run -d -p 5000:5000 training/webapp python app.py docker run -d -p 5000:5000 -p 3000:80 training/webapp py thon app.py docker run -d -p 127.0.0.1::5000 training/webapp python app.py docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py # 查看端口映射 docker port nostalgic_morse 5000 docker run -d -P --name web --link db:db 扛aining/webapp py七hon app.py Dockerfile创建镜像 docker file 进阶 核心技术 基础架构 服务端 dockerd：为客户端提供RESTful API，响应来自客户端的请求，采用模块化的架构，通过专门的Engine模块来分发管理各个来自客户端的任务。 docker-proxy：是dockerd的子进程，当需要进行容器端口映射时，docker-proxy完成网络映射配置 containerd：是dockerd的子进程，提供gRPC接口响应来自dockerd的请求，对下管理runC镜像和容器环境。 containerd-shim：是containerd的子进程，为runC容器提供支持，同时作为容器内进程的根进程 runC是从docker公司开源的libcontainer项目演化而来的，目前加入OCI(Open Containers Initiative)，支持容器相关的技术栈，同时正在实现跨OS
客户端 docker命令就是客户端
镜像仓库 docker hub
命名空间 命名空间(namespace)是Linux内核的一个强大特性，为容器虚拟化的实现提供极大便利，每个容器都可以拥有自己单独的命名空间。 实现了内存、CPU、网络IO、硬盘IO、存储空间，还有文件系统、网络、PID、UID、IPC等相互隔离
进程命名空间 IPC命名空间 网络命名空间 挂载命名空间 UTS命名空间 用户命名空间 控制组 控制组(CGroups)是Linux内核的一个特性
资源限制 优先级 资源审计 隔离 控制 联合文件系统 联合文件系统(UnionFS)是一种轻量级的高性能分层文件系统，它支持将文件系统中的修改信息作为一次提交，并层层叠加，同时可以将不同目录挂载到同一个虚拟文件系统下，应用看到的挂载的最终结果。是docker镜像的技术基础
Linux网络虚拟化 docker中网络接口默认是虚拟接口.docker服务启动时首先在主机上自动创建一个docker0虚拟网桥，实际上是一个Linux网桥。网桥可以理解为一个软件交换机，负责挂载其上的接口之间进行包转发。同时，Docker随机分配一个本地未占用的私有网段中的一个地址给docker0接口，比如172.17.0.0、16，掩码为255.255.0.0.，此后启动的容器的网口也会自动分配一个该网段的地址。当创建一个Docker容器的时候，同时会创建了一对veth pair互联接口。当向任一个接口发送包时，另外一个接口自动收到相同的包。互联接口的一端位于容器内，即eth0；另一端在本地并被挂载到docker0网桥，名称以veth开头。通过这种方式，主机可以与容器通信，容器之间也可以相互通信。如此一来，Docker就创建了在主机和所有容器之间一个虚拟共享网络。</content></entry><entry><title>Hugo新增评论插件</title><url>https://lizj3624.github.io/post/hugo-comment/</url><categories><category>hugo</category></categories><tags><tag>hugo-plug-in</tag></tags><content type="html"> 缘起 我通过github用hugo的hugo-theme-next模板搭建博客，但是发现评论不可用， 每次提交评论时都提示Window.fetch: https://Your WalineSerURL/comment?lang=zh-cn is not a valid UR的错误，经过一顿google查询， 发现Hugo本身不支持评论，需要通过插件支持，我用的是hugo-theme-next的主题模板，评论插件是waline
waline评论插件 waline快速上手</content></entry><entry><title>美股科技巨头2021Q4财报</title><url>https://lizj3624.github.io/post/faamg/</url><categories/><tags><tag>美股</tag><tag>财报</tag><tag>FAAMG</tag></tags><content type="html"> 2022年2月美股科技巨头(FAAMG)相继发Q4财报，财报总结如下
云计算三巨头 本季度亚马逊云(AWS)Q4营收177.8亿美金，同比增速40%，微软云(Azure)Q4营收81.97亿美金，同比增速46%，谷歌云(GCP)Q4营收55.41亿美金，同比增速45%，均略超市场预期。三家云计算厂商预计占据市场超过75%的市场份额。
图1：AWS、Google Cloud、微软Azure季度增速对比 图2：2021年三家头部云计算厂商占据全球市场75%的市场份额 FAAMG财报 苹果：收入利润均超预期，硬件需求强劲，软件收入持续快速上升。2022财年第一季度苹果公司实现营收1239亿美元，同比增长11.3%，超彭博一致预期（1191亿美元），主要来源于2021年下半年新品发布的iPhone和Mac业务。同时软件用户端量价齐升，超越市场预期。毛利率逆势上升至43.8%。下季度指引：在供应限制的挑战下，产品收入有望实现稳健的同比增长。服务预计将实现强劲的两位数增长。毛利率预计在42.5%-43.5%之间，运营支出预计为125亿-127亿美元。
微软：数字化需求强劲，公司预计下季度Azure同比增速将上升，个人PC正在结构性复兴。本季度营收517亿美元，同比增长20%，经营利润222亿美元，同比增长24%，均略超市场预期。本季度Azure收入增速46%。下季度指引：智能云业务预计营收在187.5亿到190亿美元，生产力与业务处理预计营收156亿到158.5亿美元，个人计算预计营收141.5亿到144.5亿美元。
谷歌：净利润大超预期，广告需求强劲且竞争力改善。总营收753亿美元，同比增速32%，略超市场预期。经营利润219亿，同比增长40%。三季度EPS30.69美元，大超市场预期。谷歌广告除了相对受益苹果隐私新政之外，旅游业的强劲复苏也有望带动旅游广告投放量的增加。但YouTube、谷歌云未来的调整和增长点值得关注。
亚马逊：云计算超预期，电商供应链与资本开支压力或在下季度得到一定缓解，Prime提价。公司2月3日发布四季度财报，营收略低于预期。AWS本季营收增速提升到40%。下季度指引，收入预计1120-1170亿美元，预计同比增长3%-8%。营业利润预计30-60亿美元，去年同期为89亿美元。
特斯拉：交付能力与盈利能力均略超市场预期，22年主要关注FSD能力与机器人研发。公司本季度生产交付、盈利能力仍在快速提升，总收入同比增长65%，达到177亿美元；营业利润率达到14.7%，在所有批量OEM中实现了最高的季度营业利润率；其中汽车收入同比增长71%，达到160亿美元。全年汽车收入472亿美元，同比增长73%，营业利润率12%；全年GAAP净利润55亿美元，盈利能力快速提升。从汽车生产销售来看，全年汽车总产量超93.04万台，同比增长83%，汽车交付量超93.62万台，同比增长87%。汽车收入毛利率增加3.7个百分点，达到29.3%，其背后主要驱动力在于降低成本、利用上海工厂出口销售和刺激需求。
Meta：App用户增长停滞，且苹果Att政策影响短期盈利能力，主动应变，以短视频Reels、布局元宇宙生态应对Tiktok短视频崛起的全球竞争。季度收入同比增20%达336.7亿美元，略高于彭博一致预期，圣诞季Quest2销售贡献。利润不及预期，主要原因在于苹果隐私新政、监管影响、宏观经济影响（成本上升、供应链问题），用户时长主动部分迁移至商业化程度较低的Reels，以及美元升值带来的外汇影响。经营利润126亿美元，同比下滑1.5%，经营利润率37.4%。Meta面临和Tiktok的竞争与获取年轻用户的问题，短视频是发力的主战场之一，元宇宙生态则是下一代社交的真正决胜。公司2022年1季度的收入指引在270-290亿美元区间，同比增长3%-11%。</content></entry><entry><title>50种认知偏差</title><url>https://lizj3624.github.io/post/50-cognitive-biases/</url><categories/><tags><tag>认知偏差</tag></tags><content type="html"> 前段时间埃隆.马斯克在社交网站发布50种认知偏差，建议年轻人都应该了解这些偏差，可以少走一些弯路。 国人翻译成中文，再次记录一下，有空多看看这些认知偏差
什么是“认知偏差”？ 认知偏差是人们在知觉自身、他人或外部环境时，常因自身或情境的原因使得知觉结果出现失真的现象。 典型表现有显著性偏差、生动性偏差等。 社会知觉中常见的刻板印象、晕轮效应等均为某种形式的知觉偏差。是个人知觉具有选择性的特征所致。
“认知偏差”一般可以使用认知行为疗法（CBT）进行调整。 CBT是通过改变你不合理的思维模式与行为模式，来减少你产生失调的情绪和行为，从而达到改善你心理问题的疗法。
50种认知偏差-中文版 1. 基本归因错误 Fundamental Attribution Error
我们经常根据个性或者性格来定义别人，但会用情境因素帮自己开脱。
例如：Sally上课迟到，肯定是她懒，你自己迟到，就是早上太忙乱。
2. 自私的偏见 Self-Serving Bias
失败总是有原因的，⽽成功全是靠⾃⼰。
例如：觉得得奖是因为自己工作努力，而不是靠别人帮助和运气。但考试不及格，只是因为睡眠不足而已。
3. 组内偏爱 In-Group Favoritism
我们偏爱同一个圈子的圈内人，而不是圈外人。
例如：Francis跟你一个教堂，所以你喜欢他多过Sally。
4. 从众效应 Bandwagon Effect
随着越来越多的人接受某些理念、时尚和信仰，这些理念的影响也会随之壮大。
例如：Sally觉得指尖陀螺对孩子挺好的，Francis也这么觉得。
5. 群体思维 Groupthink
希望团队保持一致与和谐，我们有时会为了减少冲突去做一些不合理的决定。
例如：Sally想买冰激凌，Francis想买T恤，所以你建议买印冰激凌图案的T恤。
6. 光环效应 Halo Effect
如果你认为一个人具有某种积极的特质，那么这种积极的印象会溢出到他的其他特质中。反之亦然。
例如：Taylor这么可爱，他肯定一点也不刻薄。
7. 道德运气 Moral Luck
由于一个好的结果，会提高人们对其道德地位的评价，反之亦然。
例如：xx赢得了xx之争，那他们比输掉的人更有德行。
8. 错误共识 False Consensus
现实中支持我们观点的人要比我们想象中的少。
例如：所有人都是这么想的！
9. 知识的诅咒 Curse of Knowledge
一旦我们知道了某件事，我们就会假设其他人也同样知道这件事。
例如：Alice是一名教师，她很难理解新同学们看事情的⻆度。
10. 聚光灯效应 Spotlight Effect
我们会高估他人对自己外表及行为举止的关注程度。
例如：Sally很担心大家会注意到她的冰激凌T恤有多丑。
11. 可用性启发法 Availability Heuristic
我们在做判断时，通常都依赖于当下脑海中出现的最直观例子。
例如：选择品牌时，你通常会选择最近看到过广告的那家。
12. 防御性归因 Defensive Attribution
一件事故中，如果目击者与受害者经历相似，他们就会更少的责怪受害者，转而去攻击加害者。反之亦然。
例如：Sally开车等绿灯时在车里玩手机被追尾。目击者Greg也会开车玩手机。所以他对撞了Sally的人大吼大叫。
13. 公正世界假说 Just-World Hypothesis
我们倾向于相信世界是公正的。因此，我们会认为不公正的事是有原因的。
例如：Sally的钱包被偷了，看，她总因为T恤的事批评Francis，遭报应了吧。
14. 朴素现实主义 Naive Realism
我们相信自己观察到的就是客观现实；而其他人则是不理性，不知情或者有偏见的。
例如：我看到了这个世界的真相，其他人都很蠢。
15. 幼稚的愤世嫉俗 Naive Cynicism
相信自己观察到的是客观事实，而其他人以自我为中心的偏见比他们实际表现出来的更多。
例如：这人对我好的原因，肯定是想从我这⾥得到点什么。
16. 弗拉效应（又名巴纳姆效应） Forer Effect (aka Barnum Effect)
我们很容易将我们的个性归结为模糊的陈述，即使它们适用于更为广泛的人。
例如：这个星座指南真的是太准了！
17. 邓宁-克鲁格效应 Dunning-Kruger Effect
你知道的越少就越自信。知道的越多就越不自信。
例如：Francis自信地向大家保证，冰淇淋里绝对没有海带，海带也没有被用于乳制品行业。
18. 锚定效应 Anchoring
我们在做决定时非常依赖第一眼看到的信息。
例如：这东西现在是原价的50%，那肯定老便宜了。
19. 自动化系统偏差 Automation Bias
我们依赖自动化系统，有时甚至过于相信，导致真正正确的决策被放弃。
例如：手机的自动纠错功能把 “its” 替换成了 “it’s”，于是你假定“it’s”就是正确的。
20. 谷歌效应（又名数码健忘症） Google Effect (aka Digital Amnesia)
我们经常会忘记在搜索引擎中很容易找到的信息。
例如：那个电影的演员叫啥来着？我都查了8次了。
21. 阻抗理论 Reactance
当⾃由受到限制时，我们会产生不快，所以会做出一些反抗的行为来释放情绪。
例如：家长越让孩子去做作业，孩子越是不愿意做。
22. 确认偏差 Confirmation Bias
我们倾向于找到并记住能证实我们看法的信息。
例如：用不完整的证据得出一个阴谋论，却忽略那些相反的论据。
23. 逆火效应 Backfire Effect
人的一个错误的认知被新信息推翻时，新信息与人原本的看法不符，反而会加深人对原本错误认知的信任。
例如：相信阴谋论的人会认为，新出现的证据都是伪造用来掩盖阴谋论的。
24. 第三人称效应 Third-Person Effect
我们会认为媒体对他人的影响比对我们自己更大。
例如：你显然是被媒体洗脑了。
25. 信念偏差 Belief Bias
我们判断一个论点的⼒量，不是根据它支持结论的力度，而是根据我们自己认为结论的可信度。
例如：Sally说她也支持你那个阴谋论，但她没有说出什么证据来。
26. 可获性层叠 Availability Cascade
因为我们对融入社会的需要，越被公开和重复讨论的事情，我们越会相信其真实性。
例如：糖果里藏了剃须刀片的故事广为流传，最终许多美国人不再在万圣节时提供自制糖果。
27. 衰落主义 Declinism
我们倾向于将过去浪漫化，并消极地看待未来，认为社会/机构总体上正在衰退。
例如：在我们的孩童时代，孩子更懂得尊重！
28. 现状偏见 Status Quo Bias
我们倾向于保持不变，即使是有利的变化也被认为是一种损失
例如：即使某APP侵犯了Sally的隐私，她也不愿意换另一个这方面做得更好的试试。
29. 沉没成本谬误（又名承诺升级） Sunk Cost Fallacy (aka Escalation of Commitment)
即使面临失败的结果，人们会因为前期的投入，会在这个注定失败的事情上继续投入。
例如：“投入1分钱，就会再投1块钱！”（一不做，二不休）
30. 赌徒谬误 Gambler&rsquo;s Fallacy
认为某个事件未来的可能性会受到过去事件的影响。
例如：猜硬币已经输了9次了，下次应该能猜中。
31. 零风险偏差 Zero-Risk Bias
我们更愿意将小风险降低到零，即使我们可以通过另一种选择来降低整体风险。
例如：“你应该买个保险服务”
32. 框架效应 Framing Effect
人们对一个客观上相同问题的不同描述导致了不同的决策判断。
例如：候选人获得45%的支持率将大获全胜；候选人获得45%的支持率让全国失望；
33. 刻板印象 Stereotyping
人们普遍认为，尽管没有关于个人的信息，但一个群体的成员将具有某些相同的特征。
例如：那个留着精致小胡子的人肯定是个嬉皮士，估计还收集了一些黑胶唱片。
34. 外群体同质性偏差 Outgroup Homogeneity Bias
人们认为圈外人千篇一律，而自己圈子里的人各个不同。
例如：Alice不打游戏，她认为玩游戏的人都一样。
35. 权威偏见 Authority Bias
我们信任权威人物的意见，并经常受其影响。
例如：专家说这个可以这么做。
36. 安慰剂效应 Placebo Effect
如果我们相信某种治疗会奏效，它通常会产生很小的生理效应。
例如：Alice服用了安慰剂来止痛，结果疼痛真的减轻了。
37. 幸存者偏差 Survivorship Bias
我们看到的往往是幸存者的故事，因为未幸存者已无法发声。而我们很容易把看到的当作全部。
例如：看到返航的战斗机机翼弹孔最多，得出战斗机机翼是被击中最多的部位。是事实被击中发动机的飞机已经回不来了。
38. 精神活动过速 Tachypsychia
我们对时间的看法取决于创伤、吸毒和体力消耗。
例如：当差点被汽车撞到的时候，时间都慢下来了。
39. 琐碎法则（又名自行车棚效应） Law of Triviality (aka &ldquo;Bike-Shedding&rdquo;)
人们会对琐碎的问题给予不成比例的重视，同时又避免面对复杂的问题。
例如：一个地方市政府花费了大量的时间去讨论自行车道和自行车棚的问题，而不是想办法帮助无家可归的人。
40. 蔡格尼克记忆效应 Zeigarnik Effect
比起已完成的任务，人们更容易记住未完成的任务。
例如：Greg因任务清单上还没完成的一个任务而沮丧。
41. 宜家效应 IKIA Effect
人们更看重自己参与创造的东西。
例如：“你难道不爱这个花了我20美元的茶壶吗？它上面的涂绘可是我自己亲笔画的！”
42. 本·富兰克林效应 Ben Franklin Effect
如果我们已经帮了别人一个忙，那么我们更有可能帮他另一个忙。
例如：Greg给Francis借了一支钢笔，等Francis又向Greg借5元钱时，Greg很爽快的就借了。
43. 旁观者效应 Bystander Effect
周围的人越多，我们帮助受害者的可能性就越小。
例如：当有人在斗殴中受伤时，围观的那群学生里没人去打报警电话。
44. 暗示感受性 Suggestibility
我们，尤其是儿童，有时会将提问者建议的想法误认为是记忆。
例如：“你从沙发上摔下来是在你妈妈打你之前还是之后？”
45. 虚假记忆 False Memory
我们会把想象误以为是真实的记忆。
例如：Greg确定Sally说了一个关于菠萝的笑话，但这个笑话其实是他自己想到的。
46. 潜隐记忆 Cryptomnesia
我们会将真实的记忆误认为是想象。
例如：Greg以为去过墓地是他做的一个梦，实际上他真的去过墓地。
47. 集群错觉 Cluster Illusion
我们在随机数据中发现模式和规律。
例如：“你看那个云彩像不像你家的猫？”
48. 悲观偏见 Pessimism Bias
我们有时会高估坏结果的概率。
例如：水只剩下半杯了，啥都不会变好了。
49. 乐观偏见 Optimism Bias
我们有时对好的结果过于乐观
例如：水还有半杯呢，一切都会好起来的。
50. 盲点偏见 Blind Spot Bias
人们不认为自己有偏见，还会觉得别人比自己更偏激。
例如：“我没有偏见！”
50种认知偏差-英文版 引用原文</content></entry><entry><title>查理.芒格: 如何才能度过幸福且有钱的一生</title><url>https://lizj3624.github.io/post/charlie-munger-usc-law-commencement-speech-2007/</url><categories><category>查理芒格</category><category>价值投资</category><category>video</category></categories><tags><tag>查理芒格</tag><tag>价值投资</tag><tag>video</tag></tags><content type="html"> 查理·芒格(Charlie Munger)于2007年5月在南加州法学院毕业典礼上的演讲。 演讲实录-中英文 芒格学院翻译的中文版本
查理·芒格
演讲要点： 1、要得到你想要的某样东西，最可靠的办法是让你自己配得上它。
2、必须拥有跨学科的心态，才能高效而成熟地生活。
3、摆脱自私以及偏见、嫉妒、怨憎和自怜。每当发现自己产生了自怜的情绪，不管是什么原因，哪怕由于自己的孩子患上癌症即将死去,你也要想到，自怜是于事无补的。
4、如果你真的想要在某个领域做得很出色，那么你必须对它有强烈的兴趣，也一定要非常勤奋。
5、要拥有自己真正的能力，而不是鹦鹉学舌的知识。
以下是演讲正文： 你们当中肯定有许多人会觉得奇怪：这么老还能来演讲？嗯，答案很明显：他还没有死。
我已经把今天演讲的几个要点写了下来，下面就来介绍那些对我来说最有用的道理和态度。我并不认为它们对每个人而言都是完美的，但我认为它们之中有许多具有普遍价值，也有许多是「屡试不爽」的道理。
我非常幸运，很小的时候就明白了这样一个道理：要得到你想要的某样东西，最可靠的办法是让你自己配得上它。这是一个十分简单的道理，是黄金法则。
己所不欲，勿施于人 你们要学会己所不欲，勿施于人。总的来说，拥有这种精神的人在生活中能够赢得许多东西，他们赢得的不止是金钱和名誉。还赢得尊敬，理所当然地赢得与他们打交道的人的信任。能够赢得别人的信任是非常快乐的事情。
有的时候你们会发现有些彻头彻尾的恶棍死的时候既富裕又有名，但是周围绝大多数人都认为他们死有余辜。如果教堂里满是参加葬礼的人，其中大多数人去那里是为了庆祝这个小子终于死了。
这让我想起了一个故事：有一个这样的混蛋死掉了，神父说「有人愿意站出来，对死者说点好话吗？」没有人站出来，好长时间没有人站出来，最后有个人站了出来，他说「好吧，他的兄弟更糟糕」。
这不是你们想要得到的下场，以这样的葬礼告终的生活，不是你们想要的生活。
毛姆自传体小说：《人性的枷锁》
仰慕是爱的基础 我很小就明白的第二个道理是，正确的爱应该以仰慕为基础，而且我们应该去爱那些对我们有教育意义的先贤。我懂得这个道理且一辈子都在实践它。萨默赛特·毛姆（ Somerset Maugham ）在他的小说《人性的枷锁》中描绘的爱是一种病态的爱，那是一种病，如果你们发现自己有这种病，应该赶快把它治好。
坚持终身学习 有一个道理非常重要，那就是你们必须坚持终身学习。如果不终身学习，你们将不会取得很高的成就。光靠已有的知识，你们在生活中走不了多远。离开这里以后，你们还得继续学习，这样才能在生活中走得更远。
让伯克希尔·哈撒韦在这一个十年中赚到许多钱的方法，在下一个十年未必还能那么管用，所以沃伦·巴菲特不得不成为一部不断学习的机器。
层次较低的生活也有同样的要求，我不断地看到有些人在生活中越过越好，他们不是最聪明的，甚至不是最勤奋的，但他们是学习机器。他们每天夜里睡觉时，都比那天早晨聪明一点点。孩子们，这种习惯对你们很有帮助，特别是在你们还有很长的路要走的时候。
阿尔弗雷德·诺斯·怀特海曾经说过一句很正确的话，他说只有当人类「发明了发明的方法」之后，人类社会才能快速地发展。他指的是人均 GDP 的巨大增长和其他许多我们今天已经习以为常的好东西。人类社会在几百年前才出现了大发展，在那之前，每个世纪的发展几乎等于零。
人类社会只有发明了发明的方法之后才能发展，同样的道理，你们只有学习了学习的方法之后才能进步。
我非常幸运。在就读哈佛法学院之前就已经学会了学习的方法。在我这漫长的一生中，没有什么比持续学习对我的帮助更大。再拿沃伦·巴菲特来说，如果你们拿着计时器观察他，会发现他醒着的时候有一半时间是在看书，他把剩下的时间大部分用来跟一些非常有才干的人进行一对一的交谈。有时候是打电话，有时候是当面，那些都是他信任且信任他的人。仔细观察的话，沃伦很像个学究，虽然他在世俗生活中非常成功。
学习机器巴菲特
跨学科学习的重要性 另一个对我非常有用的道理是我当年在法学院学到的。那时有位爱开玩笑的教授说：「什么是法律头脑？如果有两件事交织在一起，相互之间有影响，你努力只考虑其中一件，而完全不顾另一件，以为这种思考方式既实用又可行的头脑就是法律头脑。」我知道他是在说反话，他说的那种「法律」方法是很荒唐的。
这给了我很大的启发，因为它促使我去学习各学科中所有的重要道理，这样我就不会成为那位教授所描绘的蠢货。因为真正重要的大道理占每个学科 95% 的份量，所以对我而言，从所有的学科吸取我所需要的 95% 的知识，并将它们变成我思维习惯的一部分，也不是很难的事情。
当然，掌握了这些道理后，你们必须通过实践去使用它们。这就像钢琴演奏家，如果不持续练习，就不可能弹得很好。所以我这辈子不断地实践那种跨学科的方法。
这种习惯帮了我很多忙，它让生活更有乐趣，让我能做更多的事情，让我变得更有建设性，让我变得非常富有，而这无法用天分来解释。我的思维习惯只要得到正确的实践，真的很有帮助。
但这种习惯也会带来危险，因为它太有用了，如果你们使用它，当你们和其他学科的专家（甚至是你们的老板），能够轻而易举地伤害你们。你们会常常发现，原来你们的知识比你老板更丰富，更能够解决他所遇到的问题。当他束手无策的时候，你们有时会知道正确的答案。
隐藏睿智 遇到这样的情况是非常危险的，因为你们的正确让有身份有地位的人觉得没面子，但我还没有找到避免受这个严重问题而伤害的完美方法。
尽管我年轻时扑克牌玩得很好，但在我认为我知道的比上级多的时候，我不太擅长掩饰自己的想法，没有很谨慎地去努力掩饰自己的想法，所以我总是得罪人。
现在人们通常把我当成一个行将就木的没有恶意的古怪老头，但在从前，我有过一段很艰难的日子。我建议你们不要学我，最好学会隐藏你们的睿智。
我有个同事，他从法学院毕业时成绩是全班第一名，曾在美国最高法院工作过，年轻时当过律师，当时他总是表现出见多识广的样子。有一天，他上级的高级合伙人把他叫进办公室，对他说：「听好了，查克，我要向你解释一些事情，你的工作和职责是让客户认为他是房间里最聪明的人。如果你完成了这项任务之后还有多余的精力，应该用它来让你的高级合伙人显得像是房间里第二聪明的人。只有履行了这两条义务之后，你才可以表现你自己。」
伏尔泰：如果有权有势的人错了，
而你是对的，那你就危险了
人们必须拥有跨学科的心态，才能高效而成熟地生活。在这里，我想引用古代最伟大的律师马尔库斯·图鲁斯·西塞罗的一个重要思想。西塞罗有句话很著名，他说，如果一个人不知道他出生之前发生过什么事情，在生活中就会像一个无知的孩童。
这个道理非常正确，西塞罗正确地嘲笑了那些愚蠢得对历史一无所知的人。但如果你们将西塞罗这句话推而广之，我认为你们应该这么做：除了历史之外，还有许多东西是人们必须了解的。
所谓的许多东西就是所有学科的重要思想。但如果你对一种知识死记硬背，以便能在考试中取得好成绩，这种知识对你们不会有太大的帮助。你们必须掌握许多知识，让它们在你们的头脑中形成一个思维框架，在随后的日子里能自动地运用它们。
如果你们能够做到这一点，我郑重地向你们保证，总有一天你们会在不知不觉中意识到：「我已经成为我的同龄人中最有效率的人之一」。与之相反，如果不努力去实践这种跨学科的方法，你们中的许多最聪明的人只会取得中等成就，甚至生活在阴影中。
《西塞罗发现阿基米德之墓》
历史是时代的见证、真理的火炬
记忆的生命、生活的老师和古人的使者
逆向思维 我发现的另外一个道理蕴含在麦卡弗雷院长刚才讲过的故事中，故事里的乡下人说：「要知道我会死在哪里就好啦，我将永远不去那个地方。」这乡下人说的话虽然听起来很荒唐，却蕴含着一个深刻的道理。对于复杂的适应系统以及人类的大脑而言，如果采用逆向思考，问题往往会变得更容易解决。如果你们把问题反过来思考，通常就能够想得更加清楚。
例如，如果你们想要帮助印度，应该考虑的问题不是「我要怎样才能帮助印度？」与之相反，你们应该问：「我要怎样才能损害印度？」你们应该找到能对印度造成最大损害的事情，然后避免去做它。
也许从逻辑上来看两种方法是一样的，但那些精通代数的人知道，如果问题很难解决，利用反向证明往往就能迎刃而解。生活的情况跟代数一样，逆向思考能够帮助你们解决正面思考无法处理的问题。
让我现在就来使用一点逆向思考。什么会让我们在生活中失败呢？我们应该避免什么呢？有些答案很简单，例如，懒惰和言而无信会让我们在生活中失败。如果你们言而无信，就算有再多的优点，也无法避免悲惨的下场。所以你们应该养成言出必行的习惯，懒惰和言而无信是显然要避免的。
代数之父花拉子米
数学思维让很多问题不再是问题
避免极端意识形态 要避免极端的意识形态，因为它会让人们丧失理智。年轻人特别容易陷入强烈而愚蠢的意识形态中，而且永远走不出来。当你们宣布自己是某个类似邪教团体的忠实成员，并开始倡导该团体的意识形态时，这样你们的头脑就会坏掉，而且有时候是以惊人的速度坏掉。
我有一条「铁律」，它帮助我在偏向于支持某种强烈的意识形态时保持清醒。我觉得我没资格拥有一种观点，除非我能比我的对手更好地反驳我的立场。我认为我只有在达到这个境界时才有资格发表意见。
我的做法对大多数人而言，可能太难了，但希望对我来说它永远不会变得太难。这种别陷入极端意识形态的方法，在生活中是非常非常重要的，如果你们想要成为明智的人，严重的意识形态很有可能会导致事与愿违。
前苏联宣传画 | 警惕自我思想被人操纵
消除"自我服务偏好"和自怜 有一种叫做「自我服务偏好」的心理因素也经常导致人们做傻事，它往往是潜意识的，所有人都难免受其影响。你们认为「自我」有资格去做它想做的事情，例如，透支收入来满足它的需求，那有什么不好呢？
从前有一个人，他是全世界最著名的作曲家，可是他大部分时间过得非常悲惨，原因之一就是他总是透支他的收入。那位作曲家叫做莫扎特。连莫扎特都无法摆脱这种愚蠢行为的毒害，我觉得你们更不应该去尝试它。
总的来说，嫉妒、怨憎、仇恨和自怜都是灾难性的思想状态。过度自怜可以让人近乎偏执，偏执是最难逆转的东西之一，你们不要陷入自怜的情绪中。
我有个朋友，他随身携带一叠厚厚的卡片，每当有人说了自怜的话，他就会慢慢地、夸张地掏出那一叠卡片，将最上面那张交给说话的人。卡片上写着「你的故事让我很感动，我从来没有听过有人像你这么倒霉。」
每当你们发现自己产生了自怜的情绪，不管是什么原因，哪怕由于自己的孩子患上癌症即将死去。你们也要想到，自怜是于事无补的。这样的时候，你们要送给自己一张我朋友的卡片。自怜总是会产生负面影响，它是一种错误的思维方式。如果你们能够避开它，你们的优势就远远大于其他人。
你们当然也要在自己的思维习惯中消除自我服务的偏好，别以为对你们有利的就是对整个社会有利的，也别根据这种自我中心的潜意识倾向来为你们愚蠢或邪恶的行为辩解，那是一种可怕的思考方式。你们要让自己摆脱这种心理，因为你们想成为智者而不是傻瓜，想做好人而不是坏蛋。
你们必须在自己的认知行动中，允许别人拥有自我服务的偏好。因为大多数人无法非常成功地清除这种心理，人性就是这样。如果你们不能容忍别人在行动中表现出自我服务的偏好，那么你们又是傻瓜。
正确的说服技巧是本杰明·富兰克林指出的那种，他说：「如果你想要说服别人，要诉诸利益，而非诉诸理性。」你们应该多多诉诸利益，而不是理性，即使是当你们的动机很高尚的时候。
富兰克林：如果你想要说服别人
要诉诸利益，而非诉诸理性
远离变态的激励机制 应该避免的事是受到变态的激励机制的驱动。你们不要处在一个你们表现得越愚蠢或者越糟糕，它就提供越多回报的变态激励系统之中，变态的激励机制具有控制人类行为的强大力量，人们应该避免受它影响。
变态的工作关系也是应该避免的，你们要特别避免在你们不崇敬或者不想像他一样的人手下干活，那是很危险的。所有人在某种程度上都受到权威人物的控制，尤其是那些为我们提供回报的权威人物。
要正确地应对这种危险，必须同时拥有才华和决心。在我年轻的时候，我的办法是找出我尊敬的人，然后想办法调到他手下去。总之，在你们正确地仰慕的人手下工作，在生活中取得的成就将会更加令人满意。
养成保持公正的习惯 养成一些让你能保持客观公正的习惯。我们都记得达尔文特别留意相反的证据，尤其是他证伪的是某种他信奉和热爱的理论时。如果你们想要在思考的时候尽量少犯错误，就需要这样的习惯。
人们还需要养成核对检查清单的习惯，核对检查清单能避免很多错误，不仅仅对飞行员来说是如此。你们不应该光是掌握广泛的基础知识，而是应该把它们在头脑中列成一张清单，然后再加以使用。没有其他方法能取得相同的效果。
达尔文 | 关注正确，更关注证伪
不平等最大化的奇效 另外一个我认为很重要的道理就是，将不平等最大化通常能够收到奇效。这句话是什么意思呢？约翰·伍登（ John Wooden ）提供了一个示范性的例子。伍登曾经是世界上最优秀的篮球教练。他对五个水平较低的球员说：「你们不会得到上场的时间，你们是陪练。」
比赛几乎都是那七个水平较高的球员在打的。这七个水平高的球员学到了更多，别忘了学习机器的重要性 —— 因为他们独享了所有的比赛时间。在他采用非平等主义的方法时，伍登比从前赢得了更多的比赛。
我认为生活就像比赛也充满了竞争，我们要让那些最有能力和最愿意成为学习机器的人发挥最大的作用。如果你们想要获得非常高的成就，你们就必须成为那样的人。你们不希望在 50 个轮流做手术的医生中，抓阄抽一个来给你们的孩子做脑外科手术。
约翰·伍登 | 掌声属于获胜的那方
避免鹦鹉学舌的技巧 我经常讲一个有关马克斯·普朗克的笑话。
普朗克获得诺贝尔奖之后，到德国各地作演讲，每次讲的内容大同小异，都是关于新的量子物理理论的，时间一久，他的司机记住了讲座的内容。司机说：「普朗克教授，我们老这样也挺无聊的，不如这样吧，到慕尼黑让我来讲，你戴着我的司机帽子坐在前排，你说呢？」
普朗克说：「好啊。」于是司机走上讲台，就量子物理发表了一通长篇大论。后来有个物理学教授站起来，提了一个非常难的问题。演讲的司机说：「哇，我真没想到，我会在慕尼黑这么先进的城市，遇到这么简单的问题。我想请我的司机来回答。」
讲这个故事，并不是为了表扬主角很机敏。我认为这个世界的知识可以分为两种：一种是普朗克知识，它属于那种真正懂的人。他们付出了努力，他们拥有那种能力。另外一种是司机知识。他们掌握了鹦鹉学舌的技巧；他们可能有漂亮的头发；他们的声音通常很动听；他们给人留下深刻的印象。
但其实他们拥有的是伪装成真实知识的司机知识。如果你们在生活中想努力成为拥有普朗克知识的人，而避免成为拥有司机知识的人，你们将遇到这个问题。到时会有许多巨大的势力与你们作对。
普朗克 | 鹦鹉学舌是技巧，而不是知识
培养兴趣，保持勤奋 如果你们真的想要在某个领域做得很出色，那么你们必须对它有强烈的兴趣。我可以强迫自己把许多事情做得相当好，但我无法将我没有强烈兴趣的事情做得非常出色。从某种程度上来讲，你们也跟我差不多。所以如果有机会的话，你们要想办法去做那些你们有强烈兴趣的事情。
还有就是，你们一定要非常勤奋才行。我非常喜欢勤奋的人。我这辈子遇到的合伙人都极其勤奋。我想我之所以能够和他们合伙，部分原因在于我努力做到配得起他们，部分原因在于我很精明地选择了他们，还有部分原因是我运气好。
我早期的生意上曾经有过两位合伙人，他们俩在大萧条期间合资成立了一家建筑设计施工公司，达成了很简单的协议：「如果我们没有完成对客户的承诺，我们俩要每天工作 14 个小时，每星期工作 7 天，直到完成为止。」不用说你们也知道啦，这家公司做得很成功。我那两位合伙人广受尊敬。他们这种简单的老派观念几乎肯定能够提供一个很好的结果。
正视生活中的不幸 你们在生活中可能会遭到沉重的打击，不公平的打击。有些人能挺过去，有些人不能。我认为爱比克泰德（ Epictetus ）的态度能够引导人们作出正确的反应。他认为生活中的每一次不幸，无论多么倒霉，都是一个锻炼的机会。他认为每一次不幸都是吸取教训的良机。
人们不应该在自怜中沉沦，而是应该利用每次打击来提高自我。他的观点是非常正确的，影响了最优秀的罗马帝国皇帝马库斯·奥勒留（ Marcus Aurelius ），以及随后许多个世纪里许许多多其他的人。
你们很可能会说：「谁会在生活中整天期待麻烦的到来啊？」其实我就是这样的。在这漫长的一生中，我一直都在期待麻烦的到来。现在我已经 84 岁啦。就像爱比克泰德，我也拥有一种蒙受恩宠的生活。我总是期待麻烦的到来，准备好麻烦来临时如何对付它，这并没有让我感到不快乐。这根本对我没有任何害处，实际上，这对我有很大的帮助。
爱比克泰德 | 自怜无用
避免官僚主义，保持信任 由于在你们将要从事的行业中有大量的程序和繁文缛节，最后一个我想要告诉你们的道理是，复杂的官僚程序不是文明社会的最好制度。最好的制度是一张无缝的、非官僚的信任之网。没有太多稀奇古怪的程序。
只有一群可靠的人，他们彼此之间有正确的信任。那是玛约医疗中心手术室的运作方式。如果那里的医生像律师那样，设立许多像法律程序那么繁琐的规矩，更多的病人会死于非命。
所以当你们成为律师的时候，永远别忘记，虽然你们在工作中要遵守程序，但你不用总是被程序牵着鼻子走。你们在生活中应该追求的是尽可能地培养一张无缝的信任之网。如果你们拟定的婚姻协议书长达 47 页，那么我建议你们这婚还是不结为妙。
好啦，在毕业典礼上讲这么多已经够啦。我希望这些老人的废话对你们来说是有用的。最后，我想用约翰·班扬的巨作《天路历程》中那位真理剑客年老之后唯一可能说出的话来结束这次演讲：「我的剑传给能挥舞它的人」。</content></entry><entry><title>美股动态及各国宏观数据</title><url>https://lizj3624.github.io/post/stock-index/</url><categories/><tags><tag>美股</tag><tag>数据</tag></tags><content type="html"> 实时查看美股动态数据，实时查看各国宏观数据
新浪美股实时行情 新浪美股实时行情
新浪美股实时行情-纳斯达克交易所
历年美股市值总量
全球股指、期货、大宗商品 全球股指期货动态一览
英文财经全球金融市场动态
全球宏观 财经M平方-全球宏观</content></entry><entry><title>Cloudflare 公布 2021 年第四季度和财年财务业绩</title><url>https://lizj3624.github.io/post/cloudflare-2021-q4/</url><categories/><tags><tag>cloudflare</tag><tag>财报</tag></tags><content type="html"> 2022年2月10号盘后，Cloudflare发布了Q4财报和全年财报，信息如下
Cloudflare 2021年Q4财报亮点 第四季度收入总计 1.936 亿美元，同比增长 54%；2021财年收入总计6.564亿美元，同比增长52% 在大型企业客户持续增长的推动下，创纪录的美元净留存率为 125%，同比增长 600 个基点 第四季度实现创纪录的经营现金流和正的自由现金流；经营现金流为 4060 万美元，占总收入的 21%，自由现金流为 860 万美元，占总收入的 4% 2021财年第四季度财务摘要 收入：总收入为 1.936 亿美元，同比增长 54%。 毛利润：GAAP 毛利润为 1.511 亿美元或 78.0% 毛利率，而 2020 年第四季度为 9690 万美元或 76.9%。非 GAAP 毛利润为 1.533 亿美元或 79.2% 毛利率，而 9830 万美元，或78.1%，在 2020 年第四季度。 营业收入（亏损）：2020 年第四季度，GAAP 运营亏损为 4110 万美元，占总收入的 21.2%，而 2470 万美元，占总收入的 19.6%。非 GAAP 运营收入为 220 万美元，或占总收入的 1.2%，而 2020 年第四季度的运营亏损为 550 万美元，占总收入的 4.3%。 净收入（亏损）：GAAP 净亏损为 7750 万美元，而 2020 年第四季度为 3400 万美元。GAAP 每股基本和稀释后净亏损为 0.24 美元，而 2020 年第四季度为 0.11 美元。非 GAAP 净收入为10 万美元，而 2020 年第四季度非 GAAP 净亏损为 740 万美元。非 GAAP 每股摊薄净收益为 0.00 美元，而 2020 年第四季度非 GAAP 每股净亏损为 0.02 美元。 现金流：经营活动产生的净现金流为 4060 万美元，而 2020 年第四季度为负 880 万美元。自由现金流为 860 万美元，占总收入的 4%，而负2350 万美元，占总收入的 19%收入，在 2020 年第四季度。 截至 2021 年 12 月 31 日，现金、现金等价物和可供出售证券为 18.218 亿美元。 2021 年全年财务摘要 收入：总收入为 6.564 亿美元，同比增长 52%。 毛利润：美国通用会计准则毛利润为 5.093 亿美元或 77.6% 毛利率，而 2020 财年为 3.30 亿美元或 76.6%。非美国通用会计准则毛利润为 5.159 亿美元，或 78.6% 毛利率，而 3.346 亿美元或 77.6% %，在 2020 财年。 运营亏损： 2020 财年，GAAP 运营亏损为 1.277 亿美元，占总收入的 19.5%，而 2020 财年为 1.068 亿美元，占总收入的 24.8%。非 GAAP 运营亏损为 700 万美元，占总收入的 1.1%，相比之下，2020 财年为 3390 万美元，占总收入的 7.9%。 净亏损：GAAP 净亏损为 2.603 亿美元，而 2020 财年为 1.194 亿美元。GAAP 每股净亏损为 0.83 美元，而 2020 财年为 0.40 美元。非 GAAP 净亏损为 1510 万美元，而 2020 财年为 3510 万美元。 GAAP 每股净亏损为 0.05 美元，而 2020 财年为 0.12 美元。 现金流：经营活动产生的净现金流为 6460 万美元，而 2020 财年为负 1710 万美元。自由现金流为负 4310 万美元，占总收入的 7%，而负9210 万美元，占总收入的 21%， 2020财年。 财务展望 由于持续的 COVID-19 大流行，以下有关我们财务前景的前瞻性陈述受到很大的不确定性，反映了我们截至 2022 年 2 月 10 日关于大流行对我们运营的影响的估计，并且高度依赖于我们可能无法预测或控制的许多因素，其中包括：大流行的持续时间、传播范围和严重程度；政府和企业为应对这一流行病而采取的行动及其对我们的客户、供应商和合作伙伴的影响；在全球范围内接种 COVID-19 疫苗的时机以及这些疫苗的长期疗效；大流行对全球和区域经济以及总体经济活动的影响；我们在受影响地区继续运营的能力；
对于 2022 财年第一季度，我们预计： 总收入为 2.05 至 2.06 亿美元 Non-GAAP 运营收入为 0.5 至 150 万美元 Non-GAAP 每股净收益为 0.00 美元至 0.01 美元，使用约 3.48 亿股的加权平均已发行普通股 对于 2022 财年全年，我们预计： 总收入为 9.27 至 9.31 亿美元 Non-GAAP 运营收入为 10.0 至 1400 万美元 Non-GAAP 每股净收益为 0.03 至 0.04 美元，使用约 3.52 亿股的加权平均已发行普通股</content></entry><entry><title>中文浏览国外社交媒体热点(Buzzing.cc)</title><url>https://lizj3624.github.io/post/buzzing/</url><categories/><tags><tag>buzz</tag><tag>国外论坛</tag></tags><content type="html"> 英文不太好，一直想找翻译国外媒体热点的网站，今天终于找到了buzzing.cc
中文浏览国外社交媒体热点 Buzzing 适合：
想要了解世界（主要是英文世界）正在发生什么的人 有一定的英语基础，但是无法流畅阅读 想要提升英文阅读量，但是找不到感兴趣的读物 注重阅读体验，喜欢简约的排版 热点预览-英文版 热点预览</content></entry><entry><title>金融炼金术(The Alchemy of Finance)</title><url>https://lizj3624.github.io/post/the-alchemy-of-finance/</url><categories/><tags><tag>金融</tag><tag>读书</tag></tags><content type="html"> 最近在看索罗斯的《金融炼金术》再次做一下读书笔记以及自己的体悟
反身性理论(theory of reflexivity)的概念
反身性的概念其实很简单：在任何包含有思维参与者的情景中，参与者的思想和现实情况之间存在着一种相互影响的关系。 一方面思考者试图去了解真实的情况，另一方面他们试图获得一个他们想象中的结果。这两种过程起到的作用相反：在求 知的过程中现实是已知量，然而在参与的过程中，参与者的思想成为了已知量。在提出哪些是已知的而哪些是未知的时候，这 两种作用会相互干涉。我将这种两个作用间的相互干涉称之为"反身性"。反身性导致参与者对于现实的理解是不完美的，同时 参与者的行为也会产生他们无法预知的后果。
那种觉得市场永远能够做出正确决定的幻觉是建立在参与过程和认知过程间的反身性互动上的。事实上，市场总是错误的， 他的趋势体现在膨胀期的自我满足以及衰退期的自我瓦解。因此只有处在转折点时流行倾向才会被证明是错的。
人类不确定性原则
人类不确定性原则认为人们对于他们生活的世界的认知是不可能同时满足真实性、完整性和连贯性的。在人们的思维受到 现实限制的情况下，思维是不足以做出完美的决策的；而当思维干预了决策的情况下，思维就无法控制现实的走向。
人类不确定性原则与海森堡测不准原理有很多相似之处，海森堡测不准原理认为量子粒子的位置和动量不可能同时被测出。
索罗斯将他提出的人类不确定性原则跟量子力学的海森堡测不准原理对比，看来索罗斯对量子力学了解不少，难道他的量子 基金名称也是由此来的，哈哈。
历史的鞋带理论
我们更多地关注结果与预期之间的差别。结果会受到预期的影响，但是不会被预期所决定。它们之间存在一个双向的反馈循环： 认知过程是从结果到预期，而参与过程是从预期到结果。两个过程持续地向不同方向起作用。因果关系的方向并不是从一个结果 传到下一个，它交叉往复与结果和预期之间，反之亦然。我称之为"历史的鞋带理论"</content></entry><entry><title>美国上市公司总市值已近50万亿美金</title><url>https://lizj3624.github.io/post/us-stock-cap/</url><categories/><tags><tag>宏观</tag><tag>美股</tag></tags><content type="html"> 根据Siblis Research 的数据显示：
1、2021年9月，在纽交所、纳斯达克、美国柜台交易市场上市的美国公司总市值为48.6万亿美金，美国前500上市公司市值为38.4万亿美金，美国2020年GDP才21万亿美金。
2、美国公司在2000年初经历了互联网泡沫，市值连跌几年；2008年又经历次贷危机，市值大幅下降；随后十几年，美国公司市值基本都是年年增长。
3、虽然去年美国股市在疫情期间经历暴跌，多次熔断，但随后几个月信心很快恢复，2020年美国公司总市值还同比增加20.1%。随后美国股市屡创新高，截止今年9月份，美国公司市值已经同比上涨19.2%。
4、虽然美国公司市值不断上涨，但在美国上市的中概股却是惨不忍睹，阿里巴巴因为反垄断和蚂蚁金服事件市值已经下跌一半，教育行业由于双减政策都经历暴跌，市值十不存一，其它中概股也都有大幅度下跌。
5、美国最近十几年从移动互联网中获利最多，苹果、亚马逊、谷歌、facebook、微软不断发展，覆盖用户越来越广，对全球的影响不断加强，从全世界各地赚了太多的钱。
6、美国五大科技巨头当前市值近10万亿美金，占美国公司总市值超20%，从次贷危机以来，这五家科技巨头市值已上涨几十倍甚至上百倍，带动美国公司市值增长。
引用原文</content></entry><entry><title>Markdown语法手册</title><url>https://lizj3624.github.io/post/markdown-syntax/</url><categories><category>themes</category><category>syntax</category></categories><tags><tag>markdown</tag><tag>css</tag><tag>html</tag></tags><content type="html"> 本文提供了一个可以在 Hugo 内容文件中使用的基本Markdown语法示例，还展示了基本 HTML 元素在 Hugo 主题中是否使用 CSS 装饰。
标题 下面的 HTML 代码&lt;h1>—&lt;h6> 元素表示六个级别的节标题。 &lt;h1>是最高的节级别，&lt;h6>是最低的节级别。
H1 H2 H3 H4 H5 H6 段落 Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.
伊塔图？厨房里有很多东西，我不知道他们喜欢吃什么，或者他们喜欢吃什么。
引用 blockquote元素表示从另一个来源引用的内容，可选的引用必须在footer或cite元素内，也可选的内嵌更改，如注释和缩写。
引用没有归属 Tiam, ad mint andaepu dandae nostion secatur sequo quae. 注意 可以在块引用中使用 Markdown 语法。
带归属的引用 不要通过分享记忆来交流，通过交流来分享记忆。
— 罗布·派克1
表格 表不是Markdown核心规范的一部分，但是Hugo支持开箱即用。
Name Age Bob 27 Alice 23 表格内使用Markdown语法 Italics Bold Code italics bold code 图像 ![图像描述](图像地址) 示例 Google Chrome Firefox Browser
点击图像可以打开图像浏览器，快试试吧。
代码块 带有引号的代码块 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 用四个空格缩进的代码块 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 代码块引用Hugo的内部高亮短代码 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 列表类型 有序列表 First item Second item Third item 无序列表 List item Another item And another item 嵌套列表 Fruit Apple Orange Banana Dairy Milk Cheese 其他元素 — abbr, sub, sup, kbd, mark GIF 是位图图像格式。
H2O
Xn + Yn = Zn
按 CTRL+ALT+Delete 组合键结束会话。
大多数蝾螈在夜间活动，捕食昆虫、蠕虫和其他小动物。
以上引文摘自Rob Pike在2015年11月18日Gopherfest上的演讲。&#160;&#8617;&#xfe0e;</content></entry><entry><title>富文本内容测试</title><url>https://lizj3624.github.io/post/rich-content/</url><categories/><tags><tag>shortcodes</tag><tag>privacy</tag></tags><content type="html"> Hugo上有几个内置短代码，用于丰富内容，以及隐私配置还有一组简单的短代码，支持各种社交媒体嵌入的静态和非JS版本。
YouTube Privacy Enhanced Shortcode Twitter Simple Shortcode .twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; } “In addition to being more logical, asymmetry has the advantage that its complete appearance is far more optically effective than symmetry.”
— Jan Tschichold pic.twitter.com/gcv7SrhvJb
&mdash; Graphic Design History (@DesignReviewed) January 17, 2019 Vimeo Simple Shortcode .__h_video { position: relative; padding-bottom: 56.23%; height: 0; overflow: hidden; width: 100%; background: #000; } .__h_video img { width: 100%; height: auto; color: #000; } .__h_video .play { height: 72px; width: 72px; left: 50%; top: 50%; margin-left: -36px; margin-top: -36px; position: absolute; cursor: pointer; }</content></entry><entry><title>占位符文本显示</title><url>https://lizj3624.github.io/post/placeholder-text/</url><categories/><tags><tag>markdown</tag><tag>text</tag></tags><content type="html"> 你对我的心有偏见。我向您保证，我们的生活将不会受到影响，我们的生活将会受到影响。你说你现在住在医院里，因为你的眼睛是透明的，你的眼睛是光明的，你的眼睛是光明的!
Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.
Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt
The Van de Graaf Canon
Mane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.
Iubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.
Eurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.</content></entry><entry><title>数据公式设置显示</title><url>https://lizj3624.github.io/post/math-typesetting/</url><categories/><tags/><content type="html"> Hugo项目中的数学表示法可以通过使用第三方JavaScript库来实现。
在这个例子中，我们将使用 MathJax
Create a post under /content/en[zh-CN]/math.md
可以全局启用MathJax，请在项目配置中将参数math设置为true
或是在每页基础上启用MathJax，在内容文件中包括参数math: true
注意： 使用支持的TeX功能的联机参考资料
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \ \dot{y} &amp; = \rho x - y - xz \ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
这些方程式很狭窄。我们可以使用(例如)添加垂直间距 [1em] 在每个换行符(\)之后。正如你在这里看到的：
$$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \[1em] \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \[0.5em] \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \[1em] \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\ a_{21} &amp; a_{22} &amp; a_{23}\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$</content></entry><entry><title>支持Emoji表情符号</title><url>https://lizj3624.github.io/post/emoji-support/</url><categories/><tags><tag>emoji</tag></tags><content type="html"> 在Hugo项目中可以通过多种方式启用Emoji。
The emojify function can be called directly in templates or Inline Shortcodes.
To enable emoji globally, set enableEmoji to true in your site&rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.
馃檲 🙈 馃檳 🙉 馃檴 🙊
The Emoji cheat sheet is a useful reference for emoji shorthand codes.
N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.
.emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; }</content></entry><entry><title>关于我</title><url>https://lizj3624.github.io/about.html</url><categories/><tags/><content type="html"> Hugo是用Go编写的一个开放源代码静态站点生成器，可在Apache许可证2.0下使用。 Hugo支持TOML, YAML和JSON数据文件类型，Markdown和HTML内容文件，并使用短代码添加丰富的内容。其他值得注意的功能包括分类法、多语言模式、图像处理、自定义输出格式、HTML/CSS/JS缩小和对Sass SCSS工作流的支持。
Hugo使用了多种开源项目，包括:
https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo是博客、企业网站、创意作品集、在线杂志、单页应用程序甚至是数千页的网站的理想选择。
Hugo适合那些想要手工编写自己的网站代码，而不用担心设置复杂的运行时、依赖关系和数据库的人。
使用Hugo建立的网站非常快速、安全，可以部署在任何地方，包括AWS、GitHub Pages、Heroku、Netlify和任何其他托管提供商。
更多信息请访问GitHub.</content></entry></search>